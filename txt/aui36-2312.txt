BY ORDER OF THE COMMANDER                        AIR UNIVERSITY INSTRUCTION 36-2312
AIR UNIVERSITY (AETC)                                                  16 NOVEMBER 2011

                                                                                   Personnel

                                                          AIR UNIVERSITY ASSESSMENT
                                                                           PROGRAMS


              COMPLIANCE WITH THIS PUBLICATION IS MANDATORY

ACCESSIBILITY: Publications and forms are available on the e-Publishing web site at
               www.e-publishing.af.mil for downloading or ordering.

RELEASABILITY: There are no releasability restrictions on this publication.

OPR: AU/CFAE                                                             Certified by: AU/CF
                                                                       (Dr. Bruce T. Murphy)
Supersedes:   AUI 36-2312, 4 February                                               Pages: 26
              2004


This instruction establishes policies and procedures for assessment programs in Air University
(AU) educational and support service programs. It complements information contained in
AFMAN 36-2234, Instructional System Development; AFI 36-2301, Deveopmental Education;
AFI 38-501, Air Force Survey Program AU Sup 1, Air Force Survey Program; AUI 36-2322,
Air University Institutional Effectiveness and Institutional Research; AUI 36-105,
Responsibilities for Faculty Development and Enrichment; AUI 36-2309, Academic Integrity;
AUI 36-2303, Recognition of Outstanding Student Achievement; and the Southern Association of
Colleges and Schools’ Commission on Colleges Principles of Accreditation: Foundations for
Quality Enhancement, 2010 Edition. Refer recommended changes and/or corrections to this
publication to the Office of Primary Responsibility (OPR) using the AF Form 847,
Recommendation for Change of Publication, through your chain of command. Ensure that all
records created as a result of processes prescribed in this publication are maintained in
accordance with Air Force Manual (AFMAN) 33-363, Management of Records, and disposed of
in accordance with the Air Force Records Information Management System (AFRIMS) Records
Disposition Schedule (RDS) located at https://www.my.af.mil/afrims/afrims/afrims/rims.cfm.
This instruction applies to all AU educational programs, educational support units,
administrative support units, research within the AU mission and community/public service
programs.

SUMMARY OF CHANGES

This document is substantially revised and should be thoroughly reviewed. This revision
adds updated guidance to ensure that comprehensive institutional effectiveness practices are
 2                                                                                 AUI36-2312 16 NOVEMBER 2011


implemented throughout Air University. It requires collection of institutional data on measures
related to the AU Strategic Plan, Balanced Score Card, program efficiency and program
effectiveness data. It changes the definition of educational programs subject to assessment, IAW
new SACS-COC standards.

       1.     Purpose and Scope. ................................................................................................    3
       2.     Roles and Responsibilities. ....................................................................................       3
       3.     Assessment Programs ............................................................................................       7
Figure 3.1.   Preferred Response Order ......................................................................................        9

ATTACHMENT 1—GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION                                                                      14

Attachment 2—ANNUAL PROGRAM ASSESSMENT REPORT FORMAT                                                                                17

Attachment 3—HQ/AU INSTITUTIONAL EFFECTIVENESS OFFICE (HQ/AU CFAE)                                                                  18
AUI36-2312 16 NOVEMBER 2011                                                                     3


1. Purpose and Scope. Air University is a regionally accredited institution of higher education.
Because it is fundamentally a military organization, there are numerous directives, instructions,
guidance and policies published by higher headquarters that affect Air University faculty and
students. This document complements without repeating, that guidance. This instruction
provides guidance for development and implementation of systematic, comprehensive
assessment programs. Academic assessment programs are designed by faculty, senior
educational leaders and assessment professionals at each Center. They should generate data and
provide information to decision makers on the degree to which students achieve expected
outcomes and on the effectiveness and efficiency of programs. Assessment is a central function
that takes place in every phase of the curriculum and/or program development process. The
Instructional Systems Development process should be followed IAW AFMAN 36-2234 for
academic programs. Support programs may use AFSO-21, Balanced Scorecard, functionally
mandated assessment systems or other evaluation methods most appropriate to the services
provided. This instruction describes the assessment process for program-level outcomes. The
assessment of intermediate goals, course outcomes and objectives and other continuous process
improvement initiatives that support achievement of program-level outcomes is the purview of
Center and school commanders/commandants.
   1.1. Air Force Institute of Technology (AFIT). AFIT shall develop its own operating
   instruction on assessment of academic programs and educational and support services.
   AFIT’s operating instruction will guide the development and execution of its assessment
   programs, but will comply with the intent of this instruction, differing only as needed to meet
   North Central Association Higher Learning Commission accreditation standards
   appropriately applied to AFIT’s unique requirements.
2. Roles and Responsibilities.
   2.1. HQ AU Commander and President. AU Commander/President (AU/CC) is
   responsible for ensuring the institution engages in ongoing, integrated, and institution-wide
   research-based planning and assessment processes that 1) incorporate a systematic review of
   institutional mission, goals, and outcomes; 2) result in continuing improvement in
   institutional quality; and 3) demonstrate the institution is effectively accomplising its
   mission.
   2.2. HQ AU Vice President for Academic Affairs. The AU/CC implements university-
   wide program assessment and evaluation program through its Academic Affairs Office of
   Institutional Effectiveness (AU/CFAE).
       2.2.1. AU Institutional Effectiveness. The Chief of Institutional Effectiveness provides
       oversight and advice on program assessment policy, procedures, and methods employed
       by centers, colleges and support services throughout the university. It ensures systematic,
       explicit, and documented processes exist to measure performance
           2.2.1.1. Accreditation. Collects and evaluates documentation from educational
           programs, educational and administrative support services, research programs and
           community/public service programs. This information is used to determine the degree
           to which program level outcomes are met across the university and may also be used
           to support reaffirmation of accreditation with the Southern Association of Colleges
           and Schools Commission on Colleges (SACS COC).
4                                                   AUI36-2312 16 NOVEMBER 2011


    2.2.1.2. Compliance Certification. Prepares compliance certification documents in
    support of accreditation with SACS-COC.
    2.2.1.3. Liaison. Establishes and maintains communication with the cadre of program
    evaluators in AU centers, colleges and schools through regular formal and informal
    meetings of the AU Institutional Effectiveness Working Group.
    2.2.1.4. Human Subjects Research. Air University engages in research-based
    planning and assessment processes. It also fosters research in support of its
    educational mission. Routine program assessment studies are generally exempt from
    Institutional Review Board (IRB) oversight. However, some studies that collect data
    from students, faculty or other participants may require IRB approval. The Academic
    Office develops and maintains a Human Research Protection Program (HRPP) IAW
    AFMSA/SGE-C, Air Force Research Oversight and Compliance Office guidance to
    ensure compliance with the 32 CFR 219, Protection of Human Subjects, and AFI 40-
    402 Protection of Human Subjects in Biomedical and Behavioral Research. This
    program includes an engagement agreement between AU and United States Air Force
    Academy’s (USAFA) IRB for the purposes of gaining IRB approval for human
    subject research. It conforms to all of USAFA’s IRB requirements. AFI 40-402
    describes the responsibilities, requirements and procedures for conducting studies
    involving human subjects.
    2.2.1.5. Survey Control. All surveys, including interview and focus group protocols,
    used in program assessment require an Air University survey control number.
    AU/CFAE serves as Survey Control Officer for Air University and performs
    activities in accordance with AFI 38-501 and its Air University Supplement; assigns
    AU survey control numbers and gains approval for surveys that cannot be approved
    locally; and maintains a copy of all program surveys. The Survey Control Officer
    may also provide advice on survey construction and analysis of data, and may review
    survey results.
    2.2.1.6. Strategic Plan and Balanced Scorecard. AU Plans and Programs Directorate
    (AU/A5/8) develops and manages AU strategy using a combination of the AU
    Strategic Plan and the Balanced Scorecard (BSC) strategy management system in
    accordance with AETCI 90-1101 Strategy Management. BSC is a measurement
    system, strategic management system, and communication tool that provides a
    balance between long and short-term objectives, financial and non-financial
    measures, lagging and leading indicators, and external and internal performance
    perspectives. AU/A5/8 develops and coordinates AU/CC (in his dual-role as AETC
    Director of Education, AETC/ED) input to AETC’s strategic plans, BSC, and
    initiatives to form the basis of an effective and integrated strategic management
    process. AU/CFAE collects data for AU and AETC Balanced Scorecards (BSC)
    related to assessment of programs and institutional research for which AU/CF is the
    action officer or objective champion. AU/CFAE coordinates with AFIT’s Institutional
    Effectiveness office to assist AFIT in presenting BSC data for those objectives to the
    AU and AETC BSC board and council structures and to provide analyses of program
    effectiveness to leadership.
AUI36-2312 16 NOVEMBER 2011                                                                   5


         2.2.1.7. Compliance with Air University instructions. AU/CFAE conducts annual
         staff assistance visits of programs to evaluate the effectiveness and efficiency of
         program assessment methods, planned outcomes, compliance with relevant Air
         University instructions and other required guidance, faculty evaluation processes,
         data collection, systematic and comprehensive use of data for decision-making,
         formative and summative decisions and related results, and documentation. This
         applies to all delivery formats including resident, non-resident and distance learning
         administered by Air University’s Maxwell-Gunter AFB campus. A standardized
         checklist (Attachment 3) is provided to program evaluators prior to the visit.
         Feedback on the results will be provided to the center’s, college’s or school’s
         assessment POC, the program’s commander/commandant and AU Chief Academic
         Officer in the form of a summary report within 30 days of the visit.
  2.3. Academic Centers. Program assessment at Air University is conducted by faculty,
  program evaluation and assessment personnel and administrators responsible for each
  academic program. Assessment programs provide data to determine the extent to which
  expected student outcomes are achieved and to inform formative and summative decisions
  that support the school’s mission. Key aspects of the program should be examined to
  determine the efficient and effective use of resources. The AU Academic Office will be
  included on distribution list of program assessment reports for both resident and non-
  resident/distance learning programs sent to higher headquarters or other entities outside of
  Air University.
     2.3.1. Centers should employ a deliberate data-supported review and decision process to
     make significant or substantive changes to the program. Decisions resulting from these
     deliberations and the results of actions taken should be documented and kept on file for
     five years to support reaffirmation of accreditation. The working group, board and
     council review process, used at HQ/AU, is the recommended model, however, other
     processes may be used if they engage key stakeholders in the decision process who are
     able to implement actions and measure results. If a school changes any program such that
     it significantly modifies its purpose or expands its scope, changes the nature of its
     affiliation or its ownership, or makes other changes such as those described in AUI 36-
     2317, Air University Degree Granting, Accreditation, Reaffirmation and Substantive
     Change, it constitutes a substantive change. The AU Academic Affairs office will work
     with the affected school to complete the appropriate notifications to external agencies
     prior to initiating action on the change. AU defines a significant change as one which
     requires additions, deletions or alterations (other than for editorial reasons) which may
     change more than half of the program outcomes, but does not change the nature or
     mission of the program, and does not meet the criteria for a substantive change. Because
     AU programs exist to meet Air Force and Joint Staff requirements, one can anticipate that
     significant and substantive changes will occur relatively rarely and as a response to major
     changes directed by those agencies.
     2.3.2. Faculty Qualifications. Schools/programs must identify the academic and/or
     experiential qualifications required to teach each course. Faculty member qualifications
     should be maintained in one of the AU faculty databases such as the SRIS/Faculty
     Qualification Matrix (FQM) or the enlisted faculty database, STARS-FD.
6                                                          AUI36-2312 16 NOVEMBER 2011


    2.4. Educational Support Services. Assessment of educational support services is
    conducted by designated staff responsible for each educational support program and/or key
    processes. If students use the services directly, learning outcomes should be established if
    appropriate. Critical/high visibility aspects of the program should be measured and evaluated
    to determine the value consumers receive and satisfaction with various aspects of service
    quality. Efficient and effective use of resources should also be measured. Assessment
    provides data to determine the extent to which desired outcomes are achieved and to inform
    decisions that support the unit’s mission. Educational support services should be measured at
    the HQ/AU level and also within the academic centers and 42 ABW as appropriate. Centers
    will determine appropriate assessment methods, decision processes and documentation for
    their programs.
       2.4.1. Educational support services not belonging to a center should employ a deliberate
       data-supported review and decision process to make continuous improvements to
       services. Decisions resulting from these deliberations should be documented and kept on
       file for five years.
    2.5. Administrative Support Services. Assessment of administrative support services is
    conducted by designated staff responsible for key administrative products and services.
    These should be examined to determine the value consumers receive and satisfaction with
    various aspects of service quality. Efficient and effective use of resources should also be
    measured. Assessment provides data to determine the extent to which desired outcomes are
    achieved and to inform decisions that support the unit’s mission. Administrative support
    services should be measured at the HQ/AU level and also within the academic centers and 42
    ABW as appropriate. Centers will determine appropriate assessment methods, decision
    processes and documentation for their programs.
       2.5.1. Administrative support services not belonging to a center should employ a
       deliberate data-supported review and decision process to make continuous improvements
       to services. Decisions resulting from these deliberations should be documented and kept
       on file for five years.
    2.6. Research. Assessment of the research mission of Air University is conducted by
    designated staff and administrators responsible for the research program IAW AUI 36-2321,
    Research and Publication. Assessment provides data to determine the extent to which
    desired outcomes are achieved and to inform decisions that support the unit’s mission. Goals
    and objectives of the program should be examined to determine mission accomplishment and
    the efficient and effective use of resources. The AU research mission is primarily undertaken
    by the Air Force Research Institute (AFRI) who acts as lead agent for program assessment.
    Faculty and students at the School of Advanced Air and Space Studies (SAASS), Air War
    College, Air Command and Staff College and the Air Force Culture and Language Center,
    contribute to the research mission.
       2.6.1. The research program employs a deliberate data-supported review and decision
       process to make significant or substantive changes. Decisions resulting from these
       deliberations should be documented and kept on file for five years. The working group,
       board and council structure used at HQ/AU is the recommended model for change
       decisions, however, other processes may be used if they engage key stakeholders in the
       decision process who are able to implement actions and measure results.
AUI36-2312 16 NOVEMBER 2011                                                                    7


   2.7. Community/Public Service Programs. Assessment of community and public services
   programs is conducted by designated staff and administrators responsible for each
   educational support program and/or key processes. Goals and objectives of the program
   should be examined to determine how effectively the mission is being accomplished.
   Efficient and effective use of resources should also be measured. Assessment provides data
   to determine the extent to which desired outcomes are achieved and to inform decisions that
   support the unit’s mission. Educational support services should be measured at the HQ/AU
   level and also within the academic centers as appropriate. Community and Public Service
   programs are primarily undertaken by the Holm Center’s Junior Reserve Officer Training
   Corps and Civil Air Patrol-USAF programs.
      2.7.1. Community/Public Service programs not participating in a center’s corporate
      process should employ a deliberate data-supported review and decision process to make
      significant or substantive changes to the program. Decisions resulting from these
      deliberations should be documented and kept on file for five years. The working group,
      board and council structure is used at HQ/AU and is the recommended model, however,
      other processes may be used if they engage key stakeholders in the decision process that
      are able to implement actions and measure results.
3. Assessment Programs
   3.1. Appointment of Assessment Point of Contact. Each academic center or AU service
   unit will designate by letter a primary and an alternate program assessment contact. The
   primary POC is responsible for ensuring an adequate assessment program is developed and
   executed for each educational program or service as defined in this instruction. The POC will
   provide current assessment plan and resulting data to AU/CFAE when requested and is the
   liaison for staff assistance visits.
      3.1.1. Provide a copy of the appointment letter to AU/CFAE upon assumption of
      responsibility
      3.1.2. The primary POC for each Academic Center is encouraged to participate in the Air
      University Institutional Effectiveness Working Group and attend formal meetings. All
      program assessment personnel are welcome to attend meetings and events planned by the
      group.
   3.2. Academic Program Assessment Plan
      3.2.1. Program Level Outcomes. All programs should define program level outcomes
      that are published in the AU Catalog. Three to five learning outcomes are usually
      sufficient, however, more may be pursued as faculty deem necessary. These outcomes
      must describe what a graduate is expected to know or be able to do, at a specified level of
      competency, after completing the program of study. This level of student outcomes
      should reflect the major objectives of the overall program rather than lesson or course
      objectives/goals. Outcomes should be observable and measurable. Other program level
      outcomes can be defined, measured and monitored as desired by senior educational
      administrators and faculty. Outcomes should logically align with the mission of the
      college/school.
      3.2.2. Assessment Methods. Faculty and program evaluators should collaborate on
      selecting appropriate assessment methods and designing data collection systems.
8                                                       AUI36-2312 16 NOVEMBER 2011


    Assessment programs should develop multiple sources of data to triangulate results in
    support of outcomes assessment. Both direct and indirect measures of learning should be
    implemented. Ensure sufficient and appropriate data are collected to determine the degree
    to which students have achieved program level outcomes and to inform formative and
    summative program decisions. Develop methodology/systems for collecting data and
    plan frequency of data collection. Develop metrics that include standards or targets for
    achievement for each program outcome. Aggregate individual student data to determine
    the extent to which expected outcomes are achieved at the program level. Document the
    method of calculation and data sources for each measure.
    3.2.3. Analysis. Compare actual data to program targets to determine the degree to
    which objectives were met. Data should be trended over time. Data and results should be
    discussed in a routine forum such as a staff meeting, production meeting, strategic
    planning meeting etc. Document a summary of important observations and decisions
    made at least annually. Minutes should include the date, names of the attendees, duty
    title, and duty section.
    3.2.4. Direct Measures of Learning. Direct measures must be used to assess learning at
    the level expressed in the outcome statements. Aggregate data across all students in a
    program during the academic year to determine curriculum and instruction strengths and
    areas needing improvement. Sampling may be used if appropriate methods are used to
    ensure the resulting data can be inferred to the population from which it is drawn. Direct
    measures include comprehensive multiple choice tests, essays, performance assessments,
    research papers, wargames, observation protocols etc. These assessments should result in
    individual student products such as answer sheets, written compositions, performance of
    skills, theses, oral presentations etc. from which a student’s achievement of learning
    outcomes can be directly assessed.
       3.2.4.1. Curriculum and Test Validation. New curriculum and tests should be
       evaluated for validity and reliability, particularly in cases where multiple seminars
       and multiple schools will be using the materials. Qualitative and quantitive data can
       be used. Statistical analyses on multiple choice test items such as point biserial
       correlation coefficent and difficulty index should be calculated. In accordance with
       the standard of practice in academe, whole test measures and other statistical
       descriptive measures and tests should be employed in the development of tests and
       inventories as appropriate to ensure validity and reliability of results.
       3.2.4.2. Test Compromise. When the security of a test has been compomised,
       particularly if it is required to determine satisfactory course completion or class
       standing/ranking, an appropriate investigation should be initiated immediately.
    3.2.5. Indirect Measures of Learning. Indirect measures indicate learning has occurred,
    but do not actually measure it. Indirect measures are encouraged to corroborate the data
    provided by direct measures, but cannot be used alone. They may include promotion rates
    of graduates versus non-graduates; job placement; and survey responses from students,
    graduates, supervisors of graduates, and other external stakeholders. Course grades are
    indirect measures of learning because they do not provide specific data on student
    achievement nor provide actionable data/vectors to inform program improvements.
AUI36-2312 16 NOVEMBER 2011                                                                   9


          3.2.5.1. Surveys. Surveys may be used to gather opinion data from students,
          graduates, supervisors of graduates and other external stakeholders. Students may be
          sampled to reduce survey fatigue. All surveys must be submitted to AU/CFAE to
          recieve a survey control number prior to administration or data collection IAW AUS-
          1 to AFI 38-501, Air Force Survey Program.
             3.2.5.1.1. Level of Confidence. Achieve a survey response rate that provides an
             appropriate level of confidence.”For short programs, data can be aggregated over
             all courses offered that academic year, using the annual student population in the
             calculation. Level of confidence data should be reported with survey results
             requested by HQ/AU CF.
             3.2.5.1.2. AU Survey Scale. Survey items that will be used in AU and higher
             headquarters reports such as Balanced Scorecard (BSC), will be gathered using
             the 6-pt scale described below. It is strongly recommended that this scale is used
             on all surveys due to the dynamic nature of BSC which results in data requests
             across the university for items that may be administered in program assessment
             surveys. Place Strongly Agree first and Strongly Disagree last. Each response
             should be offered in the order that it appears in Figure 3.1 below.

Figure 3.1. Preferred Response Order
 6-Strongly Agree
 5-Agree
 4-Slightly Agree
 3-Slightly Disagree
 2-Disagree
 1-Strongly Disagree
      3.2.6. Closed-loop Improvement Cycle. When indicated, determine actions needed to
      gain improvements in outcomes and document implementation plan. Use the closed-loop
      assessment cycle described below to document changes intended to improve the degree to
      which program outcomes are achieved. This is particularly important when actual
      outcomes fall short of targets/standards. Use all available sources of information to
      inform decisions for change.
          3.2.6.1. Outcome. Step 1) Identify expected program-level learning outcome being
          reviewed including its associated achievement target(s).
          3.2.6.2. Metric. Step 2) Document aggregated data gathered on measurement
          instruments employed to assess achievement of outcome. Include a summary of other
          pertinent information (faculty observations, survey comments, resource issues etc.).
          3.2.6.3. Analysis. Step 3) Analyze data, including the impact of other factors bearing
          on the outcome, to determine areas needing improvement and to inform action plan.
          3.2.6.4. Actions. Step 4) Document decisions/actions taken to improve outcomes
          achievement.
10                                                       AUI36-2312 16 NOVEMBER 2011


        3.2.6.5. Results. Step 5) After implementation of decisions has been completed and
        the process allowed to run for an appropriate amount of time, analyze data and assess
        results. This must be done at least annually and reported to AU/CFAE in the Annual
        Program Evaluation Report (Attachment 2). Documentation will be used as evidence
        of continuous compliance with SACS-COC Principles of Accreditation. Include
        trended data on outcome to show the difference, if any, made by actions taken in step
        four of this model. For program level student learning outcomes, trend data over the
        years.
     3.2.7. Other Program Improvement Documents. Program Assessment offices should
     maintain a list of reports/minutes the center/school develops to document program
     decisions, but do not have to maintain the reports themselves. These reports can come
     from working group, board and council meetings, academic council meetings, resource
     management meetings, curriculum team meetings, faculty meetings, executive staff
     meetings, hotwashes etc. Faculty participation in curriculum decisions should be
     demonstrated in at least one of the meeting minutes/reports. Formal meeting minutes
     should identify attendees. Provide examples of documentation during annual CFA staff
     assistance visit.
     3.2.8. Faculty Evaluation. The primary focus for faculty evaluation is to provide
     diagnostic feedback to faculty members to enhance their professional growth and
     development. A secondary focus is to assess faculty member performance. Develop a
     faculty evaluation plan or instruction. Cite the instruction, add the plan as an attachment
     to the academic Program Assessment Plan, or identify its elements within the body of the
     program assessment plan. Identify who is resposible for conducting, documenting and
     storing faculty evaluations.
        3.2.8.1. A list of general teaching competencies or performance expectations should
        be provided to the faculty member/instructor upon hiring or during orientation to the
        program.
        3.2.8.2. Faculty members should be evaluated periodically against published criteria.
        AETC Form 620, Academic Instructor Monitoring Checklist, and AU Form 13,
        Period Evaluation, are commonly used to document instructional performance,
        however other forms may be developed to satisfy the unique requirements of the
        program. This instruction serves as the requirement to maintain form AU Form 13 for
        schools who prefer to use it.
        3.2.8.3. Faculty members should receive student feedback after course grades are
        assigned.
  3.3. Annual Program Assessment Report. Use the format at Attachment 2 to complete the
  Annual Program Assessment Report. It should contain important and/or representative
  improvement decisions rather than an exhaustive accounting of all formative actions. It
  provides a useful summary of program assessment information for the academic year and
  evidence of how programs improve outcomes.
     3.3.1. Reporting Cycle. Forward a copy of the Annual Program Assessment Report to
     AU Institutional Effectiveness office (AU/CFAE) no later than 31 December. All
AUI36-2312 16 NOVEMBER 2011                                                                 11


     programs should report findings from the previous academic year using available data.
     The report should be maintained on file at each program assessment office.
         3.3.1.1. Forward a copy of the program assessment plan used for the reporting
         period.
         3.3.1.2. Upon publication, provide AU/CFAE a copy, or access to the site, of
         instructions/supplements concerning faculty evaluation, test control procedures,
         student grievance procedures, student assessment and grading guidelines, award
         programs, and internal and external assessment programs. Include policies on
         research and public service/outreach if applicable.
         3.3.1.3. Strategic Planning/Balanced Scorecard Data. Describe how the
         center/college/school collects and uses data related to the AU and/or center/college
         strategic plans and Balanced Scorecards; identify who analyses the data and who
         reports the results and decisions/actions; and identify where documentation of data
         and reports are kept. Program evaluators should include the use of information
         relevant to program assessment in the Annual Program Assessment Report.
  3.4. Educational       and   Administrative       Support       Services,   Research     and
  Community/Public Service Programs. Each unit should have a written mission statement
  and internal goals and/or objectives that promote mission accomplishment and achievement
  of strategic goals. Alignment of unit strategic objectives to the AU Strategic Plan should be
  evident.
     3.4.1. Program Assessment. Develop methods of measurement and criteria/targets for
     success. Measurement methods must provide actionable data that can be used to compare
     the current state to the desired end-state. It should used to inform leadership and
     management decisions. The measure statement clearly defines how the metric is
     calculated and the format in which the results are consistently reported.
     3.4.2. Outcomes. Unit goals and/or objectives must be clearly defined and written in a
     way that lend themselves to measurement. Key processes and/or enduring objectives
     should be monitored. If more than four measures are identified, the unit may opt to
     employ a rotational basis for assessment and reporting. Measures should be assessed at
     least biennially.
     3.4.3. Assessment Cycle. Define the data collection and analysis period for each
     objective and supporting metric.
         3.4.3.1. Measurement/Data Collection. Determine what kind of data will be needed
         to measure achievement of program-level objectives. Develop methodology/systems
         for collecting data and frequency of data collection.
         3.4.3.2. Analysis. Compare actual data to program targets to determine the degree to
         which objectives were met. Data and results should be discussed in a routine forum
         such as a staff meeting, production meeting, strategic planning meeting etc.
         Document a summary of important observations and decisions made at least annually.
         Minutes should include the date, names of the attendees, duty title, and duty section.
         3.4.3.3. Improvement Decisions. When indicated, design             actions   to   gain
         improvements in outcomes and document implementation plan.
12                                                       AUI36-2312 16 NOVEMBER 2011


         3.4.3.4. Results. After implementation of decisions has been completed and the
         process allowed to run for an appropriate amount of time, analyze data and assess
         results. This must be done at least annually.
         3.4.3.5. Documentation. Document outcomes, effectiveness and overall impact on
         program outcomes/program improvment. Maintain documentation for ten years as it
         provides evidence of compliance with standards and will be used to support
         reaffirmation of accreditation.
     3.4.4. Annual Report. Use the format at Attachment 2 to complete the Annual Program
     Assessment Report. It should contain important and/or representative cases rather than an
     exhaustive accounting of all improvements. It provides a useful summary of program
     assessment information for the academic/fiscal year and evidence of how programs
     improve outcomes.
  3.5. Other Assessments. Units undertake periodic evaluations such as annual self
  inspections, evaluation of progress on strategic objectives, triennial Operational Readiness
  Inspections, accrediation self studies etc. which are valuable sources of information on how
  well the unit accomplishes its mission. These can be used as supporting documentation for
  how well goals and objectives are achieved.
     3.5.1. Document progress toward accomplishment of internal goals and strategic
     objectives. Provide a copy of this report to AU/CFAE annually in December for the
     previous academic year. This can be in the form of existing documentation of Annual
     Improvement Plan actions maintained on the AETC Process Improvement Office
     Sharepoint site at https://eis.aetc.af.mil/hq/cc/AFSO21/default.aspx and/or Balanced
     Scorecard status initiative slides on the AU BSC SharePoint at
     https://maxpoint.maxwell.af.mil/sites/au/xp/xpr/bsc/default.aspx as evidence of
     accomplishment of strategic goals and objectives. However, itshould include narrative to
     explain the process, dates changes were made to the process and the outcome of the
     changes.
     3.5.2. Efficiency analysis. Efficiency analysis is continuous and inherent in AU’s
     strategy management and AFSO 21 processes. Document efficiency improvements using
     the existing AF and AU Balanced Scorecard and Measures of Performance reporting
     processes. Areas for potential improvement may include the impact of the organizational
     structure. Where feasible and desirable, units should measure productivity relative to
     inputs of human and material resources. Analyze the impact of the organizational
     structure, business processes, policies, budget, staffing, training/development and
     communications on program performance. Document decisions and results. Report
     savings and/or more efficient use of: time, scheduling, physical and personnel resources,
     travel, operational funds and other monetary inputs, resource sharing etc. resulting in
     more effective student production, instructional delivery and learning, faculty research,
     personnel retention/development, administrative and educational support services,
     outreach activities or support services. Include results to program in Annual Program
     Evalution Report as appropriate. The AFSO21 process may be used to guide these
     studies/initiatives.
AUI36-2312 16 NOVEMBER 2011                                              13




                              DAVID S. FADOK, Lieutenant General, USAF
                              Commander, Air University
 14                                                        AUI36-2312 16 NOVEMBER 2011


                                      ATTACHMENT 1
         GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION

References
32 CFR 219, Protection of Human Subjects
AFMAN 36-2234, Instructional System Development, 1 November 1993
AFI 36-2301, Developmental Education, 16 July 2010
AFI 38-501, Air Force Survey Program, 12 May 2010
AFI 40-402 Protection of Human Subjects in Biomedical and Behavioral Research, 5 May 2005
AETCI 90-1101 Strategy Management, 16 November 2009
AUI 36-105, Responsibilities for Faculty Development and Enrichment, 9 February 2009
AUI 36-2303, Recognition of Outstanding Student Achievement, 21 December 1995
AUI 36-2309, Academic Integrity, 22 August 2008
AUI 36-2317, Air Univeristy Degree Granting, Accreditation, Reaffirmation and Substantive
Change, 5 July 2006
AUI 36-2321, Research and Publication, 24 July 2006
AUI 36-2322, Air University Institutional Effectiveness and Institutional Research, 22 October
2003
Southern Association of Colleges and Schools’ Commission on Colleges Principles of
Accreditation: Foundations for Quality Enhancement, 2010 Edition
Prescribed Forms
AU Form 13, Period Evaluation, 23 March 2007
Adopted Forms
AF Form 847, Recommendation for Change of Publication, 1 April 2010
AETC Form 620, Academic Instructor Monitoring Checklist, 31 October 2006

Abbreviations and Acronyms
AETC—Air Education and Training Command
AFIT—Air Force Institute of Technology
AU—Air University
AU/CC—Air University Commander/President
AU/CFAE—Academic Affairs Office of Institutional Effectiveness
BSC—Balanced Scorecard
SACS—COC—Souther Association of Colleges and Schools Commission on Colleges
USAFA—United States Air Force Academy
AUI36-2312 16 NOVEMBER 2011                                                                     15


Terms
Accreditation—Air University is regionally accredited though the Southern Association of
Colleges and Schools Commission on Colleges (SACS-COC) and follows the SACS-COC
Principles of Accredition guidelines for program assessment. The Air Force Institute of
Technology is regionally accredited through the North Central Association Higher Learning
Commission (HLC) and follows HLC guidelines for program assessment.
Specialized Accreditation. Programs within the institution may have accreditation with
professional organizations.
Accreditation Board for Engineering and Technology (ABET). AFIT has earned specialized
accreditation for their engineering program through ABET.
Process for Accreditation of Joint Education (PAJE). ACSC and AWC confer Joint PME I and
Joint PME II credit respectively for selected programs by virtue of accreditation awarded by the
Chairman, Joint Chiefs of Staff through the PAJE process.
Administrative Support Services—Administrative support services are units that support
university processes and educational program administration and delivery through services to
leaders, administrators, faculty, students and staff at Air University. Examples include Academic
Office, Financial Management, Office of the Registrar, Plans and Programs, Protocol, Public
Affairs, Education Logistics and Communications Directorate, and Manpower and Personnel.
Assessment—For the purpose of this instruction, AU defines assessment as a multi-step process
examining the quality and productivity of educational activities.
Community/Public Service Program—Community and Public Service programs that fit within
the educational mission of Air University. Examples include Air Force Junior Reserve Officer
Training Corps (JROTC) and Civil Air Patrol-USAF (CAP-USAF).
Educational Programs—Any educational program, developed by faculty as defined in 1.8 of
this instruction, that awards a degree, diploma, certificate or certification is considered to be a
program and is subject to the assessment requirements herein.
Educational Support Services—Educational support services are units that support teaching,
learning and research through services to students, faculty, administrators and staff assigned to
education and training programs. Examples include the Muir S. Fairchild Research and
Information Center, Extension Course Program, Air University Press, Enlisted Heritage
Research Institute and the Air University Office of History.
Student Support Services. Units that provide support services to students to enhance the quality
and accessibility of their educational experience are considered Student Support Services.
Examples include Child Development Center, Housing Office, International Affairs, Public
Affairs Center of Excellence, Law Center, Personnel Office and Inspector General.
Evaluation—For the purpose of this instruction, AU defines evaluation as a discrete step in the
assessment process where the results of some measurement are compared to a standard of
performance.
Faculty—Faculty are defined as those with relevant academic credentials and/or experience
which qualifies them to offer the courses to which they are assigned, and who fulfill some or all
of the following functions: course design and curriculum development; program assessment
including identification and assessment of student learning outcomes; teaching; academic
 16                                                        AUI36-2312 16 NOVEMBER 2011


advising; research, authorship and presentation; and service to the institution. Schools identify
their faculty members and evaluate, document and monitor their qualifications.
Institution—References to the ‘institution’ refer to Air University as a whole and not to an
academic center, college, school or support unit.
Academic Centers include Spaatz Center, LeMay Center, Holm Center, Eaker Center and Barnes
Center.
Air Force Institute of Technology (AFIT), maintaining separate regional accreditation by the
Higher Learning Commission of the North Central Association of Colleges and Schools, is also
considered to be an institution for the purposes of its accreditation.
AUI36-2312 16 NOVEMBER 2011                          17


                              Attachment 2
           ANNUAL PROGRAM ASSESSMENT REPORT FORMAT
 18                                                      AUI36-2312 16 NOVEMBER 2011


                                       Attachment 3
        HQ/AU INSTITUTIONAL EFFECTIVENESS OFFICE (HQ/AU CFAE)

 ANNUAL STAFF ASSISTANCE VISIT CHECKLIST

      SECTION A: ACADEMIC ASSESSMENT PROGRAM                            YES   NO   N/A
      ADMINISTRATION


A1.
      Does the college/school have a POC for assessment appointed
      by letter?

      AUI 36-2312 Para 3.1. requires units to designate a POC for AU
      assessment programs and forward the letter to HQ/AU CFAE

      AUI 36-2322, Para 5.6.1. Points of Contact Appointment. Each
      educational program and administrative or educational support
      activity must designate, by letter of appointment, primary and
      alternate points of contact (POC) to serve as assessment POCs.
      These individuals will work closely with the HQ AU Chief,
      Institutional Effectiveness on assessment issues. POCs serve as
      liaisons between HQ AU and their respective programs.


A2.
      Does the college/school have an assessment plan that complies
      with guidance found in AUI 36-2312? Does it identify program-
      level student outcomes; service/program outcomes and/or
      goals; and the effectiveness/efficiency at producing desired
      outcomes? Where are learning outcomes or service/program
      goals published?

      AUI 36-2312, Para 3.2. and all subparagraphs. The assessment
      plan will be composed of the following applicable materials:
             3.2.1. Describes/lists student learning outcomes at the
             program level. These should be enduring so trend data
             can be collected over years. They should match the
             outcomes in the AU Catalog or other designated
             publications.

             3.2.2. Describes methods, procedures and timelines for
             evaluating the degree to which learning outcomes were
             achieved.
AUI36-2312 16 NOVEMBER 2011                                             19


             3.2.4. Contains direct measures of learning.

             3.2.5.1. Surveys conform to guidance in AUS1 to AFI 38-
             501.

             3.2.6 Closed-loop Improvement Cycle is used to
             document actions that address missed targets on
             program-level outcomes.


A3.
      Was Annual Program Assessment Report completed as required
      and submitted on time?

      AUI 36-2312, Para 3.3

A4.
      Is faculty involved in the development of the assessment plan
      and in assessment activities?

      AUI 36-2312, Para 3.2.2.

A5.
      Does the center/school use a deliberate review and decision
      process (such as that defined in AETCI 16-501, Corporate
      Structure) to make substantive or significant changes to the
      program? If not, describe the process. Does the body meet
      periodically? Is the process systematically employed for key
      decisions? Is there a policy document describing this process?
      Are attendees and decisions documented? Where are the
      minutes maintained?

      AUI 36-2312, Para 2.2.1.

A6.
      Has AU/CFAE been provided a copy of the most current
      academic assessment plan?

      AUI 36-2312, para 3.1. The POC will provide current
      assessment plan and resulting data to AU/CFAE when requested
      and is the liaison for staff assistance visits.


A7.
      Does the center/school provide training on assessment issues to
      the faculty/instructors?

      AUI 36-105, Para 3.5.1. states “Faculty orientation serves as a
      pre-service program, properly orienting and preparing new
 20                                                         AUI36-2312 16 NOVEMBER 2011


       faculty as to the respective school’s mission, organization,
       facilities, purpose, expectations, teaching philosophies,
       curriculum, teaching requirements, and if required, teaching
       mentoring and evaluative skills…”

A8.
       Has AU/CFAE been provided a copy of the center’s Strategic
       Plan and strategy management plan?

       AUI 36-2312, Para 3.5.

A9.
       Is the academic assessment plan linked to the AU Strategic Plan
       and the center’s strategic plan and strategy management
       methodology?

       AUI 36-2322, Para 5.6.2. Unit Mission Statements and Planning
       Documents. Each school or college and educational support unit
       is required to develop, publish, disseminate, and maintain unit-
       level mission statements and planning documents that reflect
       objectives and measures clearly linked to the AU planning
       documents.

A10.
       Is data on strategic objectives routinely collected, analyzed and
       used for improvement? If a strategy management methodology
       such as Balanced Scorecard is used to implement strategic
       objectives, refer to location of documents.
       AUI 36-2312 Para 3.5.1

       SECTION B: STUDENT ASSESSMENT PROGRAM                               YES   NO   N/A


B1.
       Does the program directly evaluate students to determine the
       degree to which learning has been achieved?

       AUI 36-2312, Para 3.2.4. Direct measures must be used to assess
       learning at the level expressed in the outcome statements.

B2.
       Does the program employ indirect measures to triangulate data
       when assessing student learning outcomes? How is the data
       used? Are changes to the tests or curriculum documented?

       AUI 35-2312, Para 3.2.5. Indirect measures are encouraged to
       corroborate the data provided by direct measures, but cannot be
       used alone. They may include promotion rates of graduates
       versus non-graduates; job placement; and survey responses
AUI36-2312 16 NOVEMBER 2011                                                              21


      from students, graduates, supervisors of graduates, and other
      external stakeholders. Course grades are indirect measures of
      learning because they do not provide specific data on student
      achievement nor provide actionable data/vectors to inform
      program improvements.

      SECTION C: DATA ANALYSIS AND SURVEY PROGRAM                       YES   NO   N/A


C1.
      Does the program have a documented data collection process
      developed for its assessment program?

      AUI 36-2312, Para 3.2.2. Develop methodology/systems for
      collecting data and plan frequency of data collection. Develop
      metrics that include standards or targets for achievement for
      each program outcome. Aggregate individual student data to
      determine the extent to which expected outcomes are achieved at
      the program level. Document the method of calculation and data
      sources for each measure.


C2.
      Does the school follow guidelines established in AUS-1 to AFI
      38-501, Air Force Survey Program, to obtain survey control
      numbers as needed?

      AUS-1 to AFI 38-501

C3.
      Are guidelines for obtaining an appropriate level of confidence
      followed and reported with survey results? Is the return rate
      reported with results?

      AUI 36-2312, Para, 3.2.5.1.1.

C4.
      Do students have an opportunity to submit feedback on the
      execution and effectiveness of the curriculum and instruction?

      AUI 36-2312, Para 3.2.51. Surveys may be used to gather
      opinion data from students, graduates, supervisors of graduates
      and other external stakeholders. Students may be sampled to
      reduce survey fatigue.


C5.
      Does the school conduct analyses to validate tests and
      curriculum using guidelines suggested in AUI 36-2312?
 22                                                         AUI36-2312 16 NOVEMBER 2011


      AUI 36-2312, Para 3.2.4.1.

C6.
      Does the school/program have a “closed loop” process
      developed for its assessment program?

      AUI 36-2322, Para 5.6.4.“Closed-Loop” Documentation. In
      addition to documenting measures, findings, and use of results
      for goals and objectives, educational programs are required to
      ensure “closed-loop” documentation of the use of assessment
      data in curriculum review and other IE processes. School and
      college-level operating instructions must include a requirement
      for the documentation of the use of assessment data in
      curriculum review and program assessment processes.
      AUI 36-2312, Para 3.2.6. Closed-loop Improvement Cycle.

      SECTION D: TEST DEVELOPMENT, CONTROL &                                YES   NO   N/A
      ADMINISTRATION

      Does the college/school immediately initiate an appropriate
D1.
      investigation in the case of test compromise?

      AUI 36-2312 Para, 3.2.4.2

D2.
      Does the program develop validation plans for new curriculum
      and tests? Are the validation plans and results of the validation
      process documented?

      AUI 36-2312 Para, 3.2.4.1

      SECTION E: FACULTY EVALUATION PROGRAM                                 YES   NO   N/A


E1.
      Does the college/school have a faculty evaluation plan in place?

      AUI 36-2312 Para 3.2.8. Faculty Evaluation. The primary focus
      for faculty evaluation is to provide diagnostic feedback to faculty
      members to enhance their professional growth and
      development. A secondary focus is to assess faculty member
      performance. Develop a faculty evaluation plan or instruction.

E2.
      Do faculty members receive student feedback?

      AUI 36-2312 Para 3.2.8.3.

E3.
AUI36-2312 16 NOVEMBER 2011                                                               23


      Does the school/center publish a master list of expected
      teaching competencies or performance expectations? Are these
      provided to faculty members prior to teaching?

      AUI 36-2312 Para 3.2.8.1

E4.
      Has the school/program published faculty qualifications
      required for teaching each course?

      AUI 36-2312 Para 2.2.2. Schools/programs must identify the
      academic and/or experiential qualifications required to teach a
      course. Faculty members’ qualifications should be tracked in one
      of the AU faculty databases such as the SRIS/Faculty
      Qualification Matrix (FQM) or the enlisted faculty database,
      STARS-FD.

E5.
      Has the college/school documented faculty qualifications for all
      faculty members? (Preferably in the on-line AU Faculty
      Qualification Matrix in SRIS for Maxwell campus faculty or
      STARS-FD for Barnes Center/CCAF instructors)

      AUI 36-2312 Para 2.2.2. and AUI 36-105, Para 3.4.

E6.
      Do supervisors/evaluators provide faculty/instructors written
      feedback that is directed at improving teaching effectiveness?

      AUI 36-2312 Para 3.2.8.2

      SECTION F: FACULTY PROFESSIONAL DEVELOPMENT                        YES   NO   N/A


F1.
      Does the school/center have a Faculty Professional
      Development POC identified by an appointment letter?

      AUI 36-105, Para 3.1. To fulfill this requirement, each school
      and college will develop a supplement to this instruction and
      will designate by an official appointment letter the faculty
      member responsible for the oversight of its faculty development
      and enrichment program. Schools and colleges will provide a
      copy of this letter to AU/CFAE

F2.
      Does the school/center have a supplement/OI to AUI 36-105,
      Faculty Development, Enrichment and Responsibilities?
 24                                                        AUI36-2312 16 NOVEMBER 2011


      AUI 36-105, Para 3.1. To fulfill this requirement, each school
      and college will develop a supplement to this instruction and
      will designate by an official appointment letter the faculty
      member responsible for the oversight of its faculty development
      and enrichment program.

F3.
      Does the center/school have a process for maintaining faculty
      folders (whether online or paper)?

      AUI 36-105, Para 3.4. AU schools and colleges will create
      mechanisms to track the development and accomplishment of
      individual professional growth programs of their faculty
      members.

F4.
      Does the center/school properly maintain faculty/instructor
      information and degree status?

      AUI 36-105, Para 3.4. AU schools and colleges will create
      mechanisms to track the development and accomplishment of
      individual professional growth programs of their faculty
      members.

F5.
      Does the center/school have an In-Service Training (IST)
      program established?

      AUI 36-105, Para 3.5. Faculty programs: Air University schools
      and colleges will develop and administer internal faculty growth
      programs. There shall be three primary faculty growth
      programs: faculty orientation, faculty development via in-
      service training (IST), and individual-focused professional
      development. Faculty programs will be described in each
      college and school’s Program Review Board (PRB) presentation.

F6.
      Does the center/school maintain an IST Log or summary to
      record/document attendance at IST sessions?

      Not explicitly required by an AUI but is a good operating
      practice.

      SECTION G: AWARDS PROGRAM


G1.
      Is the college/school authorized to have a DG program?
AUI36-2312 16 NOVEMBER 2011                                                              25



      AUI 36-2303, para 2

G2.
      Does the college/school have an achievement awards program?

      AUI 36-2303. This instruction establishes policies and
      procedures designed to give recognition to outstanding student
      achievement in Air University schools.

G3.
      Do the criteria used by the college/school to designate DG or
      award status encompass academic scores, professional skills,
      and or performance skills (where applicable)?

      AUI 36-2303, para 2.1.

G4.
      Does the college/school only present Distinguished Graduate
      Awards to the top 10 percent of the class?

      AUI 36-2303, para 2.

G5.
      Does the college/school make maximum use of awards such as
      certificates, citations, and scrolls, as well as letters of
      commendation for outstanding achievement in the areas of
      skills, knowledge, and understanding?

      AUI 36-2303, para 5.2.

      SECTION H: ASSESSMENT OF ACADEMIC AND EDUCATIONAL                 YES   NO   N/A
      SUPPORT SERVICE PROGRAMS AND COMMUNITY/PUBLIC
      SERVICE AND RESEARCH PROGRAMS


H1.
      Does the program have an assessment plan, instruction or
      written guidance for evaluating effectiveness?

      AUI 36-2312 para 3.4.1.

H2.
      Are goals and/or objectives aligned to strategic objectives for
      the unit and/or higher headquarters?

      AUI 36-2312 para 3.4.

H3.
      Are program level outcomes identified and monitored?
 26                                                       AUI36-2312 16 NOVEMBER 2011


      AUI 36-2312 para 3.4.2.

H4.
      Does the unit follow a deliberate cycle of assessment?

      AUI 36-2312 para 3.4.3.

H5.
      Was Annual Program Assessment Report completed as required
      and submitted on time?

      AUI 36-2312, Para 3.4.4.
