BY ORDER OF THE COMMANDER                                        AETC INSTRUCTION 36-2640
AIR EDUCATION AND TRAINING
COMMAND                                                                            15 JULY 2014

                                                                                        Personnel

                                                         TECHNICAL AND BASIC MILITARY
                                                                 TRAINING EVALUATION


              COMPLIANCE WITH THIS PUBLICATION IS MANDATORY

ACCESSIBILITY: Publications and forms are available for downloading or ordering on the e-
               Publishing website at www.e-Publishing.af.mil.

RELEASABILITY: There are no releasability restrictions on this publication.

OPR: HQ AETC/A3PV                                       Certified by: HQ AETC/A3P (Ms. Bonnie
                                                                                   E. Molina)
Supersedes:    AETCI 36-2201, 13                                                    Pages: 46
               September 2010


This instruction implements AFPD 36-26, Total Force Development.                   It establishes
responsibilities and procedures for evaluating the quality of technical and basic military training
(BMT). It applies to the Inter-American Air Force Academy (IAAFA), Air Force Reserve
Command (AFRC), Air National Guard (ANG), technical training administered by Air
University (AU) Eaker Center, and training groups (TRG) aligned under the Second Air Force (2
AF) involved in managing, developing, and conducting BMT and technical training within
AETC. Due to unique mission requirements, it does not apply to the 517 TRG or Defense
Language Institute English Language Center (DLIELC). It applies to the 937 TRG, IAAFA, and
737 TRG (Basic Military Training (BMT)) as noted in applicable paragraphs.

This instruction requires collecting and maintaining information protected by the Privacy Act of
1974 authorized by Title 10, United States Code, Section 8013. System of Records notice F036
AF PC Q, Personnel Data System, applies. Ensure that all records created as a result of
processes prescribed in this publication are maintained in accordance with (IAW) Air Force
Manual (AFMAN) 33-363, Management of Records, and disposed of IAW Air Force Records
Disposition Schedule (RDS) located in the Air Force Records Information Management System
(AFRIMS). The use of the name or mark of any specific manufacturer, commercial product,
commodity, or service in this publication does not imply endorsement by the Air Force.

This AETCI may be supplemented by commanders responsible for implementing this
instruction. Supplements will be used to establish organization-specific guidance. (T-2) Do not
use local operating instructions to implement this guidance. (T-2) Commanders will send
 2                                                                                             AETCI36-2640 15 JULY 2014


proposed supplements through their training group or wing and 2 AF (2 AF units only) to HQ
AETC/A3P for review and coordination prior to publishing. (T-2)

Refer recommended changes and questions about this publication to the Office of Primary
Responsibility (OPR) using the AF Form 847, Recommendation for Change of Publication.
Route AF Forms 847 from the field unit through the training group, training wing and 2 AF (2
AF units only) to HQ AETC/A3P.

The authorities to waive wing/unit level requirements in this publication are identified with a
Tier ("T-0, T-1, T-2, T-3") number following the compliance statement. See AFI 33-360,
Publications and Forms Management, for a description of the authorities associated with the Tier
numbers. Unless otherwise specified, requests for waiver must be submitted by the group or
wing commander through 2 AF (2 AF units only) to HQ AETC/A3P. (See paragraph 1.2 for
specific procedures.) T-2

See Attachment 1 for a glossary of references and supporting information used in this
publication.

SUMMARY OF CHANGES

This document has been substantially revised and must be completely reviewed. This
revision updates the publication number to align it under the antecedent AFPD 36-26, Total
Force Development. Major changes include incorporating required tiering and reformatting
IAW AFI 33-360; specifying application to the 937 TRG; changing the requirements for
technical training groups’ to prepare and submit a semiannual Type 6, Distance Learning (DL)
Student Feedback Report and a separate Semiannual Trend Analysis Report to the requirement to
submit one report, the fiscal year (FY) Semiannual Evaluation Summary Report; adding
requirements for BMT to administer the RAND BMT Abuse and Misconduct Survey and
conduct the RAND Military Training Instructor (MTI) Survey or other HQ AETC approved
survey instrument(s); discontinuing the graduate assessment survey (GAS) and adding
standardized questions from the GAS to field evaluation questionnaires (FEQ) administered to
supervisors of non-prior service (NPS) AF enlisted and officer initial skills course graduates;
increasing administration of field evaluations of enlisted and officer initial skills courses from
biennially to annually; changing approval authority to grant exceptions to the annual field
evaluation requirement to 2 AF; updating the format for the field evaluation questionnaire
summary (FEQS); and updating Training Assessment Program requirements to support
implementation of the new Air Force Inspection System.

       1.      Overview. ...............................................................................................................   3
       2.      Roles and Responsibilities: ....................................................................................            4
       3.      Training Evaluation Program (TEP). .....................................................................                    6
       4.      Internal Evaluation. ................................................................................................       6
       5.      External Evaluation. ...............................................................................................        9
AETCI36-2640 15 JULY 2014                                                                                                                  3


      6.       Technical Training Group TA Program/BMT Standardization/Evaluation
               (Stan/Eval). ............................................................................................................   14
      7.       Interservice Training. .............................................................................................        16
      8.       Use of Training Evaluation Data. ..........................................................................                 16
      9.       Trend Analysis. ......................................................................................................      16

Attachment 1—GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION                                                                             18

Attachment 2—SAMPLE IN-RESIDENCE TRAINING END-OF-COURSE STUDENT
             FEEDBACK SURVEY                                                                                                               21

Attachment 3—SAMPLE TYPE 6, DL END-OF-COURSE FEEDBACK                                                                                      24

Attachment 4—SAMPLE FY SEMIANNUAL EVALUATION SUMMARY REPORT XX
             TRAINING GROUP FY SEMIANNUAL EVALUATIONSUMMARY
             REPORT 20XX                                                                                                                   26

Attachment 5—TYPE 6 STUDENT FEEDBACK QUESTIONNAIRE DATA                                                                                    29

Attachment 6—SAMPLE FIELD INTERVIEW (FI) GUIDES (FOR GRADUATES AND
             SUPERVISORS)                                                                                                                  31

Attachment 7—SAMPLE CUSTOMER SERVICE INFORMATION PROCESS (CSIP)
             TEMPLATE                                                                                                                      35

Attachment 8—FIELD EVALUATION QUESTIONNAIRE DEVELOPMENT                                                                                    36

Attachment 9—FORMAT FOR FIELD EVALUATION QUESTIONNAIRE SUMMARY
             (FEQS)                                                                                                                        44


1. Overview.
   1.1. Purpose. This publication establishes guidance and procedures for administering
   training evaluation for technical and basic military training (BMT). Training evaluation
   provides the basis for determining the quality of training. Evaluations are conducted as a part
   of the Instructional System Development process to examine the effectiveness and efficiency
   of the training program. Refer to AFI 36-2201, Air Force Training Program, AFMAN 36-
   2234, Instructional System Development, and AFH 36-2235, Volume 9, Information for
   Designers of Instructional Systems: Application to Technical Training, and Volume 13,
   Information for Designers of Instructional Systems for Basic Military Training (BMT) for
   additional guidance.
   1.2. Waiver Authority. Policy and procedures are enacted to provide quality and consistency
   in training and evaluation. Occasionally, unique circumstances may warrant special
   consideration and possible waiver of policy provisions. At the same time, because it is
   important to preserve fidelity of training, evaluation, and policy implementation throughout
   the command, a process must be established for review of proposed waivers.
 4                                                                AETCI36-2640 15 JULY 2014


        1.2.1. Unless otherwise stated in this instruction, AETC/A3P is the waiver authority for
        waivers that change the intent of the policy outlined in this instruction. (T-2) For waivers
        to unit supplements, the unit generating the supplement will identify the waiver authority
        to that supplemental guidance.
        1.2.2. Requests for waiver will be submitted through the group or wing commander and
        2 AF (2 AF units only) to HQ AETC/A3P. (T-2) Waiver requests must:
           1.2.2.1. Identify the specific policy reference and text to be waived.
           1.2.2.2. Rationale for the waiver: Explain which of the 3 reasons listed under AFI
           33-360, paragraph 1.9.1 apply and describe why.
           1.2.2.3. Time period or circumstance for which the waiver will be required.
           1.2.2.4. Risk mitigation measures the requesting commander will implement during
           the waiver period.
           1.2.2.5. Impact if waiver is disapproved.
        1.2.3. Units will upload approved waivers into Management Internal Control Toolset
        (MICT) for inspection activity review. Because waivers are the expression of a specific
        commander accepting risk, Tier 1, 2, and 3 waivers expire 30 days after a change of
        command unless the new commander renews the waiver. For non-tiered waivers, a
        waiver remains in effect until canceled in writing by the approving official, the
        publication is revised, or the waiver expires.
2. Roles and Responsibilities:
     2.1. HQ AETC/A2/3/10 will set policy, review and coordinate on implementing
     supplements, evaluate waivers for approval or disapproval, and help resolve training
     evaluation questions.
     2.2. HQ AETC/A2/3/10 Training Pipeline Manager (TPM), as applicable, will:
        2.2.1. Review FEQs prior to administration, request inputs on FEQs from the Air Force
        Career Field Manager (AFCFM), and provide feedback to the training wing/group.
        2.2.2. Review Field Evaluation Questionnaire Summaries (FEQS), BMT Survey
        Reports, and 2 AF fiscal year (FY) Semiannual Evaluation Summary Reports, as
        applicable. If exception is taken to findings, conclusions, or actions, notify 2 AF/TTOC
        and the applicable training wing/group and cite rationale for exception.
     2.3. HQ AETC/SAS-TSS will:
        2.3.1. House the data and the interface for the RAND BMT Abuse and Misconduct
        Survey and RAND MTI Survey (MTI Climate Survey), or other HQ AETC approved
        survey instrument(s)
        2.3.2. Maintain trainee and MTI anonymity; by ensuring the software/system
        configuration does not collect trainees’ personally identifiable information from the
        RAND BMT Abuse and Misconduct Survey and the RAND MTI (Climate) Survey, or
        other HQ AETC approved survey instrument(s).
     2.4. HQ AETC/A3-OAD will:
AETCI36-2640 15 JULY 2014                                                                    5


     2.4.1. Compile and analyze data from the RAND BMT Abuse and Misconduct Survey
     and RAND MTI (Climate) Survey, or other HQ AETC approved survey instrument(s).
     2.4.2. Provide results quarterly on the RAND BMT Abuse and Misconduct Survey or
     other HQ AETC approved survey instrument(s) to the Recruiting, Education and Training
     Oversight Council (RETOC).
     2.4.3. Provide a semi-annual update on the RAND MTI (Climate) Survey or other HQ
     AETC approved survey instrument(s) to the RETOC.
     2.4.4. Submit the results from both surveys or other HQ AETC approved survey
     instrument(s) to HQ AETC/A2/3/10, 2 AF, and the 37 TRW.
  2.5. Headquarters Second Air Force Technical Training Operations Center (2 AF/TTOC)
  will:
     2.5.1. Monitor subordinate training wing/group training evaluation programs for
     effectiveness and provide crossfeed of information between wings.
     2.5.2. Approve exceptions to the requirement for an annual field evaluation.
     2.5.3. Conduct a FY semiannual trend analysis. Prepare and distribute a FY Semiannual
     Evaluation Summary Report to HQ AETC/A3T, training wing and training group
     commanders with a courtesy copy to HQ AETC/A3P.
     2.5.4. Extract graduate data from Oracle Training Administrator (OTA) and forward to
     training groups monthly.
     2.5.5. Maintain a list of all FEQ eligible courses and last completed FEQS date.
     2.5.6. Route requests for software production support pertaining to training evaluations
     software other than Technical Training Management System (TTMS) to HQ AETC/A3P.
     2.5.7. Maintain the AETC TT and BMT Evaluations site.
  2.6. Training groups will:
     2.6.1. Establish a Training Evaluation Program (TEP) as required in this instruction to
     ensure all assigned courses provide quality training in an effective and efficient manner.
     2.6.2. Encourage group personnel on TDY to solicit feedback on courses, when possible,
     and provide feedback to course personnel and evaluation offices.
     2.6.3. Conduct other research or evaluation programs for the improvement of graduate or
     training quality as deemed necessary.
     2.6.4. Route requests for software support pertaining to training evaluations software
     other than TTMS through 2 AF/TTOC to HQ AETC/A3P. Training groups will not
     purchase evaluation software or services without prior coordination with 2 AF/TTOC and
     HQ AETC/A3P.
  2.7. Technical training groups will conduct a fiscal year (FY) semiannual trend analysis and
  prepare a FY Semiannual Evaluation Summary Report.
  2.8. BMT (737 TRG) will:
     2.8.1. Prepare the 737 TRG Quarterly Survey Report.
 6                                                                AETCI36-2640 15 JULY 2014


        2.8.2. Proctor the RAND BMT Abuse and Misconduct Survey and the RAND MTI
        (Climate) Survey or other HQ AETC approved survey instrument.
        2.8.3. Provide a testing facility with terminals.
     2.9. HQ AETC CSS/SCOK will provide data automation support for the Training Quality
     Assessment (TQA) training evaluation software.
     2.10. HQ AETC/A5T is the Program Management Office for TTMS.
3. Training Evaluation Program (TEP).
     3.1. Each training group will establish a TEP to provide a medium for collecting relevant
     course data that can be used to identify training improvement opportunities. The TEP will
     include, as a minimum, internal evaluation (paragraph 4), external evaluation (paragraph 5), a
     TA program for technical training groups and a Stan/Eval program for BMT (paragraph 6).
     Note: The 937 TRG TEP will include a TA program; and internal and external evaluation
     programs with specific requirements as described in “Notes” in applicable paragraphs.
     3.2. Where installed and operational, use the TTMS for all unclassified formal technical and
     basic military training related functions to include course development and delivery,
     instructor and student management, resource management, and course evaluation. For
     courses containing classified information, enter all unclassified course information necessary
     to complete adequate student accounting when developing courses in the TTMS course
     development software. Use automated products produced by TTMS, if available. Forms
     generated electronically by these systems may be used in lieu of prescribed forms. For
     METC Courses, the 937 TRG will use data collected by METC, as applicable.
4. Internal Evaluation. Internal evaluation is the acquisition and analysis of feedback and
management data from within the training environment to determine if training accomplishes the
instructional objectives effectively and efficiently. It helps commanders, supervisors, and
instructors improve course and unit support; identifies outstanding instructors, facilities, and
equipment; and allows students to attain a sense of participation and responsibility for improving
training programs.
     4.1. Program Requirements. Each training group will establish an internal evaluation
     program. The program will include, as a minimum, such areas as student feedback,
     measurement review, elimination and washback trend analysis, and instructional review.
     AETCI 36-2641, Technical and Basic Military Training Development, contains minimum
     requirements for measurement and instructional review. AETCI 36-2642, Technical and
     Basic Military Training Administration, contains minimum requirements for elimination and
     washback trend analysis. Note: The 937 TRG will conduct internal evaluation for Medical
     Readiness Courses and assigned officer courses. The 937 TRG internal evaluation program
     for all enlisted initial skills courses Types 3, 5, 8, 9, A, B and C taught by the METC will
     include only General Support, Base Support, and Military Training.
     4.2. Student Feedback. Each training group will establish a student feedback program. At
     a minimum, each training squadron and faculty development flight (or equivalent unit) will
     participate in the program. The program is intended to obtain constructive comments on
     training, training environment, and base support.
AETCI36-2640 15 JULY 2014                                                                      7


     4.2.1. Commanders will appoint student feedback monitors, in writing, to manage the
     program. Training groups will establish procedures for maintaining, tracking, and
     follow-up of student feedback to ensure responses are timely and appropriate. Note:
     Each training group serviced by a HQ AFRC/A1K and/or ANG liaison office must also
     include procedures for forwarding student feedback received pertaining to their liaison
     offices. When AETC Forms 736 are submitted by students attending AETC technical
     training courses regarding quality of service received by HQ AFRC/A1 liaison offices,
     the training group will forward the forms to HQ AFRC/A1K, 155 2d Street, Robins AFB
     GA 31098 for review and necessary action. For ANG student feedback regarding liaison
     services, the information should be sent to the ANG Liaison Superintendent, 37
     TRW/LN, 1550 Wurtsmith St, JBSA Lackland, TX 78236.
     4.2.2. Each course will include a briefing on the student feedback program as part of the
     orientation unit, and allow time in each class prior to graduation, for students to
     participate in a course critique. Encourage all students to submit feedback on any aspect
     of training at any time to identify opportunities for training or support improvement.
     Feedback monitors will ensure replies to students/classes are provided when requested.
     When possible, use EOC feedback to summarize recommendations from graduating
     students.
     4.2.3. To standardize the collection of end-of-course (EOC) feedback for resident
     courses to include training detachments, technical training groups will use the TTMS
     EOC, if available, or the sample survey at Attachment 2. (See TTMS EOC Handbook for
     additional system procedures.) Training groups may modify the survey at Attachment 2
     to meet their individual needs (for example, add questions). However, to standardize data
     collection, the survey must contain (as a minimum) the same questions with the
     supporting rating scale in Attachment 2. AETC Form 736, Student Feedback, may also
     be used to obtain student feedback.
        4.2.3.1. Technical training courses using MT will add the following question to
        resident technical training EOC student feedback surveys for these courses: Did
        motivational training used in the course improve your motivation?
        4.2.3.2. The 737 TRG develops the BMT EOC survey and will include a copy in the
        737 TRG supplement to this instruction. BMT uses the following two statements
        requiring a “Yes” or “No” response regarding MT on the BMT EOC: My MTI(s)
        used push-ups, flutter kicks, or four count squat thrusts as motivation. and I
        believe the motivation exercises helped me to become more motivated or helped
        to correct my deficiencies.
  4.3. 737 TRG (BMT) Specific Surveys.
     4.3.1. The 737 TRG will proctor the RAND BMT Abuse and Misconduct Survey, the
     RAND MTI Survey (MTI Climate Survey), or other HQ AETC approved survey
     instrument(s).
     4.3.2. The RAND BMT Abuse and Misconduct Survey or other HQ AETC approved
     survey instrument(s) will be administered to every trainee prior to graduation to assist the
     Air Force in fostering a BMT environment free of abuse and misconduct.
8                                                              AETCI36-2640 15 JULY 2014


       4.3.3. The RAND MTI (Climate) Survey or other HQ AETC approved survey
       instrument(s) will be administered twice per year to gather feedback on work experiences
       as well as abuse and misconduct to ensure a positive and safe training environment for
       both trainees and MTIs.
       4.3.4. HQ AETC/A3-OAD will:
           4.3.4.1. Compile and analyze data from the RAND BMT Abuse and Misconduct
           Survey and RAND MTI (Climate) Survey or other HQ AETC approved survey
           instrument(s).
           4.3.4.2. Produce a quarterly report on the RAND BMT Abuse and Misconduct
           Survey and a semi-annual update on the RAND MTI (Climate) Survey or other HQ
           AETC approved survey instrument(s) to the RETOC. The report will provide
           negative and positive trends regarding the environment.
           4.3.4.3. Submit report results to HQ AETC/A2/3/1/0, 2 AF, and the 37 TRW.
       4.3.5. The RETOC Secretariat will establish an annual review of the surveys. Requests
       for changes to the survey instruments will be forwarded to the RETOC Secretariat IAW
       the RETOC charter.
    4.4. Type 6 Student Feedback. To standardize the collection of EOC student feedback for
    Type 6 DL courses, training groups will use the sample survey at Attachment 3. Training
    groups may modify the survey at Attachment 3 to meet their individual needs (for example,
    add questions, use paper or electronic format). However, to standardize data collection, the
    survey must contain (as a minimum) the same questions with the supporting rating scale in
    Attachment 3. Type 6 courses may use any available method (on-line, electronic, and paper)
    to collect EOC student feedback data. For web-based Type 6 surveys, training groups will
    include the web site in Type 6 course materials and courseware.
       4.4.1. Training groups will establish procedures for maintaining, tracking, and follow-up
       of Type 6 student feedback to ensure responses are timely and appropriate. As a
       minimum, forward any specific questions rated disagree or strongly disagree to the
       appropriate training manager. For Faculty Development Type 6 courses without a
       training manager assigned, forward specific questions rated “Disagree” or “Strongly
       Disagree” to the 2 AF Faculty Development Functional Manager. Process any request
       for a response the same as a CSIP inquiry (See paragraph 5.4.)
       4.4.2. Training groups will include Type 6 student feedback in the FY Semiannual
       Evaluation Summary Report using the format at Attachment 4 with individual course
       reports as attachments to the summary report. Use format at Attachment 5 for individual
       course reports.
       4.4.3. Individual course reports must include data collected on the 25 mandatory
       questions and on any additional questions the group may have added to the feedback
       survey.
           4.4.3.1. Report data by course and include, as a minimum, the number of graduates
           in the reporting period, the number of graduates responding, the number of questions
           with an overall rating of less than 90 percent, a summary of findings with corrective
AETCI36-2640 15 JULY 2014                                                                      9


           actions taken or planned, and an attachment with the percentage of graduates who
           responded to each possible response to the questions.
           4.4.3.2. Type 6 student feedback reports will not contain Privacy Act information. In
           the summary, include root causes, lessons learned, and trends (positive and negative),
           as appropriate. EXCEPTION: Questions 11 through 15 are exempt from the 90
           percent rule because AETC schoolhouses have no direct control over these items for
           units outside of AETC. However, data, comments, and any applicable corrective
           actions must be annotated.
       4.4.4. HQ 2 AF/TTOC will monitor Type 6 DL student feedback reports for trends and
       assist training groups in resolving issues, as necessary. 2 AF/TTOC will ensure trends
       outside 2 AF’s span of control are forwarded to the HQ AETC/A2/3/10 TPM for
       assistance in resolving, with a courtesy copy to HQ AETC/A3P.
5. External Evaluation. External evaluation provides an indication of customer satisfaction of
the graduate’s ability to perform tasks required in the career field; how well gained knowledge
and skills transfer to the workplace. In addition, external evaluation may indicate the need to
revise training standards or courses to improve training quality, add technology, and/or identify
skills and knowledge where training might be reduced or increased. All training standard
changes are made according to AFI 36-2201 and AETCI 36-2641.
   5.1. Program Requirements. Each training group will establish an external evaluation
   program. Occupational analysis reports (OAR), subject-matter expert (SME) feedback, FI,
   CSIP, FEQ, and FEQS should be reviewed and/or used as appropriate.
Note: As a minimum, the 937 TRG will conduct external evaluations for all assigned initial
skills officer courses. For all enlisted initial skills courses with AF graduates taught by the
METC, the 937 TRG will conduct external evaluation until METC gains the capability. External
evaluations for the Medical Readiness courses are conducted IAW AFI 41-106, Medical
Readiness Program Management.
Note: Due to unique mission requirements, IAAFA is waived from the external evaluation
program.
Note: BMT will establish procedures for an external evaluation program in a supplement to this
instruction.
Note: Due to unique training pipeline flow, courses where 3-level graduates continue in a
training status for 5-level upgrade without going to first duty station are waived from using
FEQs, and FEQSs. (Examples are the Special Operations Weather, Enlisted Aircrew, Apprentice
Airborne Intelligence, Surveillance, and Reconnaissance Operators [AFSC 1A8XXX] and
Combat Control pipelines). Feedback for these unique pipelines can still be obtained when
conducting OARs, from supervisors and SMEs who attend specialty training requirements team
(STRT)/utilization and training workshops (U&TW).
   5.2. Occupational Analysis Reports (OAR). AFI 36-2623, Occupational Analysis,
   contains policy on OARs. Review OARs to compare the current career field education and
   training plan (CFETP) or course training standard (CTS) with feedback from the field.
   Feedback from SMEs who attend STRT/U&TWs and results of the specialty knowledge
   test/career development course (SKT/CDC) compatibility critique helps ensure course
   content is current. Compare the OAR training report to feeback received through internal
   and external evaluations.
10                                                            AETCI36-2640 15 JULY 2014


  5.3. Field Interview (FI). FIs are another source for obtaining data on both currency and
  effectiveness of courses, if funding permits. Training groups must check with the Air Force
  Survey Program Office (OPR for AFI 38-501, Air Force Survey Program) for applicable
  administration requirements prior to conducting FIs.
     5.3.1. When planning onsite visits, evaluators/interviewers should contact the Base
     Training Office (BTO) at each selected installation to coordinate plans for the FIs. (Note:
     Contact the Base 3S2XX Functional Manager, if no BTO exists.) Interviews should not
     conflict with planned inspections and exercises at onsite locations.
     5.3.2. Evaluators/interviewers should interview course training personnel in the career
     fields being evaluated prior to conducting FIs to gain an understanding of any existing or
     unique career field peculiarities. Samples of FI guides (for supervisors and graduates) are
     at Attachment 6.
     5.3.3. Any specific request for information or clarification contained on a FI response
     that cannot be immediately answered by the interviewer will be processed the same as a
     CSIP inquiry or if necessary, within 5 workdays after return from temporary duty (TDY).
     5.3.4. Third party interviews, such as those by education and training managers, course
     personnel, or interviews conducted by any other technologically advanced means of
     direct communication may also be used. A copy of the FI guides should be available for
     use in third party interviews and feedback obtained should be sent to the training group
     evaluation office. The same procedures for answering requests for information or
     clarification as listed in paragraph 5.3.3. will be used.
     5.3.5. Training groups will establish procedures to route FI feedback to appropriate
     offices and implement follow-up procedures to ensure concerns or problems identified
     are tracked and corrected.
  5.4. Customer Service Information Process (CSIP). The CSIP consists of the customer
  service information line (CSIL) and any other written method by which the field
  communicates to a training group to ask questions or express concerns or problems with
  training received. CSIL information is required to be listed in all CFETPs and CTSs IAW
  AETCI 36-2641.
     5.4.1. Groups will establish a tracking mechanism to monitor use and follow-up action of
     CSIP inquiries and implement procedures to ensure problems identified are tracked and
     corrected. As a minimum, the tracking mechanism should include date of inquiry, how
     the inquiry was received, and satisfaction results. Track the field's concern using a
     locally developed template similar to Attachment 7.
     5.4.2. The CSIL is a method by which any field user (supervisor, graduate, etc.) can
     communicate directly with the appropriate training group concerning training issues.
     Each training group will establish a phone number (with voicemail for non-duty hours)
     and distribution/organizational email address for such purposes. Groups will contact the
     inquirer to obtain all relevant information necessary to effectively answer the inquiry.
     5.4.3. Each training group will provide answers to inquiries as soon as possible, but not
     later than 5 workdays after contact with the caller or receipt of written inquiry.
AETCI36-2640 15 JULY 2014                                                                      11


     5.4.4. Each group will establish routing procedures to ensure the person most qualified to
     answer the inquiry prepares the reply. If a phone answer is appropriate, the person
     preparing the answer will call the requestor with the reply.
     5.4.5. Answers to significant training issues (such as changing course content,
     proficiency level, or length of a training program) or problems will be in writing. The
     group evaluation office will review the written replies and keep copies of these replies.
     Copies will also be sent to the appropriate AFCFM, major command (MAJCOM) Air
     Force specialty (AFS) functional manager, AETC/A2/3/10 TPM, and 2 AF/TTOC
     Workflow.
     5.4.6. To enhance customer satisfaction, training groups may send a customer
     satisfaction survey to the originators of inquiries to significant training issues.
  5.5. Field Evaluation Questionnaire (FEQ) and Field Evaluation Questionnaire
  Summary (FEQS). FEQs are designed to solicit feedback from supervisors and/or
  graduates to determine if graduates were trained as specified in the training standard. For
  officer and enlisted initial skills courses, standard questions will be added for supervisors of
  non-prior service (NPS) Air Force graduates. These standard questions will be used to
  determine the adequacy of further military training provided NPS students while attending
  initial skill technical training courses. FEQSs summarize questionnaire results.
     5.5.1. When scheduling field evaluations, give priority to courses where there is a
     concern about training.
         5.5.1.1. As a minimum, training groups will complete an annual field evaluation
         (from the date the last FEQS was signed) on each active initial skill AFSC awarding
         and mandatory 7-skill level craftsman courses (to include Type 6) that produced
         graduates.
         5.5.1.2. When an initial skill or mandatory 7-skill level course is brought on line for
         the first time start a field evaluation using graduates two to three classes following
         completion of validation.
         5.5.1.3. The approval authority for exceptions to the annual requirement for a field
         evaluation is is 2 AF/TTOC for 2 AF units and Eaker Center/MSO for Eaker Center.
         Some reasons for extending the evaluation cycle may include a lack of sample size
         for the questionnaire, transferring a course from one location to another, or changing
         the course from one type of training to another (e.g., type 3 to type 6 to another.)
         5.5.1.4. The TRG Evaluation Office will document the request for extension to the
         annual requirement, coordinate with the training manager, and submit to 2 AF/TTOC.
         Include reasons for the extension, the date the last field evaluation was completed,
         and a revised evaluation date in the documentation. Copies of the documentation of
         an approved extension will be distributed to the applicable AFCFM and
         AETC/A2/3/10 TPM.
     5.5.2. Develop FEQs as prescribed in Attachment 8 to simplify completion by the
     customer. When questionnaires are being developed, request inputs from the AFCFM
     through the AETC/A2/3/10 TPM and course personnel.            (Coordination at the
     STRT/U&TW may fulfill this requirement.) As a minimum, include questions
12                                                             AETCI36-2640 15 JULY 2014


     concerning the ability of graduates to perform those tasks deemed critical and/or core to
     the career field.
     5.5.3. Supervisors are the preferred source for evaluating recent graduates of initial skill
     courses. Survey graduates when a supervisory survey would not provide adequate
     feedback. When both graduate and supervisor data are gathered, present the data for each
     separately. In supervisor questionnaires, ask for an overall rating of graduates' job
     performance. In graduate questionnaires, ask for a rating of overall training provided.
     5.5.4. Use TQA to determine the minimum number of questionnaires required. When
     applicable, use a representative sample of students from each MAJCOM, to include
     ANG, AFRC, and sister services. (Note: Table 1 provides an example for sample size
     and confidence levels to illustrate the logic used by TQA. It does not include all possible
     confidence levels.)
     5.5.5. Use the most direct route to the graduate’s supervisor when requesting he or she
     complete an FEQ. This may mean routing through the BTO. (Note: Contact the Base
     3S2XX Functional Manager, if no BTO exists.) In order to achieve an adequate sample
     size, use one of the following methods:
        5.5.5.1. Shotgun. Send FEQ completion requests at the same time to supervisors of
        graduates and/or graduates who have been in the field from 4 to 6 months. When
        using this method, data should be extractable by length of time. (For example, if
        mailing in June, send requests to those who graduated between January and March.)
        5.5.5.2. Sequential. Send a FEQ completion request each month to graduates and/or
        supervisors of graduates who have been in the field for 4 months. Continue to send
        out mailings until a large enough sample is achieved to represent the career field.
        (For example, send notification to complete surveys in June for March graduates, in
        July for April graduates, in August for May graduates, etc.)
     5.5.6. Use the most direct route to conduct follow-up actions with the BTO, force
     support squadron commander or equivalent if you need help reaching the minimum
     confidence level. (Note: Contact the Base 3S2XX Functional Manager, if no BTO
     exists.) Achieving the desired confidence level is critical for evaluation, validity, and
     support of conclusions and actions in the FEQS. Note: If a problem area is identified that
     needs immediate attention, forward to the responsible training squadron for action. Do
     not use the criteria in paragraph 5.5.7 for this purpose.
     5.5.7. When the minimum required confidence level is achieved, training is considered
     adequate on a training standard item when 90 percent of usable surveys rate the training
     at or above the required level. Items falling below 30 percent utilization should be
     reviewed for retention, deletion, or alternate mode of training.
     5.5.8. Use the format in Attachment 9 to document the results of the FEQs, analysis, and
     summary of corrective actions taken or planned for all items not meeting the training
     adequacy or utilization criteria described in paragraph 5.5.7. Specifically state if the
     required confidence level was obtained as specified in Table 1, Note 2. The FEQS must
     be signed by the training group commander and identify the items failing to meet either
     adequacy or utilization criteria. Consider all applicable evaluation data, both internal and
     external, when preparing the FEQS. FEQSs will not contain Privacy Act information.
AETCI36-2640 15 JULY 2014                                                                         13


          5.5.8.1. When the desired confidence level is achieved, analyze data paying
          particular attention to those items deemed critical to the career field (core tasks, etc.).
          If a critical item falls below the minimum adequacy criteria described in paragraph
          5.5.7, make every effort to work with course personnel, training managers,
          AETC/A2/3/10 TPM, AFCFMs, and other SMEs to determine the cause and
          recommend the best course of action. Consider conducting a thorough analysis of the
          method of delivery, sequence of training, test results, washback rates, etc.
          5.5.8.2. When the desired confidence level is not achieved, analyze the data received
          to identify possible problem areas, summarize results, and publish report using the
          format at Attachment 9, specifically stating that the confidence level was not
          obtainable. No recommended course of action is required.
          5.5.8.3. Any specific request for information or clarification related to training
          provided contained on a questionnaire comment sheet will be processed the same as a
          CSIP inquiry.
          5.5.8.4. Post FEQSs to the AETC TT and BMT Evaluations site and notify the
          AFCFM, HQ AETC/A2/3/10 TPM, and 2 AF/TTOC it has been posted. Notify
          applicable training groups when posting a FEQS prepared on standardized faculty
          development courses. (Note: Additional distribution will be determined by the
          group commander.)
       5.5.9. Upon request from AETC/A3PV, training groups will provide information on post
       graduate surveys. This information will be used to request a survey control number
       (SCN) IAW AFI 38-501. Information requested normally consists of a list of projected
       courses with applicable target survey population for a specific time period.
Table 1. Graduate Sampling. (Notes 1 and 2)
  I            A                        B                         C                        D
 T      Course Graduates           Sample Size             Course Graduates            Sample Size
 E       During Sample           Confidence Level           During Sample           Confidence Level
 M           Period            95%     90% 80%                  Period             95% 90% 80%
  1            10              10      10    9                   700               255   195    133
  2            20              19      19    18                  750               261   199    134
  3            30              28      27    25                  800               267   202    136
  4            40              36      35    32                  850               272   205    137
  5            50              44      42    38                  900               277   208    139
  6            60              52      49    44                 1,000              286   213    141
  7            70              60      56    49                 1,100              293   217    143
  8            80              67      62    54                 1,200              300   221    144
  9            90              73      68    58                 1,300              306   224    146
 10           100              80      73    62                 1,400              311   227    147
 11           101              81      74    63                 1,500              316   229    148
 12           110              86      78    66                 1,600              320   231    149
 14                                                            AETCI36-2640 15 JULY 2014


 13             120            92       83      69               1,700         324     233     149
 14             130            98       88      72               1,800         327     235     150
 15             140            104      92      75               1,900         330     237     151
 16             150            109      97      78               2,000         333     238     151
 17             160            114      101     81               2,200         338     241     152
 18             170            119      104     83               2,400         343     243     153
 19             180            124      108     86               2,600         347     245     154
 20             181            125      109     87               2,800         350     247     155
 21             190            129      112     88               3,000         353     248     155
 22             200            133      115     90               3,500         358     251     157
 23             250            154      130     99               4,000         364     253     157
 24             300            171      142     106              5,000         370     257     159
 25             350            187      153     112              7,000         378     261     160
 26             400            200      161     116             10,000         383     263     161
 27             450            212      169     120             15,000         390     265     162
 28             500            222      176     123             25,000         394     268     163
 29             550            232      181     126             50,000         397     269     163
 30             600            240      186     129            100,000         398     270     164
 31             650            248      191     131               ---          ---     ---     ---

 NOTES:
 1. Here is an example of how to use this table. If sample course production is 500 and 95 percent is
 the desired confidence level, then 222 usable questionnaires are required. This figure is 85 percent
 of the questionnaires to be mailed out. The number of questionnaires to be mailed is computed as
 follows: (Refer to AFHB 36-2235, Volume 9, for more information.)

  85%       222     222 x 100
  100%     =    X = 85      = 261 (number of questionnaires to mail)

 2. Sample size numbers represent required usable returned questionnaires. For evaluation of courses
 with 100 or fewer graduates during the sampling period, an 80 percent confidence level is required.
 For courses with 101 through 180 graduates, a 90 percent confidence level is required. For courses
 with 181 or more graduates, a 95 percent confidence level is required.



6. Technical Training Group TA Program/BMT Standardization/Evaluation
(Stan/Eval). The TA Program/BMT Stan/Eval focus on the group’s success in providing
graduates who meet customers’ needs. It also focuses on effective use of Air Force resources.
The TA Program/BMT Stan/Eval provide an internal resource for respective commanders to
assess the quality of their organizations and take early corrective actions when required.
AETCI36-2640 15 JULY 2014                                                                      15


   6.1. Each technical training group will establish a TA Program, and BMT will establish a
   Stan/Eval Program, to give their respective Group Commander, subordinate commanders and
   group Airmen the right information at the right time to assess risk, identify areas of
   improvement, determine root cause and precisely focus limited resources – all aligned with
   the commander’s priorities and on the commander’s timeline. The TA Program and BMT
   Stan/Eval should also facilitate requests for targeted assistance from the Wing, NAF,
   MAJCOM commanders and staff when/where needed.
Note: Due to unique mission requirements, the 517 TRG and the AU Eaker Center are excluded
from TA Program requirements.
   6.2. Technical Training Group TA Programs and BMT Stan/Eval will:
      6.2.1. Inspect group-wide and subordinate unit effectiveness as well as assessing cross-
      unit functions/programs as directed by the Group Commander. Commanders will
      determine the appropriate scope, scale; timing and methodology to most effectively
      accomplish the objectives of the TA and BMT Stan/Eval Programs, respectively, and
      support the Wing Commander’s Inspection Program (CCIP).
      6.2.2. Serve as TRG focal point for higher headquarters (HHQ) inspections. Review
      corrective actions for deficiencies discovered during inspections, and track AFSO 21
      initiatives to resolve significant and critical deficiencies.
      6.2.3. Conduct special assessments/evaluations as directed or requested by commanders.
   6.3. Training Assessments and BMT Stan/Evals will:
      6.3.1. As a minimum, all TA Programs and the BMT Stan/Eval will evaluate compliance
      with applicable technical and basic military training policies for the following: feedback
      programs; resources management; risk management; training development and training
      management; trainee administration and scheduling; military training; motivational
      training practices (if applicable); and instructor utilization, proficiency, and training.
      6.3.2. Conduct evaluations to collect the facts (positive and negative), and validate
      findings.
      6.3.3. Publish a report as required by the group commander.
      6.3.4. Provide corrective action reports for deficiencies found during assessments and
      Stan/Evals. Continue follow-ups until such findings are resolved.
   6.4. Training Assessment and BMT Stan/Eval Augmentation. The TA Program and
   BMT Stan/Eval offices will select qualified personnel, such as instructor supervisors, training
   specialists, MTLs and MTIs, as applicable, whom are recommended by their training
   squadron commander to be augmenters. The TA Program and BMT Stan/Eval offices will
   maintain a listing of current augmenters with specific areas of expertise.
   6.5. TA Program and BMT Stan/Eval Evaluator Training.
      6.6.1. Each TA Program office and BMT Stan/Eval will develop a training plan to train
      all TA Program and BMT Stan/Eval personnel, respectively, including augmenters. The
      purpose of the training is to ensure uniformity in application of evaluation techniques and
      philosophy for each program, respectively. Training must cover evaluation techniques,
 16                                                             AETCI36-2640 15 JULY 2014


       documentation and standardization of instructor evaluations, safety, risk management and
       security requirements associated with courses.
       6.6.2. Each permanent or augmenter evaluator for the TA Program and BMT Stan/Eval
       must receive training prior to performing evaluation duties from the TA Program or BMT
       Stan/Eval, respectively.
7. Interservice Training. Evaluate interservice courses in accordance with AFI 36-2230-IP,
Interservice Training, and applicable interservice agreements. Use caution to ensure AETC does
not duplicate existing host-service evaluations that are adequate. The chief of the training
evaluation unit may include or exclude other service graduates from surveys except when
specifically requested to do so by officials of other services.
8. Use of Training Evaluation Data.
   8.1. Each training group will develop metrics to measure and track efficiency and
   effectiveness of training courses. Internal evaluations are the primary source for efficiency
   metrics and external evaluations are the primary source for effectiveness metrics. Qualitative
   and quantitative assessments may be merged to enhance the validity of findings. When
   metrics show a deficiency, develop and implement corrective actions.
   8.2. Technical training groups will present evaluation data to AFCFMs, at STRT/U&TWs,
   or other similar forums and use this data to help develop training requirements. BMT will
   present evaluation data at the BMT Triennial Review.
9. Trend Analysis.
   9.1. AF/TTOC will conduct a FY semiannual trend analysis and prepare a FY Semiannual
   Evaluation Summary Report:
       9.1.1. Consolidate and summarize TRG evaluation reports.            Review feedback to
       determine potential problem areas in training evaluation.
       9.1.2. Analyze all internal and external inspections and evaluations conducted at 2 AF
       units.
       9.1.3. Identify operational or training factors/trends that positively or adversely affect
       training.
       9.1.4. Make specific recommendations for corrective actions as needed and include
       Deficiency Cause Codes, FEQS, FI, and DL feedback, as applicable.
       9.1.5. Distribute by 20 May and 20 November to HQ AETC/A3T, training wing and
       training group commanders with a courtesy copy to HQ AETC/A3P. Evaluation
       Summary reports will not contain Privacy Act information.
   9.2. Technical training groups will conduct a FY semiannual trend analysis and prepare a FY
   Semiannual Evaluation Summary Report as follows:
       9.2.1. As a minimum, review higher headquarters inspections, internal, and external
       evaluation results.
       9.2.2. Identify trends in evaluation programs to include FEQ data, FIs, CSIP, and student
       feedback data (if available).
AETCI36-2640 15 JULY 2014                                                                       17


      9.2.3. Submit analysis as shown in Attachment 4 to 2 AF/TTOC Workflow by 20 April
      (covering 1 October XX – 31 March XX) and 20 October (covering 1 April XX – 30
      September XX). Reports will not contain Privacy Act information.
Note: Eaker Center and IAAFA are exempt from requirement to conduct a semiannual trend
analysis and submit a FY Semiannual Evaluation Summary Report.)
   9.3. BMT will prepare a FY quarterly summary (to include corrective actions as required on
   areas identified for improvement) on internal and external evaluation results IAW format
   prescribed in a 737 TRG supplement to AETCI 36-2640. BMT summaries will not contain
   Privacy Act information. The BMT Summary will be posted to the AETC TT and BMT
   Evaluations site no later than 45 days following the quarter (for example, 15 February for the
   October – December quarter) and notify HQ AETC/A3T, A3PV, and 2 AF/TTOC it is
   available for review.




                                            MICHAEL A. KELTZ, Major General, USAF
                                            Director of Intelligence, Operations, and Nuclear
                                            Integration
 18                                                          AETCI36-2640 15 JULY 2014


                                        Attachment 1
         GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION

References
AFI 33-360, Publications and Forms Management, 7 February 2013
AFI 36-2201, Air Force Training Program, 15 September 2010
AFI 36-2230 (I), Interservice Training, 29 August 2012
AFI 36-2623, Occupational Analysis, 10 September 2012
AFI 38-501, Air Force Survey Program, 12 May 2010
AFMAN 36-2234, Instructional System Development, 1 November 1993
AFH 36-2235, Volumes 1, Information for Designers of Instructional Systems, 01 Sep 2002
AFH 36-2235, Volumes 2-12, Information for Designers of Instructional Systems, 01 Nov 2002
AFH 36-2235, Volumes 13, Information for Designers of Instructional Systems, 03 Aug 2003
AFI 90-201, Air Force Inspection System, 23 March 2012
AETCI 36-2641, Technical and Basic Military Training Development, 26 June 2014
AETCI 36-2642, Technical and Basic Military Training Administration, 9 September 2010
Prescribed Forms
AETC Form 736, Student Feedback, 18 September 2007
Adopted Forms
AF Form 847, Recommendation for Change of Publication, 22 September 2009

Abbreviations and Acronyms
AETC—Air Education and Training Command
AFCFM—Air Force Career Field Manager
AFMAN—Air Force Manual
AFRC—Air Force Reserve Command
AFRIMS—Air Force Records Information Management System
AFS—Air Force specialty
AFSC—Air Force specialty code
ANG—Air National Guard
AU—Air University
BTO—Base Training Office
BMT—basic military training
CC—commander
AETCI36-2640 15 JULY 2014                                    19


CDC—career development course
CFETP—Career Field Education and Training Plan
CSIL—customer service information line
CSIP—customer service information process
CTS—course training standard
DL—distance learning
DLIELC—Defense Language Institute English Language Center
DSN—Defense Switching Network
EOC—end of course
FEQ—field evaluation questionnaire
FEQS—field evaluation questionnaire summary
FI—field interview
GSU—geographically separated unit
IAAFA—InterAmerican Air Force Academy
IG—inspector general
MAJCOM—major command
METC—Medical Education and Training Campus
MT—motivational training
MTL—military training leader
MTF—military training flight
NPS—non-prior service
OAR—occupational analysis report
OPR—office of primary responsibility
PCS—permanent change of station
PC—personal computer
RCS—reports control symbol
RDS—records disposition schedule
RETOC—Recruiting, Education and Training Oversight Council
SCN—survey control number
SKT—specialty knowledge test
SME—subject-matter expert
STRT—Specialty Training Requirements Team
 20                                         AETCI36-2640 15 JULY 2014


STS—specialty training standard
TDY—temporary duty
TEP—training evaluation program
TPM—training pipeline manager
TQA—Training Quality Assessment
TRG—training group
TT—technical training
TTMS—technical training management system
U&TW—utilization and training workshop
AETCI36-2640 15 JULY 2014                                                                          21


                                           Attachment 2
   SAMPLE IN-RESIDENCE TRAINING END-OF-COURSE STUDENT FEEDBACK
                              SURVEY

Table A.2.1. Sample Feedback


SAMPLE IN-RESIDENCE TRAINING END-OF-COURSE STUDENT FEEDBACK
SURVEY


Course Number & Title ________________________________________________________
Class ID _______
Shift and Section (if applicable) ________________________
Graduation Date ____________________________________
MTF Squadron (if applicable) _________________________
Student Name (optional unless reply requested) ____________________________________
Student Address (optional unless reply requested) __________________________________

This questionnaire asks for your impressions of the overall training, training environment,
training facilities, and the quality of instruction. Use the scale provided to indicate your rating of
these areas and mark it on the answer sheet provided.
A. Strongly Agree      B. Agree     C. Disagree     D. Strongly Disagree       E. Not Applicable
If you rate any item disagree or strongly disagree, please explain what areas you feel the training
was inadequate. PLEASE BE SPECIFIC.


INSTRUCTOR
1. Instructor presentations were clear.
2. Instructors were knowledgeable in the subjects they taught.
3. Instructors maintained a safe learning environment.
4. Instructors established a positive learning environment.
5. Individual assistance was provided as needed.
CURRICULA
6. Instructional objectives were understandable.
7. Course training materials (for example study guides, workbooks, tech data, etc.) were clearly
written.
 22                                                               AETCI36-2640 15 JULY 2014


8. Course training materials supported classroom instruction.
9. Instructional technology (for example, simulators, computer based training, etc.) enhanced
learning.


CURRICULA (Non B, L, Q courses)
10. Course enhanced my knowledge, skills, and/or abilities.
MEASUREMENT
11. Measurement devices (for example, performance tests, progress checks, and/or written tests)
covered course objectives.
CLASSROOM RESOURCES
12. Equipment (for example, simulators, trainers, computers, etc.) was available in sufficient
quantities.
13. Equipment (for example, simulators, trainers, computers, etc.) was in good operating
condition.
14. Classroom environment (for example, lighting, furniture, heat/air, etc.) was satisfactory for
learning.
MILITARY TRAINING (Non-Prior Service [NPS] Only)
15. Military training leaders (MTL) clearly explained policies, procedures, and standards.
16. MTLs were approachable.
17. MTLs were available when I needed help or guidance.
18. MTLs were consistent in enforcing standards.
19. MTLs led by example.
20. Airman leaders (Ropes) were consistent in enforcing standards.
21. Airman leaders (Ropes) treated all students fairly.
22. Airman leaders (Ropes) were helpful.
GENERAL SUPPORT (NPS Only)
23. Assignment personnel were helpful.
24. My dormitory was sufficiently quiet to allow study.
25. My dormitory was sufficiently quiet to allow sleep.
26. I had sufficient time to study outside of the classroom.
27. I had sufficient time to eat lunch.
AETCI36-2640 15 JULY 2014                                                       23


GENERAL SUPPORT (TDY Only)
28. Lodging personnel were responsive to my needs.
29. Lodging facilities were adequate.
BASE SUPPORT (ALL)
30. Base chapel programs met my needs.
31. Medical facilities met my needs.
32. The finance office met my needs.
33. The military personnel flight met my needs.
34. Base facilities (gym, theater, library, dry cleaners, etc.) met my needs.
35. Dining facilities were adequate.
OVERALL (NPS Only)
36. I experienced a positive learning environment during technical training.
37. This experience has motivated me towards a successful military career.
 24                                                                AETCI36-2640 15 JULY 2014


                                            Attachment 3
                   SAMPLE TYPE 6, DL END-OF-COURSE FEEDBACK

Table A3.1. Sample Format
Course Title ___________________________________________________
Course Number __________________________
Course Start Date ________________________
Name of Instructor (if applicable) _________________________________
Unit, Office Symbol, and Base _____________________________________
This questionnaire asks for your impressions of the overall training, training environment,
training facilities, and the quality of instruction. Use the scale provided to indicate your rating of
these areas and mark it on the answer sheet provided.
A. Strongly Agree        B. Agree     C. Disagree       D. Strongly Disagree      E. Not Applicable


                                  COURSE EFFECTIVENESS
1. Course objectives were clearly stated.
2. Course objectives were relative to my job requirements.
3. Course content supported the objectives.
4. Course objectives were tested at appropriate times throughout the course.
5. Test questions adequately measured my knowledge of course objectives.
6. Test questions were understandable.
7. Beneficial and timely feedback/help was built into the courseware or was provided by the
instructor.
8. Safety procedures were stressed.
9. The course was organized logically.
10. The course enhanced my knowledge, skills, and/or abilities.
                                ENVIRONMENT/EQUIPMENT
11. Learning environment (lighting, furniture, equipment, temperature) was satisfactory for
learning.
12. Equipment required for course completion was easily accessible.
13. Equipment required for course completion functioned properly.
14. I knew how to receive technical assistance if required.
15. Technical assistance was provided in a timely manner.
                                         COURSEWARE
AETCI36-2640 15 JULY 2014                                                                      25


16. Course materials were received in a timely fashion and in good condition.
17. The pace of course material was relative to the degree of difficulty.
18. The level of interaction enhanced my learning.
19. Course materials were easy to understand and user friendly.
20. Course pictures and videos were clear and supported training.
21. Audio added to the lesson presentations.
22. Course materials contained current and accurate information.
23. Indicate the approximate number of hours required to complete the course (using the
following scale).
A. 5-10 hours        B. 11-20 hours        C. 21-30 hours    D. 31-40 hours     E. 40+ hours
24. Identify your primary learning environment during course completion (using the following
scale).
A. PC at work site         B. PC at home         C. Computer lab at Education Office
D. Distance Learning classroom E. Other (Please indicate)_________________


                                 OVERALL COURSE RATING
25. My overall rating of this course is:
A. Outstanding         B. Excellent        C. Satisfactory   D. Marginal        E. Unsatisfactory


If your overall rating of this course is marginal or unsatisfactory, please explain in what areas
you feel the training was inadequate. PLEASE BE SPECIFIC.
IF YOU ENCOUNTERED PROBLEMS WITH COURSE COMPLETION, PLEASE
PROVIDE DETAILS FOR OUR CORRECTIVE ACTION.
 26                                                                  AETCI36-2640 15 JULY 2014


                                          Attachment 4
  SAMPLE FY SEMIANNUAL EVALUATION SUMMARY REPORT XX TRAINING
      GROUP FY SEMIANNUAL EVALUATIONSUMMARY REPORT 20XX

A4.1. Internal Evaluation Program Data:
   A4.1.1. Units/functions evaluated this period (List GSU inspections by date).
   A4.1.2. Analysis of trends observed in organization evaluations > 10% of total problems.
Table A4.1. Summary of Internal Evaluation Data (Example)
  1.   Problem     2. Deficiency   3. Cause Title    4. # of cases     5. % Total   6. Mission
                   Cause Code                            cited         Problems       Impact

 1.                                                     7        33.3%
 Solutions, Countermeasures to prevent recurrence and LIMFACS, if any.

 2.                                                     7    33.3%
 Solutions, Countermeasures to prevent recurrence and LIMFACS, if any.

 3.                                                     7    33.3%
 Solutions, Countermeasures to prevent recurrence and LIMFACS, if any.

 Notes:
 1. Describe the problem.
 2. List the Deficiency Cause Code as outlined in AFI 90-201.
 3. List the Title of the Deficiency Cause Code as outlined in AFI 90-201.
 4. List the number of problems discovered.
 5. List the percentage of total problems discovered for the report period (In the example
 above, there was a total of 21 problems cited. For each problem 33.3% is the portion of the
 total).
 6. Types of Mission Impact: Minor, Significant, Critical.

   A4.1.3. Status of previously reported “OPEN” problems. (Example)
        A4.1.3.1. Attrition rates in course XXXXX identified in previous analysis report remain
        high at 33% despite efforts to revise curriculum and emphasis on remedial training.
        Currently working with AFPC and AFCFM to increase entrance requirements for this
        career field
   A4.1.4. Process improvements (Example)
        A4.1.4.1. Conducted AFSO-21 process improvement event to analyze course
        development times under ISD construct. Implemented rapid prototyping model to react
        more quickly to changes occurring on the battlefield. Resulted in reduction of training
        development time from 11 months to 45 days. Details of the process are available by
        contacting XX TRG evaluations at DSN XXX-XXXX
   A4.1.5. Special evaluations (if applicable) (Example)
AETCI36-2640 15 JULY 2014                                                                              27


        A4.1.5.1. The XX TRG Commander directed a hands-on inventory of all NWRM items
        to ensure accountability. No problems noted.
   A4.1.6. Student feedback data (to include Type 6): Table A4.2                           In-Residence
   (Example)
  Training          Tech               Military      General Support Satisfaction       Base Support
   Group          Training             Training                 Rate                    Satisfaction
                 Satisfaction         Satisfaction                                          Rate
                     Rate                 Rate
  XX TRG             96%                  90%                      94%                        92%
 Problems, Solutions, Countermeasures, and LIMFACS identified through in-residence
 student feedback: None

Table A4.3. Type 6, if applicable (Example)
                                              #
Training Group # Courses # Graduates GraduatesResponding % Questions >90% SAT
    XX TRG                18             521                 521                        85%

Problems, Solutions, Countermeasures, and LIMFACS identified through type-6 student
feedback: XX TRG noted that many students attempted the survey more than once. The
Type 6 data indicates that the results of the surveys were not reliable for fourteen of the
eighteen courses. LIMFAC: connectivity issues and slow server response times.

A4.2. External Evaluation Program Data. Analysis (cumulative to cover 6-month period).
   A4.2.1. Field Evaluation Questionnaire (FEQ) Data.
Table A4.4. FEQ Table (Example)
 Training      FY 13        FY 13         FY 13        FY 13         FY 13       FY 13      FY 13       FY 13
  Group       Q1-Q2        Q1-Q2          Q1-Q2       Q1-Q2         Q3-Q4       Q3-Q4       Q3-Q4      Q3-Q4
              Courses        FEQ         Waivers      Courses       Courses       FEQ      Waivers     Courses
             Requiring     Projects      Approved     Not Due      Requiring    Projects   Approved    Not Due
             Field Eval    Mailed                    Field Eval    Field Eval   Mailed                  Field
                                                                                                         Eval
  XX
  TRG            5             4            1           19             2            2           0        23
Problems, Solutions, Countermeasures, and LIMFACS identified through FEQs: None

Notes:
1. Courses Requiring Field Evaluation: Equals the number of courses required during the period. 2.
FEQ Projects Mailed: Number of FEQ projects which have been mailed (not number of mailings,
just number of projects).
3. Waivers Approved: Number of FEQs waived during reporting period.
4. Courses Not Required FEQ: Number of courses required but could not be conducted.
5. Courses Requiring Field Eval = Projects Mailed + Waivers Approved.
6. Courses Not Due + Courses Requiring Field Eval = Total number of AFSC awarding courses and
mandatory 7-level courses.
 28                                                            AETCI36-2640 15 JULY 2014



   A4.2.2. Provide total FEQ projects closed during period, non-relational to projects mailed.
Table A4.5. Example. Field Interview (FI):


   Training         #         # Supervisor      % Supervisor      # Graduate       % Graduate
    Group       Locations       Surveys         Surveys SAT         Surveys       Surveys SAT
                 Visited       Conducted                          Conducted
   XX TRG           2              38               76%                69             87%
  Problems, Solutions, Countermeasures, and LIMFACS identified through FI: Supervisors
  reported graduates of course XXXXX trained on outdated data collection systems were taking
  longer than planned to complete upgrade training. Confirmed training need with career field
  manager. LIMFAC: new data collection system requires data system upgrade estimated at
  $120K.




                                                       GROUP COMMANDER SIGNATURE



 Attachment:
 Type 6 Student Feedback Questionnaire Data


 cc:
 TRW/CC
AETCI36-2640 15 JULY 2014                                                                                  29


                                                  Attachment 5
                        TYPE 6 STUDENT FEEDBACK QUESTIONNAIRE DATA

Table A5.1. Sample Format Student Feedback

TYPE 6 STUDENT FEEDBACK QUESTIONNAIRE DATA
(Course Number/Title)
From (Start Date to End Date)
                               Total   Percent   Percent   Strongly                                Strongly
                               Resp     Sat >     UnSat     Agree      Agree    N/A     Disagree   Disagree
                              QTR/YR   QTR/YR    QTR/YR    QTR/YR     QTR/YR   QTR/YR   QTR/YR     QTR/YR
Course Effectiveness
1. Course objectives were      11/11   100/100     0/0       1/1        7/7      0/0      0/0        0/0
clearly stated.
2. Course objectives were      11/11   100/100     0/0       3/3        8/8      0/0      0/0        0/0
relative to my job
requirements.
3. Course content               9/9     89/89     11/11      4/4        4/4      2/2      1/1        0/0
supported the objectives.
4. Course objectives were      11/11    91/91      9/9       4/4        6/6      0/0      1/1        0/0
tested at appropriate times
throughout the course.
5. Test questions              11/11   100/100     0/0       4/4        7/7      0/0      0/0        0/0
adequately measured my
knowledge of course
objectives.
6. Test questions were         11/11   100/100     0/0       5/5        6/6      0/0      0/0        0/0
understandable.
7. Beneficial and timely       11/11   100/100     0/0       4/4        7/7      0/0      0/0        0/0
feedback/help was built
into the courseware or was
provided by the instructor.
8. Safety procedures were      11/11   100/100     0/0       4/4        7/7      0/0      0/0        0/0
stressed.
9. Course was organized        11/11    91/91      9/9       3/3        7/7      0/0      1/1        0/0
logically.
10. Course enhanced my         11/11   100/100     0/0       5/5        6/6      0/0      0/0        0/0
knowledge, skills, and/or
abilities.
Environment/Equipment
*11. Learning environment      11/11   100/100     0/0       4/4        7/7      0/0      0/0        0/0
(lighting, furniture,
equipment, and
temperature) was
satisfactory for learning.
*12. Equipment required        11/11   100/100     0/0       4/4        7/7      0/0      0/0        0/0
for course completion was
easily accessible.
*13. Equipment required        11/11    91/91      9/9       4/4        6/6      0/0      1/1        0/0
for course completion
functioned properly.
*14. I knew how to receive     11/11   100/100     0/0       5/5        6/6      0/0      0/0        0/0
technical assistance if
required.
*15. Technical assistance      11/11   100/100     0/0       6/6        5/5      0/0      0/0        0/0
was provided in a timely
manner.
Courseware
16. Course materials were      11/11   100/100     0/0       4/4        7/7      0/0      0/0        0/0
received in a timely
fashion and in good
condition.
17. The pace of course         11/11   100/100     0/0       3/3        8/8      0/0      0/0        0/0
 30                                                                                          AETCI36-2640 15 JULY 2014

material was relative to the
degree of difficulty.
18. The level of interaction     9/9         89/89       11/11          4/4           4/4           2/2          1/1            0/0
enhanced my learning.
19. Course materials were       11/11        91/91         9/9          4/4           6/6           0/0          1/1            0/0
easy to understand and user
friendly.
20. Course pictures and         11/11       100/100        0/0          4/4           7/7           0/0          0/0            0/0
videos were clear and
supported training.
21. Audio added to the          11/11       100/100        0/0          5/5           6/6           0/0          0/0            0/0
lesson presentations.
22. Course materials            11/11       100/100        0/0          4/4           7/7           0/0          0/0            0/0
contained current and
accurate information.
                                                                     5-10 hours      11-20         21-30        31-40        40+ hours
                                                                                     hours         hours        hours
23. Enter the approximate                                               5/5           6/6           0/0          0/0            0/0
number of hours required
to complete the course.
                                                                     PC at work      PC at      Comp Lab       DL class        Other
                                                                                     home
24. Identify your primary       11/11                                   1/1           0/0           2/2          1/1            1/1
learning environment
during course completion.
                                                                    Outstanding    Excellent    Satisfactory   Marginal    Unsatisfactory
25. Overall rating of this      11/11       100/100                     2/2          7/7            2/2          0/0            0/0
course.
Comments

NOTE: *Questions exempt from 90 percent rule. AETC schoolhouse has no direct control over these items for units outside AETC. However,
data, comments, and any applicable corrective actions must be annotated.
AETCI36-2640 15 JULY 2014                                                                        31


                                          Attachment 6
SAMPLE FIELD INTERVIEW (FI) GUIDES (FOR GRADUATES AND SUPERVISORS)

(DO NOT REPRODUCE)
Table A6.1. Sample Interview Format
             SAMPLE FIELD INTERVIEW GUIDE FOR SUPERVISORS:
PART A - BACKGROUND DATA
1. COURSE GRADUATE ATTENDED
2. GRADUATE'S GRADE AND NAME (Last, First, MI)
3. DATE
4. NAME OF SUPERVISOR/GRADE/DSN/E-MAIL
5. DUTY AFSC AND TITLE OF SUPERVISOR
6. LENGTH OF TIME SUPERVISING GRADUATE
7. ORGANIZATION
8. BASE
9. MAJCOM
PART B - FINDINGS (FOR SUPERVISOR OF ENLISTED COURSE GRADUATES ONLY)
1. Are you knowledgeable of the training requirements outlined in the training standard?

        YES     NO

2. Has the graduate performed assigned tasks to the proficiency levels specified for the skill level
in the training standard? (If NO, identify applicable tasks below.)

        YES     NO

3. Has the graduate performed tasks other than those listed in the training standard? (If YES, list
tasks below.)

        YES     NO

4. Does the job performance of the graduate indicate he or she might have received more training
than necessary for particular tasks? (If YES, describe below.)

        YES     NO

5. Has it been necessary to conduct additional training because of apparent deficiencies in the
course? (If YES, describe deficiencies below.)

        YES     NO
 32                                                              AETCI36-2640 15 JULY 2014




6. Is the graduate making satisfactory progress? (If NO, list problems below.)

        YES     NO

7. Do you have any suggestions that would improve this course? (If YES, explain below.)

        YES     NO

8. Please rate the graduate's overall job performance, using the following rating scale. (NOTE:
Please explain a marginal or unsatisfactory rating.)

   OUTSTANDING EXCELLENT SATISFACTORY MARGINAL UNSATISFACTORY

9. Everything considered, are you satisfied with the attitude and motivation of this recent
graduate? (If NO, explain below.)

        YES     NO

PART C - FINDINGS (FOR SUPERVISORS OF SUPPLEMENTAL OR OFFICER
COURSE GRADUATES ONLY)

1. Did the graduate experience any significant difficulty in performing his or her duties that you
consider the result of inadequate training in the course? (If YES, please explain.)

        YES     NO

2. Please rate the graduate's overall job performance using the following rating scale. (Please
explain a marginal or unsatisfactory rating.)

   OUTSTANDING         EXCELLENT       SATISFACTORY         MARGINAL       UNSATISFACTORY

3. Do you have any suggestions that would improve this course? (If YES, explain below.)

        YES     NO

4. Would you recommend this course to others? (Please explain why or why not.)

        YES     NO

PART D - MISCELLANEOUS DATA (FOR ALL SUPERVISORS)

1. Other comments and recommendations regarding the training.
2. Would you like a return phone call from our evaluation office?

        YES     NO     Your DSN:
AETCI36-2640 15 JULY 2014                                                                       33



NAME OF INTERVIEWER

(DO NOT REPRODUCE)

                 SAMPLE FIELD INTERVIEW GUIDE FOR GRADUATES:

PART A - BACKGROUND DATA

 1. COURSE ATTENDED
 2. GRADUATE'S GRADE AND NAME (Last, First, MI) /DSN/E-MAIL
 3. DATE
 4. DATE GRADUATED FROM COURSE
 5. DUTY AFSC
 6. DUTY TITLE
 7. ORGANIZATION
 8. BASE
 9. MAJCOM
PART B - FINDINGS

1. Did the course adequately prepare you to perform all of your present duties? (If NO, please
explain.)

        YES     NO

2. Should more training be given in any particular area(s) of the course? (If YES, please explain.)

        YES     NO

3. Is any part of the training unnecessary? (If YES, please explain.)

        YES     NO

4. Do you have any specific recommendations for improving the course? (If YES, please
explain.)

        YES     NO

5. Please rate how well you were trained overall to perform your job. (NOTE: Please explain a
marginal or unsatisfactory rating.)

   OUTSTANDING         EXCELLENT        SATISFACTORY         MARGINAL       UNSATISFACTORY
 34                                                             AETCI36-2640 15 JULY 2014



PART C - MISCELLANEOUS DATA

1. Other comments/recommendations regarding training.
2. Would you like a return phone call from our evaluation office?

        YES     NO     Your DSN:

NAME OF INTERVIEWER
AETCI36-2640 15 JULY 2014                                                         35


                                          Attachment 7
   SAMPLE CUSTOMER SERVICE INFORMATION PROCESS (CSIP) TEMPLATE

(DO NOT REPRODUCE)

Table A.7.1. Sample Customer Service

Control No:

Received By:           Date:     Time:

Data Received Via:     Phone     Letter    E-mail    Other

Requester's Name, Grade, and DSN:

Mailing Address

Graduate's Name and Grade:

Graduation Date        Course Attended

Course Title:          Training Standard Date:

Problem/Concern:

           RESPONSE

Answered in Eval by:           Date:                Time:

Suspense Date:                 Received By:         Date:

Who Responded?                 Section: Date:       Time:

Responded By (Circle One):     Phone      Letter    E-mail     Other

Nature of Response:

Copies Sent To:                MAJCOM         AFCFM         2 AF/TTOC     Other

Remarks:
                                                                           
Customer Expressed Satisfaction              Customer Satisfaction Sent
 36                                                             AETCI36-2640 15 JULY 2014


                                         Attachment 8
                 FIELD EVALUATION QUESTIONNAIRE DEVELOPMENT

A8.1. Factors to Consider When Designing Questionnaires for the USAF Graduate
Evaluation Program. When evaluators construct the field evaluation questionnaire, the
following three major areas should be considered:
   A8.1.1. Obtaining Data to Meet the Objectives of Field Evaluation. The objective of
   every evaluation project is to determine if graduates are adequately trained to perform the
   tasks taught in the course and required in the field. For officer and enlisted initial skills
   courses, standard questions will be added for supervisors of non-prior service (NPS)
   graduates (see Paragraph A8.3). These standard questions will be used to determine the
   adequacy of further military training provided NPS students while attending the initial skill
   technical training course(s). Word the questionnaire so it can be understood and answered
   with relative ease. Extensive background questions may also be used to permit meaningful
   analysis of data received. Questions of observable performance should be used where
   possible. Emphasis should be on tasks taught in the course. Limit questions on knowledge-
   level objectives to a minimum. When developing the initial FEQ, emphasis should be on
   surveying major training standard items rather than on surveying individual training standard
   items. Individual items may be surveyed in a subsequent survey if there are indicators of a
   problem in a particular area.
   A8.1.2. Providing       Sufficient    Instructions    to    Ensure       Completion      of
   Questionnaires. State the purpose of the survey, authority under which it is conducted,
   suspense date for completion, and to whom questions can be referred. Provide information on
   the importance of the survey and the mechanics of how to complete the questionnaire.
   A8.1.3. Designing Questionnaires for the AETC Graduate Evaluation Data
   System. Design questionnaires for use with a standardized computer analysis program.
   Written comments can also be obtained from the respondent by providing a remarks section
   on the questionnaire.
A8.2. First Question on Both Questionnaires. If the questionnaire cannot be completed, this
question will ask the respondent to indicate why. This question is mandatory. He or she will pick
an answer from the following choices:

Table A8.1. Questionnaire
 Supervisor Questionnaire                                   Graduate Questionnaire
 0 - Working in another AFSC (explain on remarks sheet)     0 - Working in another AFSC
 1 - Discharge                                              1 - Awaiting security clearance
 2 - Member does not meet standards of conduct              2 - Working in another duty position
 3 - No security clearance                                  3 - Attending additional formal training
 4 - Transferred/reassigned                                 4 - Medically disqualified
 5 - Not assigned/assignment canceled                       5 - Working in Quality Control
AETCI36-2640 15 JULY 2014                                                                        37


 6 - Disqualified under Personnel Reliability Program          6 - Working in Job/Production Control
 7 - Medically disqualified                                    7 - Other (explain on remarks sheet)
 8 - Other (explain on remarks sheet)

A8.3. Second Question on the Supervisor Questionnaire for enlisted and officer initial skills
course graduates: “Are you the supervisor of a non-prior service (NPS) officer or enlisted initial
skill graduate?” If the response is “No”, then direct supervisors to skip Q# 3- Q# 9. If the
response is “Yes”, direct supervisors to respond to Q# 3 – Q# 9. Standard questions and rating
scale in Tables A8.2 and A8.3 will be included on all supervisor FEQs for enlisted and officer,
respectively (to include AFRC and ANG) initial skill Types 3, 5, 8, 9, A, B, and C courses
(AB/OB in 3rd and 4th position of course number) as identified below.
A8.4. ENLISTED FEQ. Request comments for Does Not Meet Standards, Below
Standards, and Well Below Standards responses.

Table A8.2. NPS Enlisted Initial Skills FEQ Questions/Rating Scale/Responses
Question #3
What is your assessment of the graduate’s observance of military bearing and customs and
courtesies to include proper reporting procedures, proper rendering of the salute, respect for the
flag, and display of Air Force Core Values?

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

For ratings of 1, 2, and 3, please identify the specific deficiency so it can be adequately
addressed. Check one or more that apply:

- Financial Irresponsibility
- Personal Accountability
- Non-Team Player
- Customs/Courtesies
- Immaturity
- Substance Abuse
- Lack of Discipline
- Lack of Respect
- Disrespect for Authority
- Lack of Integrity
- Late for Duty
- Misses Appointments
- Lack of Interest
- Other (This selection requires a comment.)
 38                                                                AETCI36-2640 15 JULY 2014



Question #4
What is your assessment of the graduate’s observance of Air Force standards for dress and
personal appearance to include proper wear of uniform combinations?

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

Question #5
Based on your initial evaluation as required by AFI 36-2201 how would you rate the graduate’s
ability to perform hands-on tasks at the proficiency levels specified in the 3-level course column
in the CFETP/STS?

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

For ratings of 1, 2, and 3, please identify the task(s) and graduate’s actual proficiency level using
the proficiency code key in the CFETP/STS and check one or more of the following that apply:

- Lack of Subject Knowledge
- Failure to Follow Instructions
- Lack of Technical Skills
- Lack of Responsibility
- Poor Reading Skills
- Inability to Use Publications/TOs
- Failure to Follow Safety Procedures
- Poor Communication Skills
- Physical Limitations
- Other (This selection requires a comment.)

Question #6
Based on your initial evaluation as required by AFI 36-2201 how would you rate the graduate's
understanding of the subject knowledge items specified in the 3-level course column in the
CFETP/STS?

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
AETCI36-2640 15 JULY 2014                                                                         39


4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

Question #7
What is your assessment of the graduate’s ability to effectively use references (i.e., instructions,
technical orders, commercial publications, etc.) listed for items in the 3-level course column of
the CFETP/STS? For ratings of 1, 2, and 3, please identify in your comments the specific
references you felt the graduate could not effectively use.

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

Question #8
What is your assessment of the graduate’s ability to effectively use required support equipment
(i.e., diagnostic equipment, test equipment, computer systems, tools, instruments, etc.) to perform
his/her 3-level duties? For ratings 1, 2 and 3, please identify in your comments the specific
support equipment you felt the graduate could not effectively use.

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

Question #9
How well do the items and/or associated proficiency levels listed in the CFETP/STS meet the 3-
level job requirements in your work center? For ratings 1, 2 and 3, please identify in your
comments task(s) not currently in the CFETP/STS you feel 3-levels in your workplace need to
perform or task(s) where a different level of proficiency is required.

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

For ratings of 1, 2, and 3, describe the specific deficiency so it can be adequately addressed.
Check one or more that apply:
 40                                                                AETCI36-2640 15 JULY 2014


- Working Outside Primary Duty
- Working on Unique Equipment
- 3-Level CFETP Tasks Not Applicable to this Location
- Other (This selection requires a comment.)




A8.5. OFFICER FEQ. Request comments for Does Not Meet Standards, Below Standards,
and Well Below Standards responses.

Table A8.3. NPS Officer Initials Skills FEQ Questions/Rating Scale/Responses.
Question #3
What is your assessment of the graduate’s observance of military bearing, customs and courtesies,
and display of Air Force Core Values?

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

For ratings of 1, 2, and 3, please identify the specific deficiency so it can be adequately addressed.
Check one or more that apply:

- Financial Irresponsibility
- Personal Accountability
- Non-Team Player
- Customs/Courtesies
- Immaturity
- Substance Abuse
- Lack of Discipline
- Lack of Respect
- Disrespect for Authority
- Lack of Integrity
- Late for Duty
- Misses Appointments
- Lack of Interest
- Other (This selection requires a comment.)

Question #4
What is your assessment of the graduate’s observance of Air Force standards for dress and
personal appearance to include proper wear of uniform combinations?

1 - Well Below Standards / Unacceptable
AETCI36-2640 15 JULY 2014                                                                         41


2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

Question #5
Based on your initial evaluation as required by AFI 36-2201 how would you rate the graduate’s
ability to perform hands-on tasks effectively?

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

For ratings of 1, 2, and 3, please identify the task(s) and check one or more of the following that
apply:

- Lack of Subject Knowledge
- Failure to Follow Instructions
- Lack of Technical Skills
- Lack of Responsibility
- Poor Reading Skills
- Inability to Use Publications/TOs
- Failure to Follow Safety Procedures
- Poor Communication Skills
- Physical Limitations
- Other (This selection requires a comment.)

Question #6
Based on your initial evaluation as required by AFI 36-2201 how would you rate the graduate’s
understanding of subject knowledge items in performing his/her duties effectively?

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

Question #7
What is your assessment of the graduate’s ability to effectively use references (i.e., instructions,
technical orders, commercial publications, etc.) to perform his/her duties? For ratings of 1, 2, and
3, please identify in your comments the specific references you felt the graduate could not
 42                                                                AETCI36-2640 15 JULY 2014


effectively use.

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

Question #8
What is your assessment of the graduate’s ability to effectively use required support equipment
(i.e., diagnostic equipment, test equipment, computer systems, tools, instruments, etc.) to perform
his/her duties? For ratings 1, 2 and 3, please identify in your comments the specific support
equipment you felt the graduate could not effectively use.

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding


Question #9
How well did the training received by the graduate meet job requirements in your work center?
For ratings 1, 2 and 3, please identify in your comments task(s) not currently trained you feel
initial skill officers in your workplace need to perform or task(s) where a different level of
proficiency is required.

1 - Well Below Standards / Unacceptable
2 - Below Standards / Unsatisfactory
3 - Does Not Meet Standards / Marginal
4 - Meets Standards / Satisfactory
5 - Above Standards / Excellent
6 - Well Above Standards / Outstanding

For ratings of 1, 2, and 3, describe the specific deficiency so it can be adequately addressed.
Check one or more that apply:

- Workcenter has specialized requirements
- Workcenter has specialized equipment and hardware
- Training is not appropriate for workcenter mission
- Training is not in-depth enough
- Other (This selection requires a comment.)

Notes:
AETCI36-2640 15 JULY 2014                                                                        43


1. Rating Scale. The FEQ is used to determine if graduates were trained as specified in the
training standard. In order to meet this objective, the rating scale should mirror the training
standard proficiency requirements as closely as possible. When surveying supervisors, use the
task performance proficiency code descriptions (for example, Extremely Limited, Partially
Proficient, etc.) whenever possible. Limit the use of satisfaction levels to only those FEQs that the
proficiency code does not apply to or when surveying graduates about the training they received.

2. Last Question on the Supervisor’s Questionnaire. Include a question that asks the
supervisor to rate the graduate’s overall preparation for the job. For example, “Based on your
responses to (items one through the last question relating to the Specialty Training Standard
(STS)/Course Training Standard (CTS)), please provide an overall rating of how well the course
(list course name) prepared the graduate to perform assigned duties as an apprentice (enter job
title).” Use the following rating scale.

1-   Well Below Standards / Unacceptable
2-   Below Standards / Unsatisfactory
3-   Does Not Meet Standards / Marginal
4-   Meets Standards / Satisfactory
5-   Above Standards / Excellent
6-   Well Above Standards / Outstanding

3. Last Question on the Graduate’s Questionnaire. Include a question that asks the graduate to
rate the overall training provided. For example, “How would you rate the overall training
provided?” Use the following rating scale.

1-   Well Below Standards / Unacceptable
2-   Below Standards / Unsatisfactory
3-   Does Not Meet Standards / Marginal
4-   Meets Standards / Satisfactory
5-   Above Standards / Excellent
6-   Well Above Standards / Outstanding
 44                                                            AETCI36-2640 15 JULY 2014


                                        Attachment 9
      FORMAT FOR FIELD EVALUATION QUESTIONNAIRE SUMMARY (FEQS)

Table A9.1. Sample FEQS
Course Title:
Course Number:
CFETP Date:
Course Length:       ___ days
Instructional Design: (Group-Paced, Self-Paced, etc.)
Elimination Rate (as applicable, rounded to the nearest whole percent): ____%
Annual STR/TPR: Current FY Programmed ___/__            Previous FY Graduates ___/__
Sampling Period: __________to ____________ Number of Graduates: _______
Number of Questionnaires: Sent: _____ Returned:_____ Usable: ______
Questionnaire Return Rate: ____% (rounded to whole percent)
Confidence Level Required:____%           Achieved:____% (rounded to whole percent)

Overall Rating of Training Provided:____% (rounded to whole percent)
Number of Tasks Failing to Meet 90% Adequacy Criterion:      ___ of ____
Number of Tasks Failing to Meet 30% Utilization Criterion: ___ of ____

Summary of Findings and Corrective Actions Taken or Planned: During the sampling
period of Jan-Mar 2014, 500 students graduated from the (blank) course and IAW AETCI 36-
2640 Table 1, Graduate Sampling, 222 returned-usable surveys are required to meet the 95%
confidence level. Of the 100 task items surveyed, 25 fell below the 90% adequacy and 6 did not
meet the 30% Utilization rate (See Attachments 1-4 for supporting data).

FEQ Supervisor/Graduate Comments: (Summary or list of comments with NO NAMES OR
PERSONALLY IDENTIFYING INFORMATION; STS reference, Proficiency Code, Current
Adequacy Criterion. Distinguish between supervisor or graduate comments (see Attachment 5
for complete list [if applicable])
        AETCI36-2640 15 JULY 2014                                                                   45


         ADDITIONAL TRAINING EVALUATION DATA

         Field Interviews: Number of personnel interviewed (graduates, supervisors or both) and
         locations, with comment summary. If none conducted enter NONE. (May include FI report)

         End-of-Course Critique Student Feedback Survey: (Summary of comments and ratings)

         Customer Service Information line (CSIL): Number of calls related to the course in
         question…if none enter NONE.

         Occupational Analysis Report (OAR), if applicable: Compare the OAR training report to
         feeback received through internal and external evaluations as applicable.

         Previous FEQ Summary: Short synopsis (Example):
         The last FEQS was completed on 12 March, 2012 and is/is not based on the same CFETP date
         of 1 Nov 2010. The survey of 158 graduates produced a confidence level of 98%. Correlation
         between the previous FEQS and this one shows the overall satisfaction improved from 95% to
         100%. The number tasks failing to meet the 30% utilization criterion remained at zero. The
         number of tasks failing to meet 90% adequacy criterion fell from 5 to zero.

_____                                            ___________________________         ___________
                                                   (Training Group Commander's Signature) Date

        Attachment(s):
        1. STS/CTS Data Summary from AETC TQA (web) query
        2. FEQ Survey Returns Report (TQA)
        3. TTMS Upfront Production Numbers for Sampling Period (screen capture)
        4. Tasks Failing to Meet the 90% Adequacy and/or 30% Utilization Criterion
        5. FEQ Comments (Summary or list of comments with NO NAMES OR PERSONALLY
        IDENTIFYING INFORMATION; STS reference, Proficiency code and Current Adequacy
        Criterion)
        Note: Add additional attachments as required to support conclusions, i.e. comment matrix from
        End-of-Course Student Feedback Survey
46                                                      AETCI36-2640 15 JULY 2014



STS     Prof
REF     Code      Title      Adequacy   Utilization      Corrective Action          ECD
40.4.    b     Identify        71%         82%        This STS line item is      N/A
               law of                                 covered by Block IV
               supply and                             text material and
               demand                                 lecture. Definitions of
               procedures.                            supply and demand as
                                                      well as the three steps
                                                      (procedures) for
                                                      determining supply and
                                                      demand are stressed in
                                                      both lecture and text.
                                                      Student comprehension
                                                      is measured by
                                                      progress check and on
                                                      the block test with
                                                      questions relevant to
                                                      the steps (procedures).
                                                      The course material
                                                      covers this topic to the
                                                      b level in this course.
                                                      After reviewing the
                                                      AETC Form 668,
                                                      student comprehension
                                                      appears to be 88% on
                                                      average. This line item
                                                      will be discussed at the
                                                      upcoming U&TW for
                                                      possible deletion from
                                                      the STS. .No action is
                                                      required.
