BY ORDER OF THE COMMANDER                                                AFMC INSTRUCTION 99-103
AIR FORCE MATERIEL COMMAND                                                        22 NOVEMBER 2004

                                                                                    Test and Evaluation

                                                                                TEST MANAGEMENT




                 COMPLIANCE WITH THIS PUBLICATION IS MANDATORY

NOTICE:        This publication is available digitally on the AFDPO WWW site at:
               http://www.e-publishing.af.mil.

OPR: HQ AFMC/DOF (Lt Col David Snyder)                Certified by: HQ AFMC/DOF (Col Stetson Siler)
                                                                                        Pages: 18
                                                                                   Distribution: F

This Air Force Materiel Command (AFMC) Instruction (AFMCI) implements AFMC Policy Directive
(AFMCPD) 99-1, Test Management, and Air Force Instruction (AFI) 99-103, Capabilities Based Test and
Evaluation. Additionally, it consolidates policies contained within AFMCPD 99-2/AFMCI 99-201, Test
Representatives (TESTREP) (4 Jun 1996), and AFMCPD 99-1, Risk Management (13 May 1998) into one
cohesive policy document. This AFMCI outlines developmental test and evaluation (DT&E) policy and
organizational responsibilities within AFMC. It provides the procedures for establishing Test Representa-
tives (TESTREP) and Center Test Authorities (CTA) at each AFMC center. It is applicable to all AFMC
organizations. This instruction applies to all personnel who conduct or are involved with test and evalua-
tion (T&E) of all types and acquisition category (ACAT) levels, to include subsystems, components; and
commercial off-the-shelf (COTS) and non-developmental item (NDI) systems. This instruction must be
used in conjunction with AFI 99-103, Capabilities Based Test and Evaluation, AFI 63-101, Operation of
the Capabilities Based Acquisition System, AFI 91-202/AFMC Supplement 1, The US Air Force Mishap
Prevention Program; AFI 91-204, Safety Investigations and Reports; and AFMCPAM 63-101, Risk Man-
agement. This instruction applies to T&E conducted by/for AFMC’s test centers, product centers, air
logistics centers (ALC), and the Air Force Research Laboratory (AFRL) whether or not it is conducted
with AFMC-owned or controlled test assets.
2                                                                 AFMCI99-103 22 NOVEMBER 2004


                                                Chapter 1

                                 INTRODUCTION AND OVERVIEW

1.1. Collaboration and Early Tester Involvement: These two concepts are the cornerstones to achiev-
ing “Capabilities Based T&E”. AFI 99-103 defines the integrated test team (ITT) as the mechanism to
achieve collaboration. Additionally, even before an ITT is formed, testers must be involved early on in all
acquisition and sustainment programs to infuse testability and operational realism into requirements
development while ensuring test assets will be available to test the potential capability when required.
This includes COTS, NDI, potential form-fit-function-interface changes, modifications, field service
evaluations, shelf life evaluations, source qualifications, and acceptance tests. Testers, through the ITT,
must determine the level and types of testing required and document these decisions in T&E Strategies,
T&E Master Plans (TEMP), and other program documents. Additionally, testers must be knowledgeable
of capability gaps/requirements and science and technology initiatives that may require T&E infrastruc-
ture investment early on. This is done via AFMC’s involvement with USAF/XOR’s capabilities require-
ments process as outlined in AFI 10-601, Capabilities Based Requirements Development, and
involvement on their high performance teams (HPT).

1.2. AFMC T&E Organizations. Figure 1.1. illustrates the AFMC T&E organizational construct. Each
center commander reports directly to AFMC/CC. The 46TW reports to the AAC/CC. Each product center
commander is also dual-hatted as the program executive officer (PEO) for their respective portfolio of
acquisition programs. ALC commanders are responsible to AFMC/CC for their respective portfolio of
sustainment programs. The test center/wing commanders are responsible for providing test resources and
services to their customers within the product/logistic centers.
    1.2.1. AFMC/DO: AFMC/DO is charged by AFMC/CC to shape the workforce and infrastructure for
    conducting operations to test, field, and sustain war-winning expeditionary capabilities. Overall,
    AFMC/DO advocates for funds and provides infrastructure and resource support for the command’s
    operational and test equipment and facilities. AFMC DO provides for management and oversight of
    the command’s aircraft, airfields, airspace, ranges, weather systems and air traffic control and landing
    systems. AFMC/DO manages the HQ AFMC Battle Staff and the AFMC Command Center, which
    directs and coordinates all AFMC deployment and mobility planning, unit tasking, and movement
    control. In support of the Defense Acquisition System, AFMC/DO is responsible to oversee the sys-
    tem fielding process; ensuring systems are delivered to the warfighter “on time, on cost.” In particular
    support of T&E and this instruction, AFMC/DO is responsible for T&E policy development, informa-
    tion management, and program support across the network of test, product and logistics centers. See
    paragraph 2.1.
    1.2.2. Center Test Authorities (CTA): Just as AFMC/DO acts as the command’s overarching T&E
    authority, each product and ALC commander shall have a CTA to act as advisor on test issues. The
    CTA maintains oversight of the center’s T&E processes, while assisting program managers (PM)/
    ITTs in developing their own test programs. CTAs act as the center T&E advocate for T&E policy,
    training, and resources. See paragraph 2.2.
    1.2.3. Test Representatives (TESTREP): TESTREPs provide for an on-site liaison between a test cen-
    ter/wing and their primary ALC or product center customer(s). See 2.3..
AFMCI99-103 22 NOVEMBER 2004            3


Figure 1.1. AFMC Test Support Network
4                                                                  AFMCI99-103 22 NOVEMBER 2004


1.3. Information Management. Effective management of information is critical to ensure cohesiveness
of policies and procedures, as necessary, across AFMC. As the command’s test authority, AFMC/DO will
act as a central repository of T&E information, to include lessons learned, best practices, and other infor-
mation as required. The USAF Test Pilot School will act as AFMC/DO’s center of knowledge and exper-
tise for all flight test techniques and flight test methods. Additionally, in light of integrated testing as it
applies to Agile Acquisition, AFMC/DO will act as the command’s central point of contact (POC) to the
Air Force Operational Test and Evaluation Center (AFOTEC), USAF/TE, and other external agencies, to
ensure consistency and proper dissemination of information throughout the command.

1.4. Test Risk Management. Prior to test conduct, each test plan will be subjected to technical and
safety reviews IAW AFI 99-103, AFI 91-202, and AFI 91-202/AFMC Sup 1. Each center will develop
local procedures for conducting these reviews. All T&E will be conducted in accordance with an
approved plan. Test plans will be prepared to meet the objectives defined and agreed to by the PM and the
organization conducting the test. The PM and the organization conducting the test will evaluate test objec-
tives with respect to risks and costs prior to test plan development to identify potential areas of unjustified
risk. The test approval authority (see Attachment 1) assumes the risk associated with test conduct and
shall lead each of the following reviews.
    1.4.1. Technical Review: The technical review process will ensure a thorough assessment of the test
    plan for technical soundness and adequacy. The technical review will verify that the overall method of
    test and test data acquisition is adequate to evaluate the requirements and to verify objectives can be
    met with acceptable technical risk.
    1.4.2. Safety Review: The safety review process will ensure a thorough assessment of the adequacy
    of test safety planning. Hazards unique to the test conduct will be identified. Pre-existing hazards
    associated with the weapon system shall be considered in the test hazard analysis. Test mishap
    accountability will be clearly documented. The safety review will evaluate the extent to which the
    severity and the probability of occurrence of known hazards have been minimized and assess the
    residual safety risk. The test approval authority must accept the residual level of safety risk.
    1.4.3. Test Readiness Review (TRR): The readiness review process is conducted before the com-
    mencement of testing for new-starts and system upgrades, test milestones (e.g. first flight/launch,
    etc.), or after an extended break in test activity (e.g. transition in acquisition program phase, mishap
    investigation, etc.). The TRR will ensure all preparations for initiating a test have been completed and
    known anomalies have not compromised the execution of the test. All reasonable efforts to minimize
    risk must be made and verified to the test approval authority.
    1.4.4. Tailored Reviews: Center/wing commanders, PMs, and their designees may implement addi-
    tional reviews and assessments to ensure high confidence in a system’s readiness for test with an
    acceptable level of risk. Center/unit commanders and PMs may combine reviews or otherwise stream-
    line the review processes. A test program may require different approval authorities for safety, techni-
    cal, and program risk. Review processes may be streamlined as appropriate to the level of risk. Any
    streamlined approach must still confirm a level of safety risk, technical risk and test readiness consis-
    tent with the test risk assessment.
    1.4.5. Additional Test Safety Risk Management Requirements:
AFMCI99-103 22 NOVEMBER 2004                                                                               5


       1.4.5.1. Use of Non-Test Pilot School (TPS) Pilots. Piloting of medium and high-risk events by
       other than graduates of a TPS will be specifically documented in the test plan for consideration by
       the test approval authority.
       1.4.5.2. Radio Frequency (RF) Dependent Systems Tests: Test and Evaluation of any RF depen-
       dent device, to include COTS and NDI, shall be conducted in accordance with DoD Directive
       (DoDD) 4650.1. Specifically, tests will be conducted only when appropriate equipment allocation
       (spectrum certification) guidance as prescribed under AFI 33-118 is in place.

1.5. Test Infrastructure and Resource Planning. Having adequate test assets and qualified test person-
nel when needed is the responsibility of each test center/wing. As an example, test plans that include load-
ing weapons on aircraft must include sufficient load crew certification time for the specific weapon to be
loaded IAW AFI 21-101, Aerospace Equipment Maintenance Management. ITTs will plan for the pro-
curement and disposition of any munitions items as early in the planning process as possible IAW AFI
21-201, Management and Maintenance of Non-Nuclear Munitions (contact HQ AFMC/LGMW for assis-
tance). Test centers shall identify, as early as possible, test requirement gaps based on expected capability
development initiatives and other means. Resources required to fill these gaps shall be planned and
secured for IAW AFI 99-109, Test & Evaluation Resource Planning.

1.6. Modeling and Simulation (M&S). PMs shall consider M&S during test planning. Integrated test
plans shall address M&S IAW AFI 16-1002, Modeling and Simulation Support to Acquisition and AFI
14-206, Modeling and Simulation. PMs shall take advantage of M&S capabilities used to develop the sys-
tem to limit test requirements while preserving risk reduction and sound systems engineering. M&S for
capability planning and acquisition development should enhance continuous virtual test range activities
and lay the groundwork for sustainment M&S. USAF Test Pilot School shall provide adequate training in
M&S.
6                                                                 AFMCI99-103 22 NOVEMBER 2004


                                                Chapter 2

                     ORGANIZATIONAL ROLES AND RESPONSIBILITIES

2.1. AFMC/DO.
    2.1.1. Position Requirements: All AFMC/DO personnel responsible for T&E policy or resourcing
    shall possess a minimum Acquisition Professional Development Program (APDP) level 2 certification
    in T&E (or equivalent). Additionally, it is desired that AFMC/DO T&E personnel:
       2.1.1.1. Be a military test pilot school graduate or have at least four years of testing experience.
       2.1.1.2. Occupy at least a Major level position or civilian grade equivalent.
       2.1.1.3. Have System Program Office experience (acquisition or sustainment related).
    2.1.2. Responsibilities: In addition to those responsibilities listed in AFI 99-103, AFMC/DO will:
       2.1.2.1. Ensure that all AFMC test centers/wings and the USAF Test Pilot School are resourced
       IAW AFI 99-109, Test & Evaluation Resource Planning.
       2.1.2.2. Develop T&E training courses as required. Manage the APDP certification program for
       all AFMC T&E personnel.
       2.1.2.3. Manage T&E information networks and data repositories.
       2.1.2.4. Inspect AFMC units for compliance and certification; through the AFMC Inspector Gen-
       eral (IG) for formal inspections, and unilaterally through the use of Staff Assistance Visits.
       2.1.2.5. Act as the command T&E POC to HQ USAF/XOR for HPT participation by providing
       early tester involvement in the requirements process.
       2.1.2.6. Act as AFMC POC to AFOTEC, MAJCOMs, and other external test agencies for over-
       arching integrated testing issues.
       2.1.2.7. Support the USAF Test Pilot School IAW AFI 99-107, Test Pilot School (PA).

2.2. Center Test Authority: Commanders of product centers and ALCs will establish a CTA for T&E
and establish local procedures for implementing the center’s T&E process consistent with the DoD
5000-series regulations, AFI 99-103, and this instruction. The goal of each CTA is to provide a single face
to the PM for test program assistance and to the center leadership for issues concerning T&E policy and
procedures as they relate to acquisition decision making.
    2.2.1. Position Requirements: Center Test Authorities shall be staffed with sufficient personnel profi-
    cient in the performance of T&E (APDP T&E Level 1 certified or equivalent) and who possess basic
    knowledge of:
       2.2.1.1. Pre- and post-award T&E strategy development.
       2.2.1.2. T&E documentation development and review.
       2.2.1.3. T&E regulations, standards, and techniques for management of all phases of development
       including modeling and simulation, component-level, and system-level testing.
       2.2.1.4. Modification management and configuration control.
AFMCI99-103 22 NOVEMBER 2004                                                                            7


       2.2.1.5. Technical Review Board (TRB), Safety Review Board (SRB) and TRR conduct.
       2.2.1.6. Available DoD, AF, AFMC T&E resources, facilities, and related capabilities of each.
       2.2.1.7. ITT, Combined Test Force (CTF) or other test team operations.
   2.2.2. Responsibilities. CTAs will:
       2.2.2.1. Advise center command staff on T&E policy and related issues, to include, but not lim-
       ited to the certification of system readiness for operational testing according to AFI 63-119, Cer-
       tification of System Readiness for Dedicated Operational Test and Evaluation.
       2.2.2.2. Participate in program decision meetings (e.g. Acquisition Strategy Panels (ASP)), Con-
       figuration Control Boards (CCB), product improvement working groups, and test management
       councils as required.
       2.2.2.3. Advocate for T&E training and human resource development.
       2.2.2.4. Represent the center on T&E issues to HQ AFMC, USAF/TE, MAJCOMs, and other
       external agencies.
       2.2.2.5. Assist/advise PMs and ITTs in the development and review of T&E and related program
       documentation, to include integrated test strategies, concepts and plans.
       2.2.2.6. Participate in TRB, SRB, and TRRs as required. Provide independent technical and test
       safety risk assessments, and ensure appropriate participation and level of coordination/approval of
       TRBs and SRBs for all testing that does not use an approved RTO.
       2.2.2.7. Oversee the center’s Responsible Test Organization (RTO) approval process, coordinate
       on ITT RTO recommendations to the PEO or designated representative, and inform AFMC/DO of
       all center RTO decisions on a periodic basis.
       2.2.2.8. Support PMs in establishing ITTs and developing ITT charters.
       2.2.2.9. Maintain insight into all T&E programs being conducted at, on or for the center.
       2.2.2.10. Provide center-level oversight of the center’s T&E resource management procedures
       (use, re-use, and disposal), test capability development activities, and T&E support agreement
       establishment.
       2.2.2.11. Provide oversight of center compliance with test policies and procedures.
       2.2.2.12. (ALC CTAs) Establish processes and maintain and manage requisite capabilities to con-
       duct low risk, low cost, short duration developmental T&E (DT&E), qualification T&E (QT&E),
       and sustainment testing on legacy systems the ALC supports. These tests should be of the type and
       scope normally not conducted by AFMC test centers due to their limited cost/risk or accelerated
       schedule considerations.

2.3. Test Representatives (TESTREP): A TESTREP is an owning test center/wing’s liaison provided
to a host product or logistics center, usually working within their respective CTA. TESTREPs facilitate
networking between testers and PMs at each center, while bringing test center resources to bear to assist
PMs in executing their programs. Commanders of test centers/wings will assign a TESTREP to work with
each of their primary customer’s product or logistics centers. Co-located TESTREP manpower authoriza-
tions will be sourced from the appropriate test center/wing’s existing manpower resources. The assign-
ment of TESTREPs will be contingent on specific host center needs, test center desires, and the
8                                                                 AFMCI99-103 22 NOVEMBER 2004


corresponding agreement between the host center and the owning test center/wing. The number of
TESTREP positions at each center is at the host center commander’s discretion, by mutual agreement
with the appropriate owning test center/wing commander. Procedures for documenting TESTREP perfor-
mance (to include writing appraisals, awards, and recommendations; and providing performance feed-
back) shall be defined by mutual agreement between the host center and owning test center/wing. Specific
TESTREP responsibilities, in addition to those listed in this instruction, should be established via a mem-
orandum of agreement (see Attachment 2). AFMC/DO shall be informed of all TESTREP assignment
decisions.
    2.3.1. Position Requirements. As a core set of qualifications, TESTREPs should:
       2.3.1.1. Possess a minimum APDP T&E level 2 certification (or equivalent).
       2.3.1.2. Be a military test pilot school graduate or have at least four years of testing experience at
       an AFMC test center/wing.
       2.3.1.3. Occupy at least a Major level position or civilian grade equivalent.
    2.3.2. Responsibilities: TESTREPs will:
       2.3.2.1. Advise the owning test center/wing, host center leadership, and PMs on issues related to
       test infrastructure requirements and test resource availability.
       2.3.2.2. Assist the CTA in the formulation of host center T&E policies and processes.
       2.3.2.3. Provide advice and consultation to the CTA, local DT&E organizations, and PMs on the
       development of T&E strategies, plans, and other related T&E documentation.
       2.3.2.4. Participate in meetings where emerging test requirements may be identified (e.g. ASPs)
       and coordinate future requirements with the owning test center.
       2.3.2.5. As required, participate on CCBs, product improvement working groups, and test man-
       agement councils.
       2.3.2.6. Ensure oversight requirements are met with the owning test center/wing through test pro-
       gram introduction sheets, TRBs and SRBs, and/or other means.
       2.3.2.7. Provide physical oversight and assistance, to include in-flight participation, when appro-
       priate and authorized, at test execution locations.
       2.3.2.8. Provide inputs to affected organizations for AF Test Investment Planning and Program-
       ming (TIPP) investments for future test capabilities that are in line with program office test
       requirements.

2.4. Responsible Test Organizations (RTO): RTOs are developmental test agencies qualified to plan,
conduct, and report on government DT&E and oversee contractor DT&E. RTOs can provide PMs with
much needed technical insight into contractor testing. In addition, the RTO provides insight to the PM as
to how well the system design and performance is likely to meet warfighter needs as it matures during
DT&E. AFI 99-103 states that an RTO is “the lead government developmental test organization that is
responsible for overseeing and/or conducting DT&E.”. AFI 99-103 mandates that the decision to use an
RTO is the PEO’s or his designated representative’s. For sustainment programs not assigned to a PEO, the
RTO decision authority shall be the logistics center commander overseeing the program or his designated
representative.
AFMCI99-103 22 NOVEMBER 2004                                                                             9


   2.4.1. Qualifications. RTO selection shall be based on an organization’s capabilities, qualifications,
   and the corresponding requirements of the test program. Because test activities may not necessarily be
   conducted at the RTO’s facilities, RTOs should be familiar with the operation of all such facilities and
   associated resources involved with any tests they oversee. Information to assist the ITT in its decision
   to use an RTO or to assist in the selection of the appropriate organization can be found at
   https://www.afmc-mil.wpafb.af.mil/HQ-AFMC/DO/dop/rtopage.htm.
   2.4.2. Responsibilities: In addition to those responsibilities listed in AFI 99-103, RTOs will:
      2.4.2.1. Coordinate with Participating Test Organizations (PTO) to ensure corporate expertise and
      required capabilities are brought to bear in support of PMs.
      2.4.2.2. Ensure T&E plans are coordinated with the appropriate test agencies, PTOs, and all other
      stakeholders.
      2.4.2.3. Participate on TRBs and SRBs, CCBs, product improvement working groups, and test
      management councils as required.
      2.4.2.4. Ensure that the test is conducted IAW an approved test plan and test safety documenta-
      tion, regardless of whether the RTO conducts the test or assigns conduct to a PTO.
      2.4.2.5. Ensure T-2 modifications on aerospace vehicles are approved IAW AFMCI 21-126, or by
      the PM (or designated representative) for all other systems.
      2.4.2.6. Provide oversight of combined DT&E and OT&E flight testing until the safety of the
      modification has been verified.
      2.4.2.7. Ensure that safety concerns, deficiencies, and watch items are tracked and reported
      according to TO 00-35D-54, USAF Deficiency Reporting and Investigating System.
      2.4.2.8. Provide recommendations in support of required certifications, and incremental and
      major and milestone decisions.
      2.4.2.9. Ensure that valid test measurement and data acquisition methods are utilized in the report-
      ing of test results.

2.5. Test Centers/Wings:
   2.5.1. Responsibilities. Test centers/wings will:
      2.5.1.1. Plan and provision for, execute, analyze and report on assigned testing.
      2.5.1.2. Research and plan for upcoming resource requirements to include infrastructure improve-
      ments to support future T&E activities IAW AFI 99-109.
      2.5.1.3. Attend HPT meetings as required.
      2.5.1.4. Plan and budget for early tester involvement activities as required.
      2.5.1.5. Assign and man TESTREPs at primary customer centers as appropriate.
      2.5.1.6. Develop TESTREP Memorandums of Agreement (MOA) with each host center/wing.
      2.5.1.7. Review program introduction documents and provide test expertise and advice as
      requested, in support of the local TESTREP(s).
10                                                               AFMCI99-103 22 NOVEMBER 2004


2.6. Product Centers and ALCs:
     2.6.1. Responsibilities. ALC Commanders, like their PEO counterparts (IAW AFI 99-103), will
     approve or delegate approval authority for RTO designations on the sustainment programs they over-
     see. Each ALC Commander must ensure their respective CTA is capable of performing as an RTO or
     otherwise supporting low cost, short duration testing for the systems they oversee. In addition, Prod-
     uct Centers and ALCs will:
        2.6.1.1. Establish a CTA.
        2.6.1.2. Develop TESTREP MOAs with each appropriate test center/wing.
        2.6.1.3. Establish local procedures specifying processes relating to T&E management, i.e. RTO
        designation and TRB/SRB/TRR/CCBs.



                                                JEFFREY R. RIEMER, Brigadier General, USAF
                                                Director of Operations
AFMCI99-103 22 NOVEMBER 2004                                                                  11


                                            Attachment 1

             GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION

References
JP 1-02, Department of Defense Dictionary of Military and Associated Terms
DoDD 3200.11, Major Range and Test Facility Base
DoDD 4650.1, Policy for Management and Use of the Electromagnetic Spectrum
DoDD 5000.1, The Defense Acquisition System
DoDI 5000.2, Operation of the Defense Acquisition System
AFDD 1-2, Air Force Glossary
AFI 10-601, Capabilities Based Operational Requirement
AFI 14-206, Modeling and Simulation
AFI 16-1002, Modeling and Simulation Support to Acquisition
AFI 21-101, Aerospace Equipment Maintenance Management
AFI 33-118, Radio Frequency (RF) Spectrum Management
AFPD 62-6, USAF Aircraft Airworthiness Certification
AFI 63-101, Operation of the Capabilities Based Acquisition System
AFI 63-119, Certification of System Readiness for Dedicated Operational Test and Evaluation
AFI 63-1101, Modification Management
AFI 63-1201, Assurance of Operational Safety, Suitability, and Effectiveness
AFI 91-202/AFMC Sup1, The US Air Force Mishap Prevention Program
AFPD 99-1, Test and Evaluation Process
AFI 99-103, Capabilities Based Test and Evaluation
AFI 99-107, Test Pilot School (PA)
AFI 99-109, Test Resource Planning
AFMCI 21-126, Temporary (T-2) Modification of Aerospace Vehicles
AFMCPD 99-1, Test Management
TO 00-35D-54, USAF Deficiency Reporting and Investigating System
Test and Evaluation Management Guide, Defense Acquisition University Press, 4th edition

Abbreviations and Acronyms
ACAT—Acquisition Category
AFDD—Air Force Doctrine Document
12                                                        AFMCI99-103 22 NOVEMBER 2004


AFFTC—Air Force Flight Test Center
AFI—Air Force Instruction
AFMAN—Air Force Manual
AFMC—Air Force Materiel Command
AFMCI—Air Force Materiel Command Instruction
AFMCPD—Air Force Materiel Command Policy Directive
AFOTEC—Air Force Operational Test and Evaluation Center
AFPD—Air Force Policy Directive
AFRL—Air Force Research Laboratory
ALC—Air Logistics Center
APDP—Acquisition Professional Development Program
ASP—Acquisition Strategy Panel
COTS—Commercial Off-The-Shelf
COI—Critical Operational Issue
CTA—Center Test Authority
CTF—Combined Test Force
DAU—Defense Acquisition University
DoD—Department of Defense
DoDD—Department of Defense Directive
DoDI—Department of Defense Instruction
DT&E—Developmental Test and Evaluation
e.g.—for example
HPT—High Performance Team
HQ—Headquarters
IAW—In Accordance With
IG—Inspector General
ITT—Integrated Test Team
JP—Joint Publication
M&S—Modeling and Simulation
MAJCOM—Major Command
MDA—Milestone Decision Authority
MOA—Memorandum of Agreement
AFMCI99-103 22 NOVEMBER 2004                                                                         13


MRTFB—Major Range and Test Facility Base
NDI—Non-Developmental Item
OPR—Office of Primary Responsibility
OT&E—Operational Test and Evaluation
PEO—Program Executive Officer
PM—Program Manager
POC—Point of Contact
PTO—Participating Test Organization
QT&E—Qualification Test & Evaluation
RF—Radio Frequency
RTO—Responsible Test Organization
SRB—Safety Review Board
T&E—Test and Evaluation
TEMP—Test and Evaluation Master Plan
TESTREP—Test Representative
TIPP—Test Investment Planning and Programming
TO—Technical Order
TPS—Test Pilot School
TRB—Technical Review Board
TRR—Test Readiness Review
USAF—United States Air Force
www—World Wide Web

Terms
NOTE—For additional terms and definitions not listed below, see Joint Publication (JP) 1-02,
Department of Defense Dictionary of Military and Associated Terms, and Air Force Doctrine Document
(AFDD) 1-2, Air Force Glossary, which contain standardized terms and definitions for DoD and Air
Force use. An unofficial source is the Test and Evaluation Management Guide, 4th edition, Defense
Acquisition University (DAU) Press.
Acquisition Category (ACAT)—Acquisition categories determine the level of review, decision
authority, and applicable T&E policies and procedures. They facilitate decentralized decision making and
execution, and compliance with statutorily imposed requirements. See DoDI 5000.2, Enclosure 2 for
details.
Capabilities Based Testing—A mission-focused methodology of verifying that a capabilities solution
will enable operations at an acceptable level of risk. Capabilities-oriented evaluations are emphasized
14                                                               AFMCI99-103 22 NOVEMBER 2004


throughout system testing in addition to traditional evaluations of system performance measured against
specification-like requirements.
Center Test Authority (CTA)—A product or logistics center resident T&E expert(s), providing advise
to center leadership on issues of T&E, and assistance to center PMs.
Developmental Test and Evaluation (DT&E)—Test and evaluation conducted to evaluate design
approaches, validate analytical models, quantify contract technical performance and manufacturing
quality, measure progress in system engineering design and development, minimize design risks, predict
integrated system operational performance (effectiveness and suitability) in the intended environment,
and identify system problems (or deficiencies) to allow for early and timely resolution. DT&E includes
contractor testing and is conducted over the life of the system to support acquisition and sustainment
efforts. (Defense Acquisition Guidebook)
Host Center—The product or logistics center at which a co-located TESTREP resides.
Integrated Testing—Any combination of two or more types of testing used to achieve greater test
efficiency, reduced cost, and schedule savings without compromising the objectives and needs of the
participating test organizations.
Integrated Test Team (ITT)—A cross-functional team of empowered representatives from multiple
disciplines and organizations and co-chaired by operational testers and the program manager. The ITT is
responsible for developing the T&E strategy and TEMP, assisting the acquisition community with T&E
matters, and guiding the development of integrated test plans. There is one ITT for each acquisition
program. AFI 99-103 specifies roles, responsibilities, and membership requirements of an ITT.
Objective—An operationally significant increment above the threshold. An objective value may be the
same as the threshold when an operationally significant increment above the threshold is not significant or
useful. (AFI 10-601)
Operational Test and Evaluation (OT&E)—1. The field test, under realistic combat conditions, of any
item of (or key component of) weapons, equipment, or munitions for the purpose of determining the
effectiveness and suitability of the weapons, equipment, or munitions for use in combat by typical
military users; and the evaluation of the results of such test. (Title 10 §139(a)(2)) 2. Testing and
evaluation conducted in as realistic an operational environment as possible to estimate the prospective
system's operational effectiveness and operational suitability. In addition, OT&E provides information on
organization, personnel requirements, doctrine, and tactics. It may also provide data to support or verify
material in operating instructions, publications, and handbooks.
Operational Testing—A generic term describing the test and evaluation options and levels of effort
available to an operational test organization.
Oversight—Senior executive-level monitoring and review of programs to ensure compliance with policy
and attainment of broad program goals.
Owning Test Center/Wing—The test center/wing to which a TESTREP position belongs.
Participating Test Organization (PTO)—Any government or contractor supporting test organization
that provides specific T&E data or resources for a T&E program or activity.
Program Manager (PM)—1. The designated individual with responsibility for and authority to
accomplish program objectives for development, production, and sustainment to meet the user’s
operational needs. The PM shall be accountable for credible cost, schedule, and performance reporting to
AFMCI99-103 22 NOVEMBER 2004                                                                              15


the milestone decision authority (MDA). (DoDD 5000.1) 2. Applies collectively to system program
directors, product group managers, single managers, acquisition program managers, and weapon system
managers. Operating as the single manager, the PM has total life cycle system management authority.
Responsible Test Organization (RTO)—The lead government developmental test organization on the
ITT that is qualified to conduct and responsible for overseeing DT&E.
Risk—1. A measurable probability of consequence associated with a set of conditions or actions.
(Glossary, Defense Acquisition Acronyms and Terms) 2. Probability and severity of loss linked to
hazards. (JP 1-02) 3. A subjective assessment made regarding the likelihood or probability of not
achieving a specific objective by the time established with the resources provided or requested. It also
refers to overall program risk. (Defense Acquisition Guidebook)
Specification—A document intended primarily for use in procurement which clearly and accurately
describes the essential technical requirements for items, materials, or services, including the procedures
by which it will be determined that the requirements have been met. Specifications may be prepared to
cover a group of products, services, or materials, or a single product, service, or material, and are general
or detail specifications. (Glossary, Defense Acquisition Acronyms and Terms)
Sustainment—1. The provision of personnel, logistic, and other support required to maintain and prolong
operations or combat until successful accomplishment or revision of the mission or of the national
objective. (JP 1-02) 2. The Service's ability to maintain operations once forces are engaged. (AFDD 1-2)
Test and Evaluation (T&E)—The act of generating empirical data during the research, development or
sustainment of systems, and the creation of information through analysis that is useful to technical
personnel and decision makers for reducing design and acquisition risks. The process by which systems
are measured against requirements and specifications, and the results analyzed so as to gauge progress
and provide feedback. It requires a unique planning effort and procedures outside of or in addition to
established T.O.s. The failure of or unexpected results from these procedures may result in a costly loss of
the data or create a safety or environmental risk.
Test and Evaluation Master Plan (TEMP)—Documents the overall structure and objectives of the
T&E program. It provides a framework within which to generate detailed T&E plans and it documents
schedule and resource implications associated with the T&E program. The TEMP identifies the necessary
developmental, operational, and live-fire test activities. It relates program schedule, test management
strategy and structure, and required resources to: Critical Operational Issues (COI); critical technical
parameters; objectives and thresholds documented in the requirements document; and milestone decision
points. (DAU’s Test and Evaluation Management Guide)
Test and Evaluation Strategy—The overarching integrated T&E plan for the entire acquisition program
that describes how operational capability requirements will be tested and evaluated in support of the
acquisition strategy. Developed prior to Milestone A, the T&E strategy addresses modeling and
simulation, risk and risk mitigation, development of support equipment, and identifies how system
concepts will be evaluated against mission requirements, among other things. The T&E strategy is a
precursor to the test and evaluation master plan.
Test Approval Authority—The individual/organization ultimately responsible for accepting the SRB
and TRB results and approving the test to proceed with any residual risk. This test approval authority
responsibility will vary based on the scope of the planned testing and the availability of test expertise. It
will often reside with the center commander or the program manager, but could also be delegated to the
center safety office or Center Test Authority. If an RTO has been designated, the test approval authority
16                                                              AFMCI99-103 22 NOVEMBER 2004


often resides within that organization. Assignment of this responsibility should be part of the T&E
strategy development. For tests conducted at a major range and test facility base (MRTFB), the Test
Approval Authority shall be the activity commander IAW AFI 91-202, The US Air Force Mishap
Prevention Program.
Test Mishap Accountability—The organization that pays for test-related repairs and replacements must
be written and approved in the test planning documentation. Testing often requires the preplanned
damage/destruction of a unique test asset. Even where damage is not planned, testing involves unknowns
that could increase the likelihood of damage/loss. Mishap accountability is part of the cost of conducting
the test and in no way implies blame or mishap responsibility.
TESTREP—A test center/wing advisor/liaison to a host logistics or product center.
Threshold—A minimum acceptable operational value below which the utility of the system becomes
questionable.
User—Refers to the operating command which is the primary command operating a system, subsystem,
or item of equipment. Generally applies to those operational commands or organizations designated by
Headquarters, US Air Force to conduct or participate in operations or operational testing, interchangeable
with the term "using command" or “user.” In other forums the term “warfighter” or “customer” is often
used. (AFI 10-601)
AFMCI99-103 22 NOVEMBER 2004                                                                          17


                                              Attachment 2

                     SAMPLE TESTREP MEMORANDUM OF AGREEMENT
                                    MEMORANDUM OF AGREEMENT


                                                   BETWEEN


                                     OWNING TEST CENTER/WING


                                                    AND


                             HOST CENTER/SYSTEM PROGRAM OFFICE
1. PURPOSE: This Memorandum of Agreement (MOA) defines responsibilities and procedures for sup-
port of the (owning test center/wing) test representative (TESTREP) position at (host center).
1.1. TESTREP Overview
1.2. Center Test Authority (CTA) Overview
1.3. TESTREP assignment/reporting
2. TESTREP QUALIFICATIONS:
2.1. APDP certification level
2.2. Test Pilot School experience
2.3. Years T&E experience
2.4. Rank/grade requirements
2.5. Hiring authority/process; filling vacancies
3. TESTREP REPORTING CHAIN: The TESTREP will be assigned to the (owning test center/wing)
but will reside at/within the (host center/CTA).
3.1. Rater, additional rater, reviewer
3.2. Peer evaluations/peer inputs
4. TESTREP RESPONSIBILITIES: The TESTREP will:
4.1. Assist PMs.
4.2. Participate in working groups, boards, councils, reviews and any other acquisition/sustainment plan-
ning meetings in support of the CTA test process.
4.3. Coordinate T&E expertise and capabilities requirements.
4.4.. Assess/advise on/monitor technical and safety risk.
4.5. Coordinate appropriate level of Test Wing/Center involvement.
18                                                               AFMCI99-103 22 NOVEMBER 2004


4.6. Oversee status of host center test programs and issues relating to resources and/or test process, and
potential future programs for the owning center/wing.
4.7. Perform other duties as assigned.
5. OWNING TEST CENTER/WING RESPONSIBILITIES: The Owning Test Center/Wing will:
5.1. Provide test planning technical and safety expertise.
5.2. Provide test resources and personnel.
5.3. Fund salaries, directed TDYs, civilian awards, professional training for the TESTREP.
6. HOST CENTER RESPONSIBILITIES: The Host Center will:
6.1. Provide adequate facilities and support.
6.2. Provide performance assessments and promotion recommendations to the owning test center/wing as
appropriate.
6.3. Provide for TDY funding.
6.4. Provide adequate-time/opportunities for the TESTREP to accomplish appropriate professional train-
ing.
7. OTHER REQUIREMENTS:
8. EFFECTIVE DATE: This agreement is considered effective upon date of signature. Proposed
changes will be coordinated with and approved by all participants prior to changes being made.
