Administrative Changes to SMCI 63-103, Software Acquisition Process Improvement Instruction

OPR: SMC/EN

Global replace of “Wings/Groups and detachments” with “Directorate/Director”


26 APRIL 2011
BY ORDER OF THE COMMANDER                                  SPACE AND MISSILE SYSTEMS CENTER
SPACE AND MISSILE SYSTEMS CENTER                                           INSTRUCTION 63-103

                                                                                          28 MAY 2009
                                                                   Certified Current 29 November 2011
                                                                                            Acquisition

                                                                SOFTWARE ACQUISITION PROCESS
                                                                    IMPROVEMENT INSTRUCTION




                 COMPLIANCE WITH THIS PUBLICATION IS MANDATORY

ACCESSIBILITY:             Publications and forms are available on the e-Publishing website at www.e-
                           publishing.af.mil for downloading or ordering.

RELEASABILITY:             There are no releasability restrictions on this publication.


OPR: SMC/EAS                                          Certified by: SMC/EA (Colonel David E. Swanson)
Supersedes: SMCI63-103, 1 Dec 2006                                                           Pages: 25


This instruction outlines the process to comply with the requirements of the Air Force Software
Acquisition Process Improvement Strategy (SWAPI). It serves as a guide to standardize the Air Force
Space Command (AFSPC) and Air Force Materiel Command (AFMC) roles and responsibilities. It
applies to all Space and Missile Systems Center (SMC) Integrated Weapons System Management
(IWSM) Wings (formerly System Program Offices (SPOs)), the 61st Communication Squadron, 61st Air
Base Group and all organizations dealing with the acquisition of software intensive weapon systems,
including the maintenance and sustainment. (This includes all programs and/or projects that fall under
the Wings). The focus of this instruction is on the acquisition of the software that is an integral part of
the weapon system. The implementation of this instruction is mandated by the Policy on Software
Acquisition at SMC, dated 20 August 2004. See reference 2. Note: Tables 1 to 17 are not complete,
but are examples of attachment 2 which is required.

SUMMARY OF CHANGES

1. Minor grammatical changes, document formatting, inserted hyperlinks to referenced attachments
2. Merged table 4 and 5, then renumbered the tables
3. Replaced the old table 20 (now table 19)
4. Replaced attachments 2, 3 and 4
5. In Acronym list, replaced CMMI®-AM with CMMI®-Acquisition
6. Added in Reference Numbers
7. Deleted 2.2, organization not active
8. Tables 1 - 20 were renumbered
9. Deleted the CMMI sentences in 1.2 as the CMMI-ACQ is not a replacement for this Inst.
10. In 3.2 modified the first 2 sentences as following to clarify.
2                                                                           SMCI63-103 28 MAY 2009


11. Added in new 3.2.7 to address life cycle diagram in Figure 1. Since NSS 03-01 was rescinded, new
Figure 1 depicts DODI 5000.02 instead of NSS 03-01.
12. Appended the following text to 3.3.1 Q2 and Attachment 2 ―Describe the current software staff
leadership in the wing and on the program.‖
13. Deleted NSS 03-01 reference in 3.3.2 since it was rescinded.
14. In 3.2.2, added in for each sub-item or bullet after the (not to exceed a ½ page)
15. Deleted Lack of expectation management from Table 6. It was difficult to define and did not add
any value
16. Modified 3.3.4 Q1 and same in attachment 2 to clarify the question.
17. Added footnote to attachment 2, ―The format of this template is flexible. The content is required.‖
18. Appended to the end of Q2 in 3.3.1 and in attachment 2, ―Describe the current software staff
leadership in the wing and on the program.‖
19. Added the following to the end of the introductory paragraph ―Note: Tables 1 to 17 are not
complete, but are examples of attachment 2 which is required.‖
20. Deleted the a., b., c. from Attachment 2, 3.3.2, Q2
21. Added to 3.3.2, Table 8, Q5 which reads ―Q5. Describe how the wing is in compliance with the
Clinger-Cohen Act (CCA).‖
22. Reworded 3.3.3.2 to a more realistic 50% margin as in: ―System maintainability and supportability
issues need to be addressed early in the program. There needs to be a minimum of a 50% margin in
processor, memory, and input/ output utilization.‖
23. Reworded 2nd sentence of 3.3.4.2 to read: ―Significant levels of reuse, usually overly optimistic, are
often planned at program start and are not addressed in the successive stages of the acquisition cycle.
Reused software is a significant source of risk to program cost and schedule.‖
24. In Table 12, replace the use of the term you with the phrase the program
25. Deleted SDCE from table 14
26. Replaced table 19 revised table to clarify
27. Added CMMI®, CMMI®, and CMMI®-ACQ to the acronym list in attachment 1
28. Clarified section 3 to indicate that SWAPI reports are to be updated yearly
29. 3.3.4.1 reworded by James Haag, SMC/JA for clarification and to comply with new DoDI 5000.02.
30. Added in reference 8, SMCI 63-104, Software Acquisition
1. Objectives. This instruction is intended to improve the efficiency and effectiveness of SMC acqui-
sition processes and software management. These processes are applied as an integral part of our
systems engineering and capability acquisition processes.
     1.1. This document has been tailored to address SMC‘s unique acquisition requirements while retain-
     ing the wings‘ maximum flexibility on the method of implementation of this instruction.
     1.2. The wing is free to implement any process that adequately addresses each of the required areas
     in this instruction.
2. Headquarters Air Force (HQ AF) Oversight. The process flow for the software acquisition process
improvement strategy consists of:
    2.1. The Assistant Secretary of the Air Force / Acquisition (SAF/AQ) and the Undersecretary of the
    Air Force (SAF/US) will direct software acquisition policy.
    2.2. The Air Force Software Intensive Systems Strategic Improvement Plan Working Group
    (AFSSIP) is responsible for coordinating headquarters level Integrated Process Teams with
    Representatives from SAF/AQ, AF CIO, Product Centers (AFMC/ASC, AFMC/ESC, AFSPC/SMC),
    AFMC/IT, AFOTEC, STSC, etc. and (SMC/AXE is a working member of this group) – This group
SMCI63-103 28 MAY 2009                                                                          3


   works the various acquisition issues, policies, etc and advises the AFSSG on the same. Refer to
   Attachment 3, titled ―Headquarters Air Force (HQ AF) Oversight.‖
3. Air Force Software Acquisition Process Improvement Strategy Process. Each SMC wing shall
forward an electronic copy of their implementation plan and the completed metrics (e.g., Answered
Questions and Stoplight Chart) from implementation of their AF Software Acquisition Improvement
Process to Program Executive Officer (PEO) for Space and copy SMC/EAS (Acquisition Systems
Engineering Division). The wing will brief the PEO for space during a Program Management Review
(PMR) semi-annually. Wing personnel shall be ready to support their answers. The reporting process
shall commence 6 months after the publishing of the original Software Acquisition Process
Improvement Instruction, SMCI 63-103, dated 28 March 2005 and shall repeat yearly. The Metric
process flow diagram is illustrated in Attachment 4.
   3.1. Process Area Content. The process areas that need to be addressed, as a minimum, are shown
   below:
       3.1.1. SAF/AQ Revitalizing the Software Aspects of Systems Engineering

Table 1. SAF/AQ Policy Items to be Addressed.
 High Confidence Estimates
 Realistic Program Baselines
 Risk Management
 Capable Developer
 Developer Processes
 Wing/Group (i.e., originally named SMC Program Office) Processes
 Earned Value Management Applied to Software
 Metrics
 Life Cycle Support
 Lessons Learned
 AF Policy Compliance/Clinger-Cohen Act (CCA)
 Training

       3.1.2. Public Law 107-314, Section 804 (Bob Stump National Defense Authorization Act for
       Fiscal Year 2003) Process Areas (see reference 4).

Table 2. Section 804 Process Areas.
 DOCUMENTED PROCESS - A documented process for software acquisition planning
 METRICS - Develop appropriate metrics for performance measurement and continual process
 improvement
 EXPERIENCE & TRAINING - A process to ensure key program personnel have
 appropriate level of experience or training in software acquisition
 ENSURE ADHERENCE - A process to ensure implementation and adherence to established
 processes and requirements relating to the acquisition of software

       3.1.3. Office of the Secretary of Defense (OSD) Acquisition Technology and Logistics
       (AT&L)/Command, Control, Communications, Intelligence (C3I) Process Areas (see reference
       3).
4                                                                                  SMCI63-103 28 MAY 2009


Table 3. Areas Addressed by OSD In Addition to Areas Required By Section 804.
    CONFIG MGMT - Configuration Management
    TEST AND EVALUATION - Test and Evaluation
    INTEGRATED TEAM MANAGEMENT – Not applicable at this time
    SOURCE SELECTION - Solicitation and source selection

     3.2. Instructions: Each SMC wing shall complete the questionnaire (See the first 3 columns of Table 4.
     ―Software Process ―Desired‖ State Traceability Matrix‖ and Attachment 2). All responses/answers to the
     questions shall be in an editable format document (e.g., Microsoft Word, Editable Portable Document Format
     (PDF), Microsoft Excel). The suggested format is depicted in Attachment 2. The Matrix illustrates the short
     questions that need to be answered in the sections on: People, Training, and Experience; Policy and Guidance;
     Software Technology Development and Transition; Special Interest Items (e.g., Commercial Item (e.g., COTS
     - Commercial Off-The-Shelf)), Reuse, Security); Acquisition Processes and Compliance; Developer Process
     Compliance; and Metrics, Assessment, and Improvement. This matrix illustrates the mapping of the questions
     to the required compliance documents (OSD memo and Section 804). See references 3 and 4.
         3.2.1. Personnel having questions in the areas described above should review the SMC Software
         Acquisition Handbook. See reference 6.
         3.2.2. Each question is annotated by a prefix of ‗Qn‗and shall be answered by each program. Each
         answer should be 1 to 2 paragraphs (not to exceed a ½ page) for each sub-item or bullet. These responses
         will be used to determine how each program is complying with SWAPI requirements.
         3.2.3. Small programs (i.e., typically with less than 10,000 Source Lines of Code) may generate a tailoring
         request with justification to the PEO for Space per the Dr. Sambur and Mr. Teets memorandum entitled
         Revitalizing the Software Aspects of Systems Engineering, dated 20 September 2004. See reference 1.
         3.2.4. The following lessons learned information shall be delivered to the SMC Acquisition Center of
         Excellence (ACE) in an electronic format and on a schedule agreed to by both parties: including original
         estimates and delivered actuals for software size, effort, and schedule; program risks and mitigation
         approaches; objective description of factors such as added functional requirements; schedule perturbations;
         and any other program events that contributed to the successes and challenges of this program.
         3.2.5. The stoplight chart (Example) in paragraph 3.4. is to be completed by each SMC wing. The
         template can be found in Attachment 2.
         3.2.6. The terms and acronyms used for the traceability matrix below are in full caps.
         3.2.7. A life cycle diagram marked to show the current position in the life cycle should accompany the
         stoplight chart. An example is shown in Figure 1 that is based on the 2008 version of DODI 5000.02.
         See reference 7.

Figure 1. Position in Life Cycle.
             Table 4. Software Process "Desired" State traceability Matrix for:

                          1. AF SW Intensive Strategic Improvement Program

                          2. FY03 NDAA Section 804 or OSD AT&L/C3I Process Areas.
                            Section #                      Current State Survey
Process




                                                                                                   1. AF SW Intensive Strategic Improvement Memo
Area




                                                                                                   2. FY03 NDAA Section 804 or OSD AT&L/C3I Process Areas
                               Q1       Describe how the required experience level is determined, 1. Wing Processes
People, Training, &




                              3.3.1     how the training …..                                       2. Experience & Training
   Experience




                               Q2       Describe the wing's plan for retaining key staff, training 1. Wing Processes
                              3.3.1     new staff members ….                                       2. Experience & Training
                               Q3       Describe how it is determined that wing staff personnel    1. Wing Processes
                              3.3.1     have the material resources ….                             2. Ensure Adherence
                               Q1       Describe how the wing addresses software policy as an      1. Wing Processes
                              3.3.2     integral part of systems engineering ….                    2. Documented Processes
                                                      Describe how the wing addresses software management and acquisition guidance, including:
                               Q2
                                        a. The source of software acquisition and management       1. Wing Processes
                              3.3.2
                                          guidance and recommended practices.                      2. Documented Processes
    Policy and Guidance




                                                                          Describe how the wing addresses the following topics:
                               Q3       Budget and schedule estimates (80%-90% confidence),        1. Realistic Program Baselines, Risk Mgmt & High Confidence
                              3.3.2     robust risk ….                                             2. Documented Processes

                               Q4       Describe how the wing tracks compliance to ensure they        1. Wing Processes
                              3.3.2     are adhering to the mandatory provisions of laws, policies,   2. Ensure Adherence
                                        regulations, etc.
                               Q5       Describe how the wing is in compliance with the Clinger-      1. Ensure Adherence
                              3.3.2     Cohen Act (CCA)                                               2. Ensure Adherence
                               Q1       Describe how the wing verifies the contractor has a           1. Developer Processes, Wing Processes
SW Tech Development




                              3.3.3     process for assessing the feasibility of meeting system       2. Ensure Adherence
   and Transition




                                        performance requirements.
                               Q2       Describe how the wing personnel have addressed                1. Life Cycle Support
                              3.3.3     maintainability and supportability issues ….                  2. Documented Processes
                    6                                                                                        SMCI63-103 28 MAY 2009


                                         Section #                    Current State Survey
Process




                                                                                                                  1. AF SW Intensive Strategic Improvement Memo
Area




                                                                                                                  2. FY03 NDAA Section 804 or OSD AT&L/C3I Process Areas
                                            Q3       Describe how the wing's personnel assure the system will 1. Life Cycle Support
                                           3.3.3     have sufficient spare resources ….                           2. Ensure Adherence
                                            Q4       Describe how wing's personnel are assigned to verify the 1. Wing Processes
                                           3.3.3     system …. human interface/usability ….                       2. Experience & Training
                                                       Describe how the wing has addressed training areas that include how guidance, tailorable templates or examples,
                                            Q1                             and training are established and easily accessed for Program Manager use on:
                                           3.3.4     Commercial Items, GOTS, and open ….                          1. Developer Process, Wing Processes
                                                                                                                  2. Experience & Training
 Special Interest Items




                                            Q2       Describe how the wing verifies the risks associated with     1. Risk Management
                                           3.3.4     reuse, Commercial Items, GOTS, and open ….                   2. Ensure Adherence
                                            Q3       Describe how the wing verifies the system supports the       1. Developer Processes, Wing Processes
                                           3.3.4     architecture and network-centric ….                          2. Ensure Adherence
                                            Q4       Describe how the wing ensures that emphasis has been         1. Ensure Adherence
                                           3.3.4     placed on software testing areas such as: early software     2. Ensure Adherence
                                                     testing ….
                                            Q5       Describe how the wing verifies that the contractor utilizes  1. Ensure Adherence
                                           3.3.4     types of testing that will ….                                2. Ensure Adherence
                                            Q1       Describe how the wing has incorporated software into its     1. Wing Processes
  Acquisition Processes and Compliance




                                           3.3.5     program acquisition strategy ….                              2. Ensure Adherence
                                            Q2       Describe the processes the wing is using for software        1. Wing Processes
                                           3.3.5     acquisition as an integral part of the system acquisition,   2. Documented Processes, CM, SRC Selection, Test &
                                                     including processes for software acquisition planning,          Evaluation
                                                     requirements ….
                                            Q3       Describe the techniques the wing is using to develop an      1. Realistic Program Baselines
                                           3.3.5     independent program software size, cost, and schedule        2. Documented Processes
                                                     estimate ….
                   SMCI63-103 28 MAY 2009                                                                                             7


                                        Section #                   Current State Survey
Process




                                                                                                           1. AF SW Intensive Strategic Improvement Memo
Area




                                                                                                           2. FY03 NDAA Section 804 or OSD AT&L/C3I Process Areas
                                                       Describe how the wing establishes guidance and methods for evaluating contractor capability, capacity, and
                                                       commitment to disciplined development processes in source selection to include: Requiring the IMP, System
                                           Q1
                                                                          Engineering Management Plan, and Software Development Plan as:
                                          3.3.6
  Developer Process Compliance




                                                    Part of the proposal, evaluating them during source        1. Capable Developer
                                                    selection, and making them contractually binding ….        2. Documented Processes SRC Selection
                                           Q2       Describe how the wing ensures all development              1. Capable Developer
                                          3.3.6     contractors have defined, documented, applied, and         2. Documented Processes & Ensure Adherence
                                                    enforced disciplined processes.
                                           Q3       Describe how the wing establishes the developer's          1. Capable Developer
                                          3.3.6     capability to support periodic independent assessments of 2. Ensure Adherence, Experience & Training
                                                    ….
                                           Q4       Describe how the wing tracks whether the wing and the      1. Realistic Program Baselines & Wing Processes
                                          3.3.6     contractor team(s) execute within cost ….                  2. Ensure Adherence & CM
                                                      Describe how the wing uses the results from independent program assessments prior to key system milestones:
 Metrics, Assessment, and Improvement




                                           Q1
                                                    Used as preventive measures ….                             1. Wing Processes
                                          3.3.7
                                                                                                               2. Metrics & Ensure Adherence
                                           Q2       Describe how the wing defines and publishes                1. Wing Processes
                                          3.3.7     expectations for acquisition process improvement ….        2. Metrics & Documented Processes
                                           Q3       Describe the software-intensive system acquisition-related 1. Metrics
                                          3.3.7     metrics the wing uses. ….                                  2. Metrics, Ensure Adherence, Test & Evaluation
                                           Q4       Describe how the wing sets metric objectives and           1. Metrics
                                          3.3.7     thresholds and how the wing uses the metrics ….            2. Metrics & Documented Processes
                                           Q5       Describe how the wing determines and uses the software 1. Earned Value Management
                                          3.3.7     cost/schedule earned value ….                              2. Metrics & Documented Processes
   3.3. Wing Areas This Instruction Addresses: The text before the questions for each process area
   (e.g., 3.3.1.) is for guidance purposes, not as mandated requirements.
       3.3.1. People, Training, and Experience: Wing personnel need to have adequate training for
       their part in the acquisition. Each person as a minimum needs to have the appropriate Certified
       Acquisition Professional Level. The wing needs to identify the minimum training level/degree
       requirements/certification requirements for each position in their organization.
          3.3.1.1. Staff Experience needs to be analyzed to assess whether the personnel assigned to the
          project possess the experience necessary to acquire a system that meets customer needs.
          3.3.1.2. Critical skills need to be identified at the start of a project. The availability of appro-
          priate skills for each task needs to be evaluated.
          3.3.1.3. Staff turnover needs to be monitored, both from a retirement and morale perspective
          (i.e., we need to be careful about age-related metrics). A high turnover rate for younger
          employees could be indicative of a morale/management problem.
          3.3.1.4. Staff retention can be a critical factor in the success of a software development or
          maintenance program. It is important that the program have a plan for retaining key staff,
          training new staff members, cross training personnel, and ensuring staff personnel have the
          appropriate security clearances.
          3.3.1.5. When dealing with staffing issues, it is important to address the following critical
          areas:

Table 5. People, Training, and Experience Section Questions to Answer.
 Q1. Describe how the required experience level is determined, how the training level of wing personnel
      is being tracked, and how these personnel are being trained (also identify where no training is
      being provided).
 Q2. Describe the wing‘s plan for retaining key staff, training new staff members, and performing cross
      training. Describe the current software staff leadership in the wing and on the program.
 Q3. Describe how it is determined that the staff personnel have the material resources to accomplish
      their job (i.e., computers, copiers, Internet Access, reliable email, development and test tools,
      network support such as ftp, SecureID, Kerbos, support).

       3.3.2. Policy and Guidance: There is a significant need for Department of Defense (DoD) and
       Air Force policy and guidance directly related to software management and acquisition. A lack of
       software-related policy needs to be viewed by the wing as a major contributor to failure to meet
       expectations. Well-defined policy and guidance on software management and acquisition will
       minimize non-value-added software acquisition activities and focus the wing on universally
       prescribed methods that have real value to the software management. The Clinger-Cohen Act is
       designed to improve the way the Federal Government acquires and manages information
       technology. It requires individual programs to use performance based management principles
       for acquiring information technology. See Table 11 of SMCI 63-104 for a simple Clinger-Cohen
       Act compliance list. Contributors to program failure and poor software acquisition performance
       resulting from poorly defined policy and guidance include:
SMCI63-103 28 MAY 2009                                                                                    9


Table 6. Example Areas Under Policy And Guidance.
  Unrealistic estimates of software development size, effort, and/or schedule are reflected in program
  baselines
  Requirements volatility and lack of related adjustments to baselines
  Contractor's lack of or weak application domain expertise
  External interfaces (suppliers) outside the control of the Program Manager
  Inadequate risk management

           3.3.2.1. The following questions ensure the wing properly addresses software management
           and acquisition policy and guidance:

Table 7. Policy and Guidance Section Questions To Answer.
   Q1. Describe how the wing addresses software policy as an integral part of systems engineering, and
       applies all tenets of systems engineering to software.
   Q2. Describe how the wing addresses software management and acquisition guidance, including:
       - The source of software acquisition and management guidance and recommended practices
       - How the wing consolidates this guidance and practices and tailors it for the various wing
          components
       - References to any examples and templates the wing uses to ease application of guidance and
          practices
   Q3. Describe how the wing addresses the following topics:
       - Budget and schedule estimates (80%-90% confidence)
       - Application of lessons learned with respect to software size growth
       - Participation of application domain experts in program estimates
       - Adjusting budget and schedule when requirements change
       - Robust risk management program
       - Requirements and expectation management process involving wing, user, and prime
          contractor personnel
       - Studying lessons learned from previous programs before planning and during execution
       - Incentives and award fee
   Q4. Describe how the wing tracks compliance to ensure they are adhering to the mandatory
       provisions of laws, policies, regulations, etc.
   Q5. Describe how the wing is in compliance with the Clinger-Cohen Act (CCA)

       3.3.3. Software Technology Development and Transition: During planning and requirements
       analysis stages, the feasibility of meeting system-performance requirements must be assessed (e.g.,
       does the satellite sensor detect the correct number of targets in the required time and range limita-
       tions.). Wing personnel need to note that performance for the new system can be projected with
       modeling and simulation techniques and need to make sure the contractor addresses these issues.
           3.3.3.1. It is critical for the wing to verify the contractor has a process for assessing the
           feasibility of meeting system performance requirements.
           3.3.3.2. System maintainability and supportability issues need to be addressed early in the
           program. There needs to be a minimum of a 50% margin in processor, memory, and input/
           output utilization.
10                                                                        SMCI63-103 28 MAY 2009


          3.3.3.3. A system‘s user interface needs to consider the human being as required by 36 C.F.R.
          §§1194.21 and 1194.41, unless otherwise excepted.
          3.3.3.4. The following questions ensure the wing properly addresses Software Technology
          Development and Transition:

Table 8. Software Technology Development and Transition Section Questions to Answer.
Q1. Describe how the wing verified the contractor has a process for assessing the feasibility of
meeting system performance requirements.
Q2. Describe how wing personnel have addressed maintainability and supportability issues (e.g.,
Contractor Logistic Support, access to design documentation).
Q3. Describe how wing personnel assure the system will have sufficient spare resources for future
expansion (e.g., using only 50% of available memory, 50% of performance timing available)
Q4. Describe how wing personnel are assigned to verify the system being acquired from the
contractor(s) has taken human interface/usability into account.
Q5. Describe how the wing is in compliance with the Clinger-Cohen Act (CCA).

      3.3.4. Special Interest Items (Commercial Item (e.g., COTS – Commercial Off-The-Shelf),
      Reuse, Security and Software Test): The use of Commercial Item, reuse software, software
      security and software test issues needs to be thoroughly addressed by the wing to ensure the
      software risk is clearly identified and controlled and the software related requirements are met.
      The wing must ensure that well-defined processes are in place to address these software critical
      areas.
          3.3.4.1. Commercial Item software in widespread use involves applications interfaces to
          Government Off-The-Shelf (GOTS) software, operating systems, device drivers, etc. How-
          ever, Commercial Items are still a source of risk in terms of long-term viability and support-
          ability, quality, etc. Note that when a Commercial Item is recompiled, it is no longer a
          Commercial Item. Any modification of Commercial Off-The-Shelf (COTS) software means
          that the item is no longer COTS. Rights acquired to Commercial item software shall be (1)
          consistent with the program's Data Management Strategy required by DoDI 5000.02 and (2)
          acquired under licenses customarily provided to the public unless those licenses do not
          satisfy the user's minimum needs or are inconsistent with Federal procurement law. For
          further details, See reference 8.
          3.3.4.2. Software reuse is widely encouraged to reduce cost of development and to expedite
          the development effort. Significant levels of reuse, usually overly optimistic, are often
          planned at program start and are not addressed in the successive stages of the acquisition
          cycle. Reused software is a significant source of risk to program cost and schedule.
          3.3.4.3. Some systems use software developed by foreign contractors with no defined trace-
          ability to the actual developer, thus causing significant information assurance concerns. Some
          systems release software to foreign Governments using applicable Secretary of the Air Force/
          Information Assurance (SAF/IA) policy.
          3.3.4.4. Architecture and net-centric paradigms are not yet well understood and applied.
          Methods in place do not yet support effective analyses and implementation trade-offs of soft-
          ware intensive systems.
SMCI63-103 28 MAY 2009                                                                                 11


          3.3.4.5. An effective software testing program will identify the correctness, completeness,
          security and quality of the developed system software and minimize risk to the program mis-
          sion. Although testing varies between organizations, software testing needs to be emphasized.
          Emphasizing the proper software testing areas and ensuring that the contractor utilizes types of
          testing that will adequately test the system software will minimize risk to the program mission.
          3.3.4.6. The following questions ensure the wing properly addresses Commercial Items,
          reuse, software security and software testing:

Table 9. Special Interest Items Section Questions to Answer.
Q1. Describe for each item how the wing has established (determined and provided): (1)
    guidance; (2) tailorable templates or examples; (3) training; and (4) made them easily
    accessed (made available) for use: Commercial Items, GOTS; open source software,
    software from foreign sources, reuse application and impacts, system architecture, and
    information assurance. Although all special interest items must be addressed, be sure to
    fully address these two special items: software from foreign sources and information
    assurance.
Q2. Describe how the wing verifies the risks associated with reuse, Commercial Items, GOTS,
    and open source software, and information assurance. Describe how the wing verifies that
    foreign-developed software is identified and understood, and how the risks are mitigated.
Q3. Describe how the wing verifies the system supports the architecture and network-
    centric paradigm to include analysis and implementation trade-offs.
Q4. Describe how the wing ensures that emphasis has been placed on software testing areas such
    as: early software testing, test planning, test strategy, test plans, test bed development, test
    procedures, test scenarios, test cases and metrics.
Q5. Describe how the wing verifies that the contractor utilizes types of testing that will
    adequately test the system software. Types of testing include: white box black box, stress,
    positive/negative, boundary and system.

      3.3.5. Acquisition Processes and Compliance: Processes to ensure acquisition process
      compliance have generally not been established across the Air Force. Some of the existing
      problems with acquisition processes and compliance include:

Table 10. Example Areas Under Acquisition Processes and Compliance.
  Lessons learned focus is lacking
  Functions allocated to software are often assumed achievable and not fully considered in the
  requirements trade space
  There is little attention to sustainment
  Only mixed results are achieved in software acquisition
  Software acquisition processes are not prescribed:
      Presence and effectiveness of documented processes is inconsistent, and results are
      dependent upon personalities
      Relationship between documented acquisition processes and program success is not
      established
12                                                                           SMCI63-103 28 MAY 2009


             3.3.5.1. The software acquisition and management processes, which are established within
             the wing and directorate, need to ensure that:

Table 11. Areas That Need to be Addressed by SW Acquisition & Management Process.
     Realistic and achievable program baselines are used
     Risks associated with complexity and unprecedented capability are identified
     Requirements definition, management, and growth issues are managed
     Software acquisition processes are defined, documented, and institutionalized
     A metrics ―starter set‖ (with examples) is used and monitored for effective application
     Improvement activities are included when warranted
     The system is successfully supported and operated within evolutionary acquisition constructs
     Lessons learned are captured effectively

             3.3.5.2. The Software Acquisition Management Plan (SWAMP) provides a strategy and pro-
             cess to perform acquisition management oversight of the contractor(s) for the entire acquisi-
             tion life cycle. The SWAMP specifically defines for the wing what to assess and how to do it.
             The SWAMP focuses on total software and related systems engineering capability and
             execution, the program selection process, risk reduction, bidders’ or contractors’ products
             and processes, and compliance guidance to Air Force and DoD acquisition policies. For
             addition information, refer to the SMC Software Acquisition Handbook. See reference 6.
                 3.3.5.2.1. The following questions ensure the wing properly addresses Acquisition
                 Processes and Compliance:

Table 12. Acquisition Processes and Compliance Section Questions to Answer.
     Q1. Describe how the wing has incorporated software into its program acquisition strategy
         (including software development, test, and support strategies) and Request for Proposal
         (RFP(s)) (including Statement of Work and Statement of Objective (SOW and SOO),
         standards and other compliance documents, Contracts Data Requirements List (CDRL) items
         and associated Data Item Descriptions (DIDs), award and incentive fees, and evaluation
         criteria).
     Q2. Describe the processes the wing is using for software acquisition as an integral part of the
         system acquisition, including processes for software acquisition planning, requirements
         development and management, risk management, configuration management, solicitation and
         source selection, contract monitoring, and test and evaluation. Please provide a reference to the
         Software Acquisition Management Plan (SWAMP) that the program is using to manage the
         acquisition throughout the life cycle.
     Q3. Describe the techniques the wing is using to develop an independent Program
         software size, cost, and schedule estimate and to evaluate the contractors‘ estimates
         of size, cost and schedule for realism.

         3.3.6. Developer Process Compliance: The contractors‘ process capability and capacity must
         be understood in a consistent manner or method. Simply relying on Capability Maturity Model
         (CMM®)/CMMI® level without adequate examination or understanding can undermine the
         contractor oversight process. See reference 5. Multiple factors affect developer compliance with
         defined processes that include:
SMCI63-103 28 MAY 2009                                                                                   13


Table 13. Some Factors That Affect Developer Compliance.
  Ineffective application of Integrated Master Plan/Integrated Master Schedule (IMP/IMS)
  Inconsistent/inadequate insight into the contractor team members‘ software processes
  Cost and schedule pressures
  Not tracking or participating in processes for finding and removing defects early in the process

          3.3.6.1. The following questions ensure the wing properly addresses developer process
          compliance:

Table 14. Developer Process Compliance Section Questions to Answer.
  Q1. Describe how the wing establishes guidance and methods for evaluating contractor capability,
      capacity, and commitment to disciplined development processes in source selection to include:
         Requiring the IMP, System Engineering Management Plan, and Software Development Plan
         as:
             Part of the proposal, evaluating them during source selection, and making them
             contractually binding.
            Identifying and addressing strengths, weaknesses, and risks.
            Evaluating the contractor teams' software capabilities, both for source selection and
             contract monitoring (e.g., use of CMMI®, other techniques).
   Q2. Describe how the wing ensures all development contractors have defined, documented,
       applied, and enforced disciplined processes.
   Q3. Describe how the wing establishes the capability to support periodic independent assessments
       of developer capability and capacity, based on PEO/program manager demand.
   Q4. Describe how the wing tracks whether the wing and the contractor team(s) execute
       within cost, schedule, and performance baselines and how corrections are made
       (including configuration management).

      3.3.7. Metrics, Assessment, and Improvement

Table 15. Measurement, Assessment and Improvement Needs.
  A standard set of metrics that can be applied across all programs
  Large-scale acquisition process improvement using formal models (e.g., CMMI®-
  Acquisition Model (ACQ)
  Consistent application of assessment to determine the process maturity of acquisition
  organizations

          3.3.7.1. Established metrics are generally used to monitor contractor efforts rather than Wing
          acquisition processes, resulting in inconsistent application and effectiveness of metrics that are
          in place to monitor acquisition programs. In the past, a consistent assessment method has not
          been applied to determine the maturity of acquisition organization's processes.
          3.3.7.2. Improvement activities are underway at several centers to focus on revitalizing sys-
          tems engineering. However, even though improvement activities are gaining momentum, soft-
          ware is not explicitly addressed. Large-scale acquisition process improvement using formal
          models is rare, and formalized process improvement is not a priority in the current environ-
14                                                                             SMCI63-103 28 MAY 2009


             ment of high ops-tempo, acquisition workforce downsizing, etc. In addition, wing process
             improvement metrics are not consistent, required, or defined.
                 3.3.7.2.1. Earned Value provides a uniform unit of measure for reporting the progress of
             a project. It provides the basis for cost and schedule performance analysis. If you want to
             know what‘s happening to the cost of your project BEFORE it is completed, you need to know
             what the planned cost at any time was, what the cost of the completed work is, and the value
             of the work actually completed. The units are usually work hours and dollars.
             3.3.7.3. The wing must ensure the use of standard software metrics as an integral part of
             program execution and risk management to include:

Table 16. Desired Characteristics of Software Metrics Usage.
     Integration with systems engineering requirements and approaches.
     Integration with lessons learned to help better predict cost, schedule, and performance related to
     software.
     Consistent application across prime contractors and subcontractors, as applicable (e.g., software
     defects).

             3.3.7.4. The following questions ensure the wing properly addresses metrics, assessment, and
             improvement:

Table 17. Metrics, Assessment, and Improvement Section Questions to Answer.
     Q1. Describe how the wing uses the results from independent program assessments prior to key
         system milestones:

           as a preventive measure

           to identify strengths, weaknesses, and risks relevant to the phase of the program
     Q2.   Describe how the wing defines and publishes expectations for acquisition process
           improvement to focus on improving the team‘s ability to rapidly deliver war-fighting
           capability.
     Q3.   Describe the software-intensive system acquisition-related metrics the wing uses. Include
           both (a) metrics used within the program(s) to assess the acquisition processes, as well as (b)
           metrics used to measure the contractor's software development activities. Include metrics
           related to acquisition process compliance, software progress (design, coding, and testing),
           software development effort, staffing profiles, cost, schedule, software size, risk
           management, computer resource utilization, requirements volatility and management, testing,
           defects, quality, development team capability, and complexity.
     Q4.   Describe how the wing sets metrics objectives and thresholds and how the wing uses the
           metrics (including objectives, thresholds, plans, actuals, and historical data) to manage the
           acquisition, development, and, if applicable, sustainment, and describe how the metrics are
           used to influence program decisions.
     Q5.   Describe how the wing determines and uses the software cost/schedule earned
           value (e.g., schedule performance index and cost performance index at the software
           level).
SMCI63-103 28 MAY 2009                                                                              15


   3.4. Compliance with Air Force Software Acquisition Process Improvement Requirements:
   The SMC SWAPI point of contact (POC) will complete a Stoplight Chart for each system. The system
   names below are examples and are to be replaced by the wing's system names.

Table 18. Evaluation Criteria Descriptions.
 Poorly Compliant (<50%)         Means that less than 50% of the issues in the question are adequately
                                 addressed, in the opinion of the wing.
 Borderline Compliant (50-74%)   Means that 50%-74% of the issues in the question are adequately
                                 addressed, in the opinion of the wing.
 Mostly Compliant (75-99%)       Means that 75%-99% of the issues in the question are adequately
                                 addressed, in the opinion of the wing.
 Completely Compliant            Means that all of the issues in the question are adequately
                                 addressed, in the opinion of the wing.
Table 19. Compliance with Air Force SWAPI Requirements Matrix.
 N/A - Not Applicable
 Red - Poorly Compliant (< 50%)                                                                                              PROGRAM NAME (insert Program Name)
 Yellow - Borderline Compliant (50 - 74%)
 Blue - Completely Compliant

  Wing Process




                                                                                                                                                                                 Stoplight
      Area




                                                                                                                                                                                 Color




                                                                                                                                                                                                         Color
                                           Section #                             Question                                                   Answer                                           Evaluator
                                              Q1       Describe how the required experience level is determined,     The required experience level is determined …,
                                             3.3.1     how the training level of the wing personnel is being         the training level of the wing is being tracked …
                                                       tracked, and how these personnel are being trained (also      the program personnel are being trained …
        People, Training, and Experience




                                                                                                                                                                                Y
                                                       identify where no training is being provided).


                                              Q2       Describe the wing’s plan for retaining key staff, training    The wing’s plan for “retaining” key personnel is
                                             3.3.1     new staff members, and performing cross training.             … the training of new staff members is … and




                                                                                                                                                                                G
                                                       Describe the current software staff leadership in the wing    cross-training is …
                                                       and on the program.
                                              Q3       Describe how it is determined that the staff personnel have   The wing/program office ensures the staff
                                             3.3.1     the material resources to accomplish their job (i.e.,         personnel have the …
                                                       computers, copiers, Internet Access, reliable email,




                                                                                                                                                                                R
                                                       development and test tools, network support such as ftp,
                                                       SecureID, Kerbos, support, etc.).
                                              Q1       Describe how the wing addresses software policy as an
                                             3.3.2     integral part of systems engineering, and applies all tenets
                                                       of systems engineering to software.
                                                                                                  Describe how the wing addresses software management and acquisition guidance, including:
        Policy and Guidance




                                                       The source of software acquisition and management
                                                       guidance and recommended practices.
                                                       How the wing consolidates this guidance and practices and
                                              Q2       tailors it for the various wing components.
                                             3.3.2
                                                       References to any examples and templates the wing uses
                                                       to ease application of guidance and practices.




                                                                                                                      DAVID E. SWANSON, Colonel, USAF
                                                                                                                      Director, Engineering and Architectures
                                           Attachment 1
             GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION

References
Revitalizing the Software Aspects of Systems Engineering, dated 20 Sept 04 (SAF/AQ)
Policy on Software Acquisition at SMC, 20 August 2004 (SMC/CC)
Office of the Secretary of Defense Memorandum on Software Acquisition Process Improvement Pro-
grams, dated 21 Mar 2003 (OSD AT&L/C3I)
Public Law 107-314, Section 804 (Bob Stump National Defense Authorization Act for Fiscal Year 2003)
Capability Maturity Model® Integration®, Current Version
SMC Software Acquisition Handbook, Current Version
DoDI 5000.02, dated 12 May 2003, current version
SMCI 63-104, Software Acquisition Instruction, current version

Abbreviations and Acronyms
ABG—Air Base Group
ACE—Acquisition Center of Excellence
AT&L—Acquisition, Technology and Logistics
AFMC—Air Force Materiel Command
AFMC/ASC—Air Force Materiel Command/Aeronautical System Center
AFMC/ESC—Air Force Materiel Command/Electronic Systems Center
AFOTEC—Air Force Operational Test and Evaluation Center
AFSPC—Air Force Space Command
AFSSG—Air Force Software Steering Group
AFSSIP—Air Force Software Intensive Systems Strategic Improvement Program
C3I—Command, Control, Communications and Intelligence
CDRL—Contracts Data Requirements List
CMM®—Capability Maturity Model®
CMMI®—Capability Maturity Model® Integration®
CMMI®-ACQ—Capability Maturity Model® Integration® - Acquisition Model
COTS—Commercial Off The Shelf
DID—Data Item Description
DoD—Department of Defense
EA—Engineering and Architecture Division
EAS—Engineering and Architecture Software
MGMT—Management
NDAA—National Defense Authorization Act
OSD—Office of the Secretary of Defense
18                                                        SMCI63-103 28 MAY 2009


PDF—Portable Document Format
PEO—Program Executive Officer
PGM—Program
PMR—Program Management Review
PO—Program Office
POC—Point of Contact
RFP—Request For Proposal
SAF/AQ—Secretary of the Air Force/Acquisition
SAF/IA—Secretary of the Air Force/International Affairs
SAF/US—Secretary of the Air Force/Under Secretary
SEI—Software Engineering Institute
SETA—System Engineering and Technical Assistance
SMC—Space and Missile Systems Center
SOO/SOW—Statement of Objectives/Statement of Work
SPO—Systems Program Office
SSG—Software Steering Group
STSC—Software Technology Support Center-Software
SWAMP—Software Acquisition Management Plant
SWAPI—Software Acquisition Improvement
                                                                                              Attachment 2
                                                                  SUGGESTED QUESTION/ANSWER TEMPLATE1

    A2.1. Suggested Question/Answer Template.

    Table A2.1. Suggested Question/Answer Template1.
N/A - Not Applicable
Red - Poorly Compliant (< 50%)                                                                     PROGRAM NAME (insert Program Name)
Yellow - Borderline Compliant (50 - 74%)
Blue - Completely Compliant
 Wing




                                                                                                                                               Stoplight
Process                  Section




                                                                                                                                               Color




                                                                                                                                                                       Color
 Area
                            #                          Question                                     Answer                                                 Evaluator
                           Q1      Describe how the required experience level is
                          3.3.1    determined, how the training level of the wing personnel
                                   is being tracked, and how these personnel are being
 People, Training, and




                                   trained (also identify where no training is being
                                   provided).
     Experience




                           Q2      Describe the wing’s plan for retaining key staff, training
                          3.3.1    new staff members, and performing cross training.
                                   Describe the current software staff leadership in the wing
                                   and on the program.
                           Q3      Describe how it is determined that the staff personnel
                          3.3.1    have the material resources to accomplish their job (i.e.,
                                   computers, copiers, Internet Access, reliable email,
                                   development and test tools, network support such as ftp,
                                   SecureID, Kerbos, support, etc.).
                           Q1      Describe how the wing addresses software policy as an
                          3.3.2    integral part of systems engineering, and applies all
                                   tenets of systems engineering to software.
 Policy and
 Guidance




                                                                           Describe how the wing addresses software management and acquisition guidance, including:
                                   The source of software acquisition and management
                           Q2      guidance and recommended practices.
                          3.3.2




    1
            The format of this template is flexible. The content is required.
   20                                                                                                              SMCI63-103 28 MAY 2009


                                  How the wing consolidates this guidance and practices
                                  and tailors it for the various wing components.

                                  References to any examples and templates the wing
                                  uses to ease application of guidance and practices.

                                                                                                Describe how the wing addresses the following topics:
                                  Budget and schedule estimates (80%-90% confidence)

                                  Application of lessons learned with respect to software
                                  size growth
                                  Participation of application domain experts in program
                                  estimates
                           Q3     Adjusting budget and schedule when requirements
                          3.3.2   change
                                  Robust risk management program
                                  Requirements and expectation management process
                                  involving wing, user, and prime contractor personnel

                                  Studying lessons learned from previous programs before
                                  planning and during execution
                                  Incentives and/or award fee
                           Q4     Describe how the wing tracks compliance to ensure they
                          3.3.2   are adhering to the mandatory provisions of laws,
                                  policies, regulations, etc.
                           Q5     Describe how the wing is in compliance with the Clinger-
                          3.3.2   Cohen Act (CCA)
                           Q1     Describe how the wing verifies the contractor has a
                          3.3.3   process for assessing the feasibility of meeting system
                                  performance requirements.
SW Tech Development and




                           Q2     Describe how the wing personnel have addressed
                          3.3.3   maintainability and supportability issues (e.g., Contractor
                                  Logistic Support, access to design documentation).
                                  Sustainment includes: maintenance, transportation,
       Transition




                                  sustaining engineering, data management, configuration
                                  management, manpower, personnel, skills, training,
                                  critical program information protection, anti-tamper
                                  provisions, information technology and technology
                                  refresh.
                           Q3     Describe how wing personnel assure the system will
                          3.3.3   have sufficient spare resources for future expansion
                                  (e.g., using only 50% of available memory, 50% of
                                  performance timing available)
   SMCI63-103 28 MAY 2009                                                                                                                                    21


                              Q4     Describe how wing personnel are assigned to verify the
                             3.3.3   system being acquired from the contractor's) has taken
                                     human interface/usability into account.
                                          Describe for each item how the wing has established (determined and provided): (1) guidance; (2) tailorable templates or examples; (3) training; and (4) made them easily
                                        accessed (made available) for use: Commercial Items, GOTS; open source software, software from foreign sources, reuse application and impacts, system architecture, and
                                       information assurance. Although all special interest items must be addressed, be sure to fully address these two special items: software from foreign sources and information
                                                                                                                       assurance.
                                     Commercial Items
                                     GOTS
                              Q1
                             3.3.4   open source software
                                     software from foreign sources
                                     reuse application and impacts
                                     system architecture
                                     information assurance
    Special Interest Items




                              Q2     Describe how the wing verifies the risks
                             3.3.4   associated with reuse, Commercial Items,
                                     GOTS, and open source software, and
                                     information assurance. Describe how the
                                     wing verifies that foreign-developed
                                     software is identified and understood, and
                                     how the risks are mitigated.
                              Q3     Describe how the wing verifies the system
                             3.3.4   supports the architecture and network-centric
                                     paradigm to include analysis and
                                     implementation trade-offs.
                              Q4     Describe how the wing ensures that
                             3.3.4   emphasis has been placed on software
                                     testing areas such as: early software testing,
                                     test planning, test strategy, test plans, test
                                     bed development, test procedures, test
                                     scenarios, test cases and metrics.
                              Q5     Describe how the wing verifies the contractor
                             3.3.4   utilizes types of testing that will adequately
                                     test the system software. Types of testing
                                     include: white box, black box, stress,
                                     positive/negative, boundary and system.
                              Q1     Describe how the wing has incorporated
Processes and




                             3.3.5   software into its program acquisition strategy
 Compliance
 Acquisition




                                     (including software development, test, and
                                     support strategies) and RFP(s) (including
                                     SOW and SOO, standards and other
                                     compliance documents, CDRL items and
                                     associated DIDs, award and incentive fees,
22                                                                                                             SMCI63-103 28 MAY 2009

                                       and evaluation criteria).




                                Q2     Describe the processes the wing is using for
                               3.3.5   software acquisition as an integral part of the
                                       system acquisition, including processes for
                                       software acquisition planning, requirements
                                       development and management, risk
                                       management, configuration management,
                                       solicitation and source selection, contract
                                       monitoring, and test and evaluation. Please
                                       provide a reference to the Software
                                       Acquisition Management Plan (SWAMP) that
                                       the program is using to manage the
                                       acquisition throughout the life cycle.
                                Q3     Describe the techniques the wing is using to
                               3.3.5   develop an independent program software
                                       size, cost, and schedule estimate and to
                                       evaluate the contractors’ estimates of size,
                                       cost and schedule for realism.
                                        Describe how the wing establishes guidance and methods for evaluating contractor capability, capacity, and commitment to disciplined development processes in
                                                          source selection to include: Requiring the IMP, System Engineering Management Plan, and Software Development Plan as:
                                       Part of the proposal, evaluating them during
                                       source selection, and making them
Developer Process Compliance




                                Q1     contractually binding.
                               3.3.6   Identifying and addressing strengths,
                                       weaknesses, and risks.
                                       Evaluating the contractor teams' software
                                       capabilities, both for source selection and
                                                                                ®
                                       contract monitoring (e.g., use of CMMI ,
                                       other techniques).
                                Q2     Describe how the wing ensures all
                               3.3.6   development contractors have defined,
                                       documented, applied, and enforced
                                       disciplined processes.
                                Q3     Describe how the wing establishes the
                               3.3.6   capability to support periodic independent
                                       assessments of developer capability and
                                       capacity, based on PEO/program manager
                                       demand.
SMCI63-103 28 MAY 2009                                                                                                                                      23

                                        Q4     Describe how the wing tracks whether the
                                       3.3.6   wing and the contractor team(s) execute
                                               within cost, schedule, and performance
                                               baselines and how corrections are made
                                               (including configuration management).
                                                                           Describe how the wing uses the results from independent program assessments prior to key system milestones:
                                        Q1     as a preventive measure
                                       3.3.7   to identify strengths, weaknesses, and risks
                                               relevant to the phase of the program
                                        Q2     Describe how the wing defines and
                                       3.3.7   publishes expectations for acquisition process
                                               improvement to focus on improving the
                                               team’s ability to rapidly deliver war-fighting
                                               capability.
                                        Q3     Describe the software-intensive system
Metrics, Assessment, and Improvement




                                       3.3.7   acquisition-related metrics the wing uses.
                                               Include both:
                                               (a) metrics used within the program(s) to
                                               assess the acquisition processes, as well as
                                               (b) metrics used to measure the contractor's
                                               software development activities. Include
                                               metrics related to acquisition process
                                               compliance, software progress (design,
                                               coding, and testing), software development
                                               effort, staffing profiles, cost, schedule,
                                               software size, risk management, computer
                                               resource utilization, requirements volatility
                                               and management, testing, defects, quality,
                                               development team capability, and complexity.
                                        Q4     Describe how the wing sets metric objectives
                                       3.3.7   and thresholds and how the wing uses the
                                               metrics (including objectives, thresholds,
                                               plans, actuals, and historical data) to manage
                                               the acquisition, development, and, if
                                               applicable, sustainment, and describe how
                                               the metrics are used to influence program
                                               decisions.
                                        Q5     Describe how the wing determines and uses
                                       3.3.7   the software cost/schedule earned value
                                               (e.g., schedule performance index and cost
                                               performance index at the software level).
                                          Attachment 3
                     HEADQUARTERS AIR FORCE (HQ AF) OVERSIGHT

A3.1. Headquarters Air Force (HQ AF) Oversight.

Figure A3.1. Headquarters Air Force (HQ AF) Oversight.

                                  SAF/US

                                                                Policy
                                  SAF/AQ
                                                 SW Acq Process Improvement (SWAPI)




                                                              AFSSG
 MAJCOMS       AFMC                                                          AFSPC
                                                            (Advisory)


                                 HQ AFMC E&TM
                               Engineering Council
                                                          AFSSIP               SMC
                                   (Advisory)




                                                                                      Execution
      ASC      ESC      ALCs
                                                                              SMC
                                                          SMC/EAS             Wings
SMCI63-103 28 MAY 2009                                                                 25


                                             Attachment 4
                              METRIC PROCESS FLOW DIAGRAM

A4.1. Metric Process Flow Diagram.
Figure A4.1. Metric Process Flow Diagram.



                                       SMC SWAPI POC
                              Sends Wing/Program Office notification
                              • SWAPI compliance update is due




                                   SMC Wing/Program Office:
                 • Receives SWAPI update notification (Every 12 months)
                 • Fills out the SWAPI template & Stop Light Chart with sufficient
                   detail pertinent to each question (Due date stipulated at time of
                   notification)
                 • Submits completed SWAPI template to SMC SWAPI POC




                              SMC SWAPI POC
            •   Reviews answers submitted by SMC Wing/Program Office
            •   May return file to the SMC Wing/Program Office for additional
                clarification
            •   Generates monthly metrics of SMC Wing’s/Program compliance
            •   Submits metrics to SMC EA Chief Engineer




                                            Complete               N
                                                                   o
                                            ?

                                                    Ye
                                                    s
                                     SMC EA Chief Engineer
                Completed Metric Data Package (e.g., updated SWAPI template
                and Stop Light chart) briefed to SMC PEO for Space @ PMR
                (Semi-annually)
                  • Copies sent to AFSPC/LC (AFSPC CIO)
