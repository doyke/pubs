DEPARTMENT OF THE AIR FORCE                                                                                         AF MANUAL 36-2234
Headquarters U.S. Air Force                                                                                             1 November 1993
Washington D.C. 20330-5000

                                                                          Education/Training

                                                 INSTRUCTIONAL SYSTEM DEVELOPMENT

This manual describes the Instructional System Development (ISD) principles and processes for
developing education and training programs in the United States Air Force. It presents an instructional
design model for analyzing, designing, developing, and implementing effective and cost-efficient
instructional systems. Applications of the principles and processes in this manual are found in the various
volumes of Air Force Handbook 36-2235. This manual applies to all personnel who plan, design,
develop, implement, approve, administer, conduct, evaluate or manage Air Force instruction. It also
applies to Air National Guard (ANG) and U.S. Air Force Reserve (USAFR) units and members.

                                                                           Table of Contents

Chapter                                                                                                                              Page

1. INTRODUCTION ...................................................................................................... 5
   Overview .................................................................................................................... 5
   A.Background.............................................................................................................. 7
   B.Total Instructional System ........................................................................................ 11
   C.Quality Improvement ............................................................................................... 14

2. LEARNING THEORY .............................................................................................. 17
   Overview ................................................................................................................... 17
   A.Theoretical Approaches ............................................................................................ 17
   B.Types of Learning .................................................................................................... 18
   C.Applying Theory to the Learning Situation .............................................................. 22

3. PLANNING................................................................................................................ 25
   Overview ................................................................................................................... 25
   A.Determine Instructional Need ................................................................................... 25
   B.Determine Instructional System Concepts ................................................................ 27

_____________________________
Supersedes AFM 50-2, 15 July 1986 (see signature page for summary of changes)
No. of Printed Pages: 128
OPR: HQ AETC/XORR (Major Richard O'Neal)
Approved by: HQ USAF/DPPE (Col David L. Chase)
Distribution: F
2                                                                                        AFMAN 36-2234                   1 November 1993


Chapter                                                                                                                                Page

    C.Determine Resource Requirements and Constraints .................................................. 28
    D.Develop ISD Management Plan .............................................................................. 29
    E.Develop ISD Evaluation Plan.................................................................................... 30

4. ANALYSIS ............................................................................................................... 31
   Overview .................................................................................................................... 31
   A.Occupational/Educational/Mission Analysis .............................................................. 32
   B.Task Analysis ......................................................................................................... 34
   C.Learning Analysis .................................................................................................... 37
   D.Resource Analysis .................................................................................................. 38
   E.Target Audience Analysis ........................................................................................ 41
   F.ISD Evaluation Plan Update ..................................................................................... 42
   G.ISD Management Plan Update ................................................................................. 43

5. DESIGN .................................................................................................................... 45
   Overview ................................................................................................................... 45
 A. Develop Objectives..................................................................................................... 45
   Characteristics of Objectives ....................................................................................... 46
   Learned Capability ..................................................................................................... 47
   Condition .................................................................................................................. 47
   Standard ..................................................................................................................... 48
   Guidelines for Developing Objectives ........................................................................... 49
   Writing Objectives for Types of Learning .................................................................... 49
   Hierarchy of Objectives ............................................................................................... 50
   Prioritizing, Clustering, and Sequencing Objectives ..................................................... 52
   B.Develop Tests ......................................................................................................... 54
   C.Review Existing Materials ...................................................................................... 59
 D. Design Instructional Plan .......................................................................................... 60
   Select Instructional Method ........................................................................................ 62
   Select Media. .............................................................................................................. 65
   Select Media for Integrated Activities .......................................................................... 67
   Determine Instructional Strategies................................................................................ 69
   Design Instructional Activities .................................................................................... 72
   E.Develop Implementation Plan .................................................................................. 73
   F.Design Instructional Information Management System .............................................. 74
   G.Update ISD Evaluation Plan ..................................................................................... 75
   H.Update ISD Management Plan.................................................................................. 76

6. DEVELOPMENT ...................................................................................................... 78
   Overview .................................................................................................................... 78
   A.Prepare Plan of Instruction/Course Syllabus ............................................................. 78
   B.Produce Instructional Materials ............................................................................... 79
   C.Install Instructional Information Management System .............................................. 82
   D.Update ISD Evaluation Plan ..................................................................................... 83
AFMAN 36-2234                  1 November 1993                                                                                              3

Chapter                                                                                                                              Page

    E.Update Management Plan. ........................................................................................ 84
    F.Validate Instruction................................................................................................... 85
    Develop Validation Plan............................................................................................... 85
    Conduct Internal Reviews ............................................................................................ 86
    Conduct Individual Tryouts.......................................................................................... 87
    Conduct Small-Group Tryouts ..................................................................................... 90
    Conduct Operational (Field) Tryouts ............................................................................ 91
    G.Finalize Instructional Materials ................................................................................. 93

7. IMPLEMENTATION................................................................................................. 95
 Overview ....................................................................................................................... 95
 A. Implement System Functions ...................................................................................... 95
   Management Function ................................................................................................. 95
    Support Function ....................................................................................................... 96
    Administration Function ............................................................................................ 98
   Delivery Function ........................................................................................................ 99
 B. Conduct Instruction ................................................................................................... 99
   Preparations for Conducting Instruction ...................................................................... 100
   Guidelines for Conducting Instruction ......................................................................... 101
 C. Conduct Operational Evaluation ............................................................................... 103
   Operational Evaluation................................................................................................. 103
   Internal Evaluation ...................................................................................................... 104
   External Evaluation ..................................................................................................... 107
    Questionnaires ........................................................................................................... 108
    Field Visits ................................................................................................................. 113
    Job Performance Evaluation ....................................................................................... 115
    Other Sources of Evaluation Input ............................................................................. 116

8. EVALUATION .......................................................................................................... 117
 Overview ....................................................................................................................... 117
   A.Formative Evaluation................................................................................................ 118
   B.Summative Evaluation .............................................................................................. 120
   C.Operational Evaluation. ........................................................................................... 120

Attachment A - Air Force ISD Documents ....................................................................... 122
Attachment B - Bibliography............................................................................................. 123
Attachment C - Abbreviations .......................................................................................... 125
Attachment D - Definitions ............................................................................................... 127
                  List of Figures                                                                                            Page

Figure 1.     Original Air Force ISD Model .......................................................................... 9
Figure 2.     System Functions .............................................................................................. 12
Figure 3.     Functions with Phases ..................................................................................... 13
Figure 4.     Updated AF ISD Model ................................................................................... 15
Figure 5.     Analysis Phase................................................................................................... 43
4                                                                                      AFMAN 36-2234                  1 November 1993

Figure 6. Design Phase ..................................................................................................... 61
Figure 7. Simple to Complex Continuum ......................................................................... 74
Figure 8. Objective Hierarchy........................................................................................... 74
Figure 9. Development Phase .......................................................................................... 111
Figure 10. Implementation Phase ...................................................................................... 136
Figure 11. Evaluation ........................................................................................................ 171
AFMAN 36-2234        1 November 1993                                                                                5

                                              Chapter 1
                                           INTRODUCTION

Overview


Purpose               Instructional System Development (ISD) is the official Air Force process for developing
                      education and training for Air Force personnel. AFPD 36-22 directs the use of a systematic
                      approach to Air Force instruction. This manual, AFMAN 36-2234, discusses the background of
                      ISD, describes what it is, explains the ISD process, and provides guidance for finding additional
                      information on specific areas of the process. It also provides the necessary theory and
                      philosophy for developing effective, cost-efficient instruction. Specific applications of the ISD
                      process are found in a series of handbooks (AFH 36-2235). A list of these handbooks and other
                      ISD documents is in Attachment A.

Definition of ISD     Instructional system development is a deliberate and orderly, but flexible process for planning,
                      developing, implementing, and managing instructional systems. It ensures that personnel are
                      taught in a cost-efficient way the knowledge, skills, and attitudes essential for successful job
                      performance.

Content               AFMAN 36-2234 covers the following content areas.

                              ·The Introduction describes the background and basic concepts of Air Force ISD. It
                              compares the original and updated Air Force ISD models. It outlines the activities
                              comprising the ISD process and shows how they fit into a total instructional system with
                              evaluation and the principles of quality applied throughout the process. It discusses
                              differences among Air Force ISD applications and how the requirements of using
                              commands drive ISD implementation.
                              ·Learning Theory briefly reviews and updates instructional and learning theories that
                              are incorporated in recent instructional design and suggests directions of future
                              developments.
                              ·Planning discusses the management and technical concerns that should be addressed
                              before beginning an ISD project.
                              ·Analysis describes the activities that occur during analysis of instructional need.
                              ·Design covers the activities and products of the design phase.
                              ·Development gives the techniques and activities used in producing instructional
                              materials.
                              ·Implementation describes fielding an instructional system and initiating instructional
                              delivery.
                      ·Evaluation discusses the various means of measuring effectiveness and efficiency at the
                      different stages in the life cycle of an instructional program.

Air Force Training    AFMAN 1-1 states that people are the decisive factor in war. It is imperative that people
Doctrine              receive the right education and training at the right time. Education and training should:

                                                   ·Prepare forces for combat.
                                                   ·Be as realistic as possible.
                                                   ·Be conducted for all forms and levels of war.
                                                   ·Give special attention to training for joint and combined
                                                   employment.

                      ISD can help ensure that you meet these objectives.
6                                                                 AFMAN 36-2234              1 November 1993

Introduction       This chapter provides information on the background of ISD, how it fits in the total
                   instructional system, and how it relates to Quality Air Force (QAF).

                                               Section A
                                              Background

Roots Of ISD       The Air Force ISD process is an adaptation of the systems engineering process to problems of
                   developing, implementing, and evaluating instruction. The ISD process assumes that
                   alternative solutions to instructional problems will be more or less cost- efficient depending on
                   the instructional need and environmental constraints, and that a systems approach to choosing
                   among alternative solutions will produce the most effective results.

Four Generations   According to Tennyson (1991), ISD is an evolving process. The following is a summarization
Of ISD             of Tennyson's four generations of instructional development.
AFMAN 36-2234          1 November 1993                                                                                  7

Four Generations Of
ISD (Continued)




Sources of Concepts Concepts used in designing the ISD process have been drawn from the disciplines of:
                                                       ·System engineering
                                                       ·Behavioral and cognitive psychology
                                                       ·Instructional technology

                         When the Air Force ISD process was originally defined it represented the then state-of-the art
                         specification for the design and development of instruction. At that time, behavioral learning
                         theory held that efficient job instruction could teach the behaviors directly without providing
                         cognitive understanding of the theoretical foundations of the activity being performed.
                         Behavioral learning has provided a successful approach for teaching procedural tasks. Though
                         procedural tasks still account for the vast majority of Air Force jobs, the remainder requires
                         concepts beyond behavioral learning theory. The concepts beyond behavioral learning theory
                         are from cognitive psychology and systems engineering.

Goal                     As originally adopted in the Air Force, the goal of instructional systems development was to
                         increase the effectiveness and efficiency of education and training by fitting instruction to jobs,
                         eliminating irrelevant knowledge from courses while ensuring that students acquired the
                         necessary skills, knowledge, and attitudes to do the job. Instruction was to be provided in the
                         areas most critical to job performance and was not to be wasted in areas having a low probability
                         of meeting immediate or critical long-term needs. The ISD process prescribed a series of
                         procedures which addressed decisions about exactly what, where, how, and when to teach the
                         skills, knowledge, and attitudes needed to perform every task selected for instruction.

Effectiveness            The Air Force developed its first major instructional system in 1965. Application of the ISD
                         process has consistently improved the quality of instruction in the Air Force. Use of the process:

                                                       ·Increases the effectiveness of the instruction.
                                                       ·Improves time-efficiency.
                         ·Produces the best instruction for the lowest possible cost.

ISD Models               Over the years, the ISD process has been described graphically through a wide variety of models
                         which call out the procedures in a number of phases or steps. Most models encompass the
                         functions of analyzing instructional needs, and designing, developing, implementing, evaluating
                         and improving instruction. The use of a systematic problem solving approach is the common
                         thread that runs through all models.

ISD Is QI                ISD is a quality improvement (QI) process. The processes and products of the phases are
                         continuously assessed for quality with emphasis on how well they meet the users' needs. Life
                         cycle evaluation ensures continuous improvement of the instruction.
8                                                                 AFMAN 36-2234             1 November 1993

Original Air Force   The original Air Force Model was a five-step process, shown in Figure 1.
ISD Model
AFMAN 36-2234        1 November 1993                                                                                   9

Description of the    The original Air Force model organizes the ISD functions into five steps.
Model
                      1. Analyze System Requirements

                          This is done through occupational, job, and task analyses which result in statements of
                          behavior, conditions, and standards for task performances.

                      2. Define Education and Training Requirements

                          This step includes a needs analysis to determine if training is needed, assessment of target
                          population characteristics, and selection of tasks for instruction through consideration of
                          such factors as criticality, learning difficulty, and frequency of performance.

                      3. Develop Objectives and Tests

                          Here the developer writes the three-part objectives that define what the students should be
                          able to do after instruction, the conditions under which they may perform, and the
                          acceptable standard of performance. The developer then writes test items to measure student
                          performance on each objective.

                      4. Plan, Develop, and Validate Instruction

                          In this step, the developer designs and produces course materials. The developer tries these
                          materials out on students using the criterion test items to ensure that the students can
                          achieve course objectives.

                      5. Conduct and Evaluate Instruction

                      Here the course is fielded. Evaluation of instructional effectiveness continues for the life of the
                      course and identifies needs that may develop for improving or updating the instruction.

Feedback and          This original model also shows (1) how the ISD process uses feedback and interaction among
Constraints           the functional blocks of activities to allow for continuous improvements to the products, and (2)
                      how environmental constraints limit the designers' choices to what is possible.

Flexibility           The process allowed instructional developers to enter or reenter the steps of the ISD process as
                      necessary to develop, update, or revise the instructional system. The Air Force model worked
                      well and was considered adequaThe te. It supported an instructional system that was focused
                      primarily on classroom education and technical training delivered by an instructor using the
                      lecture/demonstration method.

Need for Updating     The Air Force instructional goals, which have not changed, are to field effective and
                      efficient instructional systems that prepare individuals to meet Air Force performance
                      requirements. However, the process, which served the Air Force well for many
                      years, needed to be updated. Constant changes in the instructional environment,
                      increasingly complex job requirements, new instructional technologies, and emerging
                      automated instructional development tools, as well as other changes, stretched the
                      capabilities of the Air Force ISD process. This led to a belief that the linear approach
                      to ISD was not adaptable to today's conditions.
10                                                                         AFMAN 36-2234              1 November 1993

New Concerns              Today's concerns include not only classroom instruction, but also instruction that is exported to
                          the job site using new delivery methods and technologies. New automated instructional
                          development tools can make the instructional development more efficient. Building quality in
                          instructional systems is a key concern. Other concerns are the concept of totally integrated
                          training systems and how to do the ISD process in different applications such as systems
                          acquisition, education, aircrew, and technical training programs.



Future Requirements Principles of ISD have evolved over the past three decades from ISD as a tool for applying
                          behavioral learning principles to classroom instruction, through models of step-by-step
                          procedures designed to enable anyone to develop instruction, to sophisticated models concerned
                          with complex technological as well as cognitive and attitudinal issues that require experienced
                          instructional design experts to sort out.

                          Today instructional development, updating, and revision require expertise not only in
                          instructional design but in media (e.g., computer hardware and software, video, interactive
                          systems), cognitive learning theory, and vastly complex content areas. The scope of the
                          expertise has gone beyond the capabilities of the single instructional design expert. It now
                          requires a team of experts from any one of several disciplines.

                          Attempts are being made to use expert system techniques to help both the experts and novice
                          instructional developers cope with contemporary advancements. If successful, these techniques
                          will impact instructional design in fundamental ways, such as by providing ISD expert system
                          tools.

                          It is clear that any new model of the ISD process should reflect the movement away from
                          rigorously applied procedures and emphasize adaptability to changing environments. These
                          concerns have become cornerstones in the revision of the Air Force's ISD process. Updating the
                          process should allow the Air Force to meet today's need for effective and efficient instructional
                          systems and continue to meet future challenges in instructional systems development.

                          One of the Air Force's greatest challenges will be to elevate the level of instruction, knowledge,
                          and training which is currently being provided to personnel. It is not enough to enhance the
                          methodology of an ISD system and its principles. Personnel must be trained in the multitude of
                          disciplines and technologies which the Air Force is using and currently examining for future
                          ISD use in order to accomplish the task.
AFMAN 36-2234       1 November 1993                                                                                 11

                                               Section B
                                      Total Instructional System

Updated Air Force    The updated ISD model has been designed to represent simplicity and flexibility so that
ISD Model            instructional system developers with varying levels of expertise can understand the model
                     and use it to develop effective, efficient instructional systems. This model depicts the
                     flexibility that instructional developers have to enter or reenter the various stages of the
                     process as necessary. Entry or reentry into a particular stage of the process is determined
                     by the nature and scope of the development, update or revision activity.

System Functions     An extension of the systems approach places the ISD process within the functional design
                     of a total instructional system. Figure 2 shows the basic top-level system functions of the
                     instructional system: management, support, administration, delivery, and evaluation.




What Are They?       The system functions of the ISD model are as follows.

                        ·Management— the function of directing or controlling instructional system development
                           and operations.

                        ·Support— the function of maintaining all parts of the system.

                        ·Administration— the function of day-to-day processing and record keeping.

                        ·Delivery— the function of bringing instruction to students.

                         ·Evaluation— the function of gathering feedback data through formative,        summative,
                     and operational evaluations to assess system and student performance.

Relation to ISD      Using these essential functions to design the overall instructional system architecture and then
                     allocating them to the respective instructional system components, or people responsible,
                     ensures that these functions are operational when the total training system is fielded. ISD
                     products are integrated into the total instructional system, and aspects of the instructional
                     system functions are active throughout all phases of the ISD process.
12                                                                AFMAN 36-2234             1 November 1993


                  Figure 3 shows the phases most often used in the systems approach, which are analysis, design,
                  development, and implementation, with the evaluation activities integrated into each phase of
                  the process. The phases are embedded within the system functions. Evaluation is shown as the
                  central feedback "network" for the total system.




Relation To ISD   The instructional development process, which the model summarizes, calls for instructional
(Continued)       developers to:

                     ·Analyze and determine what instruction is needed.
                     ·Design instruction to meet the need.
                     ·Develop instructional materials to support system requirements.
                     ·Implement the instructional system.

                  Evaluation is a central function that takes place at every phase.

                  Symbolically, Figure 3 shows that all phases of the model depend on each of the other phases.
                  The ISD process allows the instructional developer or design team to enter or reenter the various
                  phases of the process as determined by the nature and scope of the development or revision
                  activity. The phases of the updated model are described below.

Analysis Phase    In courses that tie the content directly to preparing a student to do a job, the instructional
                  developer analyzes the job performance requirements and develops a task list. The developer
                  then analyzes the job tasks and compares them with the skills, knowledge, and abilities of the
                  incoming students. The difference between what they already know and can do and what the job
                  requires them to know and be able to do determines what instruction is necessary. The activities
                  of formative evaluation begin.
AFMAN 36-2234       1 November 1993                                                                                    13

Design Phase         In the design phase, the instructional developer develops a detailed plan of instruction which
                     includes selecting the instructional methods and media, and determining the instructional
                     strategies. Existing instructional materials are reviewed during this phase to determine their
                     applicability to the specific instruction under development. In this phase, the developers also
                     develop the instructional objectives and test and design the instruction. The implementation
                     plan for the instructional system is developed in this phase and a training information
                     management system is designed, if required. Formative evaluation activities continue in this
                     phase.

Development Phase    In the development phase, both the student and instructor lesson materials are developed. If the
                     media selected in the design phase included items such as videotapes, sound/slides, interactive
                     courseware (ICW), and training devices, these are developed. If a training information
                     management system was developed for the instructional system, it is installed in this phase. As
                     a final step in this phase, the implementation plan is updated. During this phase, instructional
                     developers also validate each unit/module of instruction and its associated instructional
                     materials as they are developed. They correct any deficiencies that may be identified.
                     Validation includes:

                        ·Internal review of the instruction and materials for accuracy
                        ·Individual and small-group tryouts
                     ·Operational tryouts of the "whole" system
                     Revision of units/modules occurs as they are validated, based on feedback from formative and
                     summative evaluation activities. The final step in this phase is to finalize all training materials.

Implementation       The instructional system has been designed and developed, and it is now time for the actual
Phase                system to become operational. In this phase, the instructional system is fielded under
                     operational conditions. The activities of operational evaluation provide feedback from the field
                     on the graduate's performance.

Evaluation           Evaluation is a continuous process beginning during the analysis phase and continuing
                     throughout the life cycle of the instructional system. Evaluation consists of:

                         ·Formative Evaluation, consisting of process and product evaluations conducted during the
                             analysis and design phases, and validation which is conducted during the development
                             phase. Included are individual and small group tryouts.

                         ·Summative Evaluation, consisting of operational tryouts conducted as the last step of
                            validation in the development phase.

                         ·Operational Evaluation, consisting of periodic internal and external evaluation of the
                            operational system during the implementation phase.

                     Each form of evaluation should be used during development, update, and revision of instruction,
                     if possible, and if the form of evaluation is applicable.
14                                                                 AFMAN 36-2234           1 November 1993

Updated AF ISD   Figure 4 depicts the completed ISD model. This completed figure shows the system functions
Model            and ISD phases embedded within the quality improvement (QI) process.




                 The updated model graphically illustrates that:

                     ·Evaluation is the "centerpiece" of the ISD process.
                     ·ISD is a continuous process with the flexibility to enter and reenter the various phases, as
                          necessary, to develop, update, or revise instruction.
                     ·All ISD activities take place within and are dependent on the system functions.
                     ·Teamwork is required between personnel performing system functions and those designing,
                          developing, and implementing instructional systems.
                 ·All ISD activities and system functions focus on continuous quality improvements in the
                 system.



                                   Section C
                                    Quality Improvement

Introduction     The Air Force goal of continuous quality improvement is achieved in the ISD process. As can be
                 seen in Figure 4, the entire ISD process takes place within the sphere of quality improvement.
                 Throughout the process, each ISD activity and product is continuously covered in order to
                 improve quality.

What It Is       Quality improvement (QI) is the continuous, organized creation of beneficial change to the
                 system. The objective of quality improvement is to foster continuous improvement in the
                 products and processes.

                 All of the principles of quality are implemented in the ISD process. The ISD process ensures
                 total quality in the education and training environment by continuously evaluating the process
                 and products. The relationship between the key concepts of QI can be easily seen in the ISD
                 process. For example:

                 ·Customers define quality. ISD emphasizes criterion-based instruction. The criteria are directly
                 linked to performance requirements in the field. Field representatives identify education and
                 training requirements which instruction providers such as Air Education and Training
                 Command (AETC) or other training organizations are then under "contract" to satisfy. All
                 evaluations are focused on the graduate's actual job performance.
AFMAN 36-2234     1 November 1993                                                                                15

ISD and Quality    ·Know your mission. ISD depends on mission and job analysis for the necessary data to design,
Relationship       develop, and implement instruction. All instruction should be based directly on mission or job
                   requirements. The quality checks in the analysis process help eliminate instruction that is
(Continued)        unrelated to the job.

                   Job analysis uses data from many sources, including mission statements found in regulations or
                   locally developed statements. Instructional developers also make use of management
                   engineering reports, occupational survey data, and direct observation to determine the actual job
                   requirements.

                   As part of the job analysis process, an instructional needs assessment is conducted to determine
                   what the actual performance problems are. In some cases, a problem is not due to a lack of
                   instruction, but to deficiencies in the job structure or environment. The ISD process helps
                   ensure that instruction is not developed for non-instructional problems. Instruction may also be
                   developed as a "preventive" measure-that is, to prevent problems and to meet the informational
                   and educational needs of Air Force personnel.

                   ·Know your customers. The information gained in the mission/job analysis process gives the
                   instructional design team information that defines the customer's expectations.

                   Everything that can be done to help students learn should be factored into
                   instructional system design. ISD is based on the premise that what the person
                   needs to do the job determines the instructional requirements.

                   ·Set goals and standards. The goals and standards for an instructional
                   development effort come in many variations. First, the job requirements and the
                   impact of the performance deficiency determine the timing required for the
                   development process and the conduct of the instructional program. Second, the
                   content of the instruction is determined by the person's needs to do the job. The
                   design team should directly translate the cues, conditions, and performance
                   standards of the job directly into the instructional program.

                   ·Focus on customers. As mentioned earlier, the gaining unit or work center needs
                   determine instructional requirements. By continuing to trace the relationship
                   between the job requirements and the person's needs to do the job, a continual
                   focus on the actual field requirement is maintained. In addition, the ISD process
                   requires that the capabilities, aptitudes, and attitudes of the target audience be
                   considered.

                   ·Manage by fact. Each phase of the ISD process requires constant evaluation
                   against the job requirements identified earlier in the process. In addition, a
                   variety of tools have been developed to ensure that design and development
                   decisions are made with supporting data. For example, a number of media
                   selection tools are being used which provide managers information to match
                   training media with the instructional requirements. These matches are based on
                   learning theories and development cost factors (money and time). ISD is
                   designed to guide managers and developers to awareness of factors affecting
                   their decisions.

                   Foster teamwork. An instructional program cannot be designed and developed in a vacuum.
                   In order to develop effective instruction, the design team should be in constant touch with the
                   work center and evaluation offices, to ensure that the training matches the performance
                   requirements of the job.
16                                                   AFMAN 36-2234             1 November 1993

      ·Empower your people. ISD is a problem-solving, decision-making model. Since ISD is
     flexible and there are any number of ways to solve a given instructional problem, a design team
     should be allowed freedom and authority in designing, developing, and implementing
     instruction that meets job performance requirements.

     ·Integrate quality in all phases. Evaluation is continuous quality checking. This is true during
     each phase of the ISD process, from analysis to implementation. Built-in checks in each phase
     ensure the quality of the ISD process and instructional products with emphasis on satisfying
     training requirements and producing graduates who can do their jobs.

     . Evaluate quality constantly. The ISD process is a cyclic, ongoing process of continuous
     improvements. As instructional developers progress through the different phases of ISD, the
     process and products of each phase are constantly evaluated against the instructional
     requirements and principles of learning. The results of the evaluations determine which phase
     of ISD to enter next. Constant evaluation identifies changes in instructional requirements due to
     updates in equipment and personnel which result in new ISD efforts to provide the best possible
     instruction to Air Force Personnel.
AFMAN 36-2234       1 November 1993                                                                                     17

                                Chapter 2
                            LEARNING THEORY

Overview                ·


Definition           Learning theory is the body of principles proposed by psychologists and educators to explain
                     how people acquire skills, knowledge, and attitudes.

Purpose in           Learning theory is used in formal instruction to facilitate and accelerate the learning process.
Instruction          When applied to the practice of instruction, learning principles, derived from theories, can guide
                     the instructional developer in improving the effectiveness and efficiency of the learning
                     activities of a program.

Relation to ISD      Learning theory impacts instructional systems development in several ways.

                        ·Many of the products specifically called for in the ISD phases are derived from behavioral
                           learning theory. In the 1950s, behaviorists developed procedures for designing
                           "programmed" instruction that included:

                            ··Analyzing and breaking down content into specific behavioral objectives.
                            ··Determining procedures needed to achieve the objectives.
                            ··Trying out and revising the steps.
                            ··Validating the program against the objectives.

                            This approach was incorporated into the early ISD procedures.

                        ·Instructional developers apply learning theory to select instructional strategies for the type
                            of learning required. To the extent that there are real differences in the types of
                            learning, e.g., intellectual skills, motor skills, or attitudes, cognitive strategies, different
                            instructional techniques may be needed.

                     ·Instructional developers look to learning theory to explain how individuals differ in the ways
                     they learn. Understanding different learning styles, in order to target methods and materials to
                     individual students, may become the most important theoretical area for enhancing learning.

                                   Section A
                             Theoretical Approaches


Behavioral Theory    The behaviorist school says that learning takes place when the student makes an association
                     between a stimulus or cue and the desired response behavior. When the behavior is given a
                     positive reward, the learning is believed to be reinforced. Learning proceeds as students become
                     able to distinguish among stimuli and make appropriate responses to them. Stimulus events or
                     cues and the corresponding responses are combined into complex patterns. Learning to
                     interpret complex cues and associate them with responses leads to comprehension of the total
                     situation.

Cognitive Theory     Most current theories of learning are cognitive theories. Concern is focused on what is going on
                     in the learner's mind. Two major models of cognitive theory are the information processing
                     model and the social interaction model.
18                                                                     AFMAN 36-2234               1 November 1993

Information          The information processing model says that the learner's brain has internal structures that select
Processing Model     and process incoming material, store and retrieve it, use it to produce behavior, and receive and
                     process feedback on the results.

                     A number of cognitive processes are involved in learning, including the "executive" functions of
                     recognizing expectancies, planning and monitoring performance, encoding and chunking
                     information, and producing internal and external responses.
Social Interaction   Social interaction theory says that learning and consequent changes in behavior take place as a
Model                result of interaction between the learner and the environment. Behaviors are modeled either by
                     other people or symbolically. The environment demonstrates the consequences of the modeled
                     behaviors, and the learner cognitively processes the observed behaviors and consequences, and
                     changes his own behavior appropriately. The cognitive processes include attention, retention,
                     motor responses, and motivation. Techniques for achieving learning include direct modeling
                     and verbal instruction. Behavior, personal factors, and environmental events all operate together
                     to produce learning.

                                               Section B
                                            Types of Learning

Introduction         In this section, learning is addressed in terms of the individual types of learning and the
                     integration of human activities. Categories of learning types establish a framework for how
                     learning takes place. In real life, these types of learning are integrated. This integration is
                     discussed in terms of schemas, enterprise theory and metaskills.

Types of Learning    Learning theorists have categorized human activity into types of learned behavior. Gagné's
                     (1985) categories of learning types are the most inclusive. They include intellectual skills, verbal
                     information, cognitive strategies, motor skills, and attitudes. Gagné suggests that each type of
                     learning requires different internal conditions for processing to occur. Internal conditions may
                     be cued or prompted by external conditions present in the learning environment.
AFMAN 36-2234           1 November 1993                                                                                       19

Intellectual Skills       Intellectual skills are the foundation for all higher learning. They consist of discrimination,
                          concepts and rule-using. Cognitive strategies are often called a higher-order type of intellectual
                          skill.

                          Intellectual skills are hierarchical in nature. For example, in order to learn a higher-order skill,
                          the learner should possess the prerequisites and have already learned the lower-order skills such
                          as discriminations, concrete concepts, defined concepts, and rule learning.

                          Discriminations

                          Discriminations are skills related to seeing differences between stimuli. Most adult problems in
                          discrimination come from physical disabilities like color blindness, hearing loss, or some injury
                          that affects sensory perception.

                          Concrete Concepts

                          Concrete concepts are skills related to categorizing physical objects into one or more classes
                          based on their physical attributes. Identifying resistors from among other electrical components
                          is an example of concrete concept learning.

                          Defined Concepts

                          Defined concepts are skills related to classifying symbolic objects into one or more classes based
                          on a definition. The definition is actually a rule for classification. For example, classifying a
                          verbal statement from an officer as a command is an example of a learned defined concept.

                          Rule Learning

                          Rule learning skills relate to applying principles or procedures to solve problems. Problem
                          solving is the ability to recall relevant rules and use them to solve a novel problem. The product
                          of problem solving is not only a solution to the problem, but also learning a new rule or
                          procedure to be used if a similar situation should arise in the future.

Verbal Information        Verbal information is the learning of names and labels that can be verbalized. It is also called
                          declarative knowledge. Verbal information learning requires some basic language skills. In
                          addition, verbal information is more readily retained when it is learned within a larger context
                          of meaningful information.

Cognitive Strategies The basic premise of an information processing model is that individuals mentally process their
                          environment. This process consists of a number of stages in which the stimuli become
                          information, which is given meaning by previous knowledge and current expectations.
                          Cognitive strategies are employed to maintain the knowledge in short-term memory and
                          translate it to a structure that enters long-term memory as a type of knowledge in the form of
                          propositions, productions or schemas.

                          Cognitive strategies are thought of as executive control mechanisms for learning. Monitoring
                          the use of strategies is "metacognition." Cognitive strategies used in metacognition are called
                          metacognitive strategies.

                          There are different types of cognitive strategies such as clustering items into similar groups to
                          reduce memory load, reading strategies to increase comprehension, and others. Good learners
                          have a variety of strategies they can use to process new information.
20                                                                    AFMAN 36-2234               1 November 1993

Motor Skills       Motor skills are learned behaviors that involve the smooth coordinated use of muscles. Motor
                   skills most often involve a sequence of activities that may be described verbally as an "executive
                   subroutine." This verbal information is learned to provide guidance for learning the execution
                   of the motor skill. When the learner has acquired the motor skill, the verbal routine is no longer
                   needed and the skill is performed in a smooth and continuous manner.

                   Motor skills may be learned by modeling, as when a coach shows a student how to swing a golf
                   club.

                   Motor skills require practice and kinesthetic (natural) feedback. Verbal feedback from an
                   observer also helps the learner make corrections in performance. Much of the instruction is
                   aimed at getting the student to recognize the feel of the motor performance when it is executed
                   correctly.

Attitudes and      The acquiring of particular attitudes may require the prior learning of intellectual skills or
Motivation         particular sets of information. For example, if a positive attitude toward safety is to be acquired,
                   the learner should have (1) intellectual skills (concepts and procedures) associated with safety,
                   and (2) a variety of verbal information about the advantages of following safety procedures or
                   the consequences of not following them.

                   Attitudes have mutually supportive relationships. An individual generally tries to maintain
                   consistency with regard to choice behaviors. However, attitudes are based on perceptions of
                   reality. These perceptions are colored by misinformation or critical experiences.

                   Attitudes are learned or influenced by observing others and viewing the consequences of their
                   behavior. This type of learning (vicarious) is a distinct principle of social learning. External
                   conditions for learning attitudes include a human model.

                   Experiences play a major role in the formulation of attitudes.

                   Motivation plays a significant role in learning. Keller (1987) has developed a general model
                   integrating the various sources of motivation for learning. He calls it the ARCS model, an
                   acronym for the four sets of conditions that should be met to have a motivated learner:

                       ·A for attention.

                           Attention involves grabbing the learner's interest at the beginning of instruction and
                           maintaining that interest throughout the lesson and course.

                       ·R for relevance.

                           Relevance is the personal significance and value to the learner of mastering the learning
                           objectives.

                       ·C for confidence.

                           Confidence relates to the learner's expectancy of success.

                       ·S for satisfaction.

                   Satisfaction comes from achieving performance goals.

Integration of     In real life, the types of learning are integrated. This integration is discussed in terms of
Human Activities   schemas, enterprise theory and metaskills.
AFMAN 36-2234           1 November 1993                                                                                     21

Schemas                  Intellectual skills should be integrated into existing knowledge to be remembered and recalled.
                         They are thought to be stored as schemas and as part of propositional networks. A schema is a
                         structured set of memory elements, (propositions, images, and attitudes) representing a large set
                         of meaningful information pertaining to a general topic. The topic may be an object, such as a
                         jet fighter, weapon, or officer. Or it may be an event, such as a preflight check or preventive
                         maintenance procedure. Regardless of type, schemas contain information on certain well-
                         understood features of the object or event. These features, called slots, are filled in by the
                         learner when encountering new information that relates to the schema. Schemas are acquired
                         through experience and may be the greatest benefit of apprenticeships.

                         Recent theory proposes that intellectual skills are "situated." That means their utility is in a
                         large part a function of how they are learned. In order that they do not become "inert
                         knowledge," they should be learned and practiced within a broader context.

Enterprise Theory        Gagné and Merrill (1990) proposed a method to identify learning goals that require an
                         integration of multiple objectives. They proposed that such an integration of multiple objectives
                         be conceived in terms of the pursuit of a comprehensive purpose in which the learner is
                         engaged, called enterprise. An enterprise is a purposeful, planned activity that may depend for
                         its execution on some combination of verbal information, intellectual skills, and cognitive
                         strategies, all related by their involvement in the common goal. A task for the instructional
                         developer is to identify the goal of a targeted enterprise along with its component skills,
                         knowledge, and attitudes, and then to design instruction that enables the student to acquire the
                         capability of achieving this integrated outcome.

Metaskills               The metaskill concept (Spears, 1983) refers to the complex skills of adapting, monitoring, and
                         correcting the use of individual skills in complex performances that integrate cognitive,
                         perceptual, and motor processes. Proficiency in metaskills depends on the number of individual
                         skills practiced. Plateaus in performance are related to the intervals required for students to put
                         together new sets of metaskills.

                         Processes involved include:

                            ·Gaining organic knowledge of the effects of actions on overall goals.
                            ·Organizing knowledge hierarchically to include cause-effect rules.
                         ·Developing monitoring procedures that incorporate outcome expectancies.

Alternative Learning The types of learning previously discussed in this section include more traditional behavioral
Strategies           outcomes as well as some of the newer cognitive outcomes. These learning outcomes, as well as
                         others, are being enhanced by new alternative learning strategies. A brief discussion of
                         accelerated learning is provided as an example of an alternative learning strategy.

                         Accelerated learning is a method of using traditional and non-traditional techniques to
                         increase instructor and student motivation. The principles of accelerated learning apply to
                         classroom instruction as well as individual multimedia methods. In the accelerated learning
                         environment, students and instructors tend to be more creative, motivated, team-oriented, and
                         willing to try different things.

                         In the classroom environment, where possible, instruction is put into a social context to enrich
                         mental performance and help supply diversity. Classroom activities involving interpersonal
                         skills such as role playing, games, and skits provide students with an opportunity to interact and
                         express themselves. These activities also allow students to strengthen their intrapersonal skills
                         by interpreting information in light of their own personal experiences.
22                                                                        AFMAN 36-2234               1 November 1993

                         With accelerated learning techniques, the environment in which students receive instruction
                         plays a key role in the learning process and should be attended to when developing instruction
                         using the principles of accelerated learning. For example, lighting, temperature, decorations,
                         and seating arrangements should be adjusted and controlled to enhance learning.

                         Some of the other alternative learning strategies being used in today's learning environment
                         include:

                             ·Cooperative learning
                             ·Situated learning
                             ·Constructive approach
                             ·Cognitive apprenticeship
                             ·Scaffolded instruction
                             ·Reciprocal teaching
                              ·Concept mapping

                                              Section C
                               Applying Theory to the Learning Situation


Introduction             Within real-world constraints, instructional developers design instructional programs and select
                         learning contexts and materials to implement learning principles contained in a given theory.
                         The learning context relates to the external situation that enables new learning to be associated
                         or connected to previous learning. For example, if students are to learn a list of names,
                         associating them with a previously learned list is often very effective.

Context Variables        The context in which something is learned determines not only what is learned but how it can
                         be used in the future. Learning is situated in the context and gains meaning from that context.
                         For example, problem solving should occur in an authentic context. The information and
                         principles learned when solving real problems may be better remembered by the student.

Cooperative              Social cognition psychologists feel that a context promoting cooperative learning is more helpful
Learning                 to students than one promoting individual work, especially with regard to learning attitudes.

                         Other psychologists see cooperative learning situations as effective when the interaction among
                         students can supply learning support through tutoring and feedback. For example, peer tutoring
                         is a technique for improving learning in a particular type of context.

Learning Activities      Students learn as they confront the response demands built into activities. Good activities are
                         built around the attainment of multiple goals. They engage students in active forms of learning,
                         help develop values and critical thinking skills, are built around important content, and are well
                         matched to the learner's abilities, interests, and learning style. Different types of instructional
                         delivery systems have been associated with particular instructional contexts. For example,
                         computer-assisted instruction was considered most appropriate for individualized instruction
                         because it could be personalized, test for misunderstandings, and provide feedback. However, it
                         has been determined that the computer can be an important part of cooperative learning
                         environments.

Technology Changes Emerging ICW technologies such as CD-ROM, videodisc, fax, conference phones, and two-way
Context            satellite TV change the context of instruction. This is because technology not only delivers
                         information, but is also a tool that can be used to enable information retrieval from knowledge
                         databases in ways different from printed text. The encyclopedia on a CD-ROM is not likely to be
                         used in the same way by a learner as the same encyclopedia in the form of printed text.
AFMAN 36-2234        1 November 1993                                                                                      23

Materials             The nature of the materials affects the stimuli with which the learner interacts during the
                      process of learning. Instructional materials are often used in the broader context of an
                      instructional delivery system. A textbook, for example, is meant to be used with a teacher. The
                      textbook does not provide, in most cases, enough learning support to complete the learning
                      process. Most students cannot learn from it without additional information. These broader
                      instructional delivery systems often provide a variety of materials in what is called a
                      "multimedia" environment. This environment might include a live instructor or might be totally
                      mediated as in a computer-interactive video.

                      Emerging technologies make distinguishing between different types of materials difficult, but
                      the features of the delivery systems can be described in terms of their capabilities for providing
                      different stimuli and different "events" of instruction. For example, using interactive video as
                      the delivery system can provide several sources of stimulation for the students, such as "multiple
                      learning tracks" and "self-pacing," both of which serve to stimulate the students. Interactive
                      courseware also has many applications in the "events" of instruction. For example, interactive
                      courseware can be used to "stimulate recall of prerequisites" while providing feedback at the
                      same time at the appropriate points in a lesson.

One-on-One            It is believed that the most capable delivery system would be the expert (instructor) working
                      one-on-one with the learner on real problems in a real situation. For example, if the skill to be
                      learned were maintaining a plane's fuel system, the ideal situation would seem to be to pair a
                      novice with an expert and have the expert explain the procedure while the novice performs it.
                      In this case, the instructor can provide for the occurrence of all the events of instruction.

Mediated Materials    Different mediated learning systems have different capacities for providing these events. For
                      example, a videotape can elicit learner responses to a question but it is only capable of giving
                      rhetorical feedback. It is incapable of correcting learner misunderstanding because it is
                      incapable of judging whether the response to a question was correct.

Physical Objects      Situations that contain physical objects are the most concrete and easy to understand because
                      they don't require the translation of symbols. When instruction is done with real objects, all the
                      cues for later performance are available. However, real situations may be very complex or
                      hazardous, and it may be simpler to gain information from a simplification of the real situation
                      in the form of a mock-up or simulation.

                      Learning situations utilizing physical objects call for the learner to manipulate the objects.
                      Through handling them the learner gains much information about their size, sturdiness,
                      complexity, and other features. By handling the object, the learner is building schemas of the
                      experience that may be important in future learning.

                      Real materials are often used in demonstrations by instructors. A demonstration makes the
                      learner an observer of the expert handling the equipment. This instructional technique usually
                      involves the transmission of a great deal of declarative knowledge about the object being
                      discussed, which the learner encodes and stores with greater rapidity than in the handling
                      environment.

Film and Video        Media-type materials such as film and videos are more abstract than physical objects. These
                      media generally have a linear format, and information is paced by the delivery system. They
                      usually present a visual image from an objective rather than a subjective point of view, and they
                      are edited to compress time. This removes cues that are available from the real equipment and
                      handling activities.
24                                                                       AFMAN 36-2234              1 November 1993

Pictures and Text       Most abstracts are still pictures, diagrams, and printed text. In order to understand text you very
                        often need to look at the real object, and to understand the real object you have to read the text.
                        The text is providing what Reigeluth (1983) calls an instructional overlay that provides the
                        learner with the events of instruction that cannot be provided by the object itself. On the other
                        hand, the real object provides the context for using the information from the text. Both are more
                        efficient when used together.

Printed Text            The most abstract medium is printed text. To gain meaning from printed text and
                        illustrations, the learner should be able to read (that is, decode) words. Furthermore, the
                        learner should be able to comprehend what is being said. Learning is more difficult
                        because physical cues are absent. The learner cannot query the author when there is
                        ambiguity in the message.

                        Printed text is generally "formal" and follows different rules for communication than
                        demonstrations or video instruction. This formality makes printed text more difficult to
                        understand. Authors also vary in their ability to write clearly and use illustrations to
                        provide learning guidance.

Internal Events of      Events of learning are a set of communications embedded in instructional activities. They serve
Information             the function of activating internal events of information processing. The learning process is
                        shown in the following table.
 Processing

                                 Learning Process                                     Learning Phase
                Expectancy                                                   Motivation
               Perception                                                   Apprehending
               Working Storage                                              Acquisition
               Encoding                                                     Processing
               Storage                                                      Retention
                       Learning Process                                     Learning Phase

               Validation of Understanding                                  Feedback
               Transfer                                                     Generalization
               Valuing                                                      Personalizing


Guidelines for          The model addresses procedures for developing instruction and this chapter addresses learning
Application             theory. Together they provide an orderly method for systematic decisions in an integrated
                        design.

                        The procedure for developing instruction is guided by the application of learning theory based
                        on known approaches that work. Instructional designers use "what works" for a given
                        application. Once an approach has been selected, you need to be consistent in the learning
                        analysis, development of objectives and choice of instructional strategy.
AFMAN 36-2234   1 November 1993                                                                            25

Additional       For more information on applying learning theory to learning, see:
Information
                     ·AFMAN 36-2236, Handbook for Air Force Instructors.
                     ·Gagné, R. M. and Merrill, M. D. (1990). Integrative Goals for Instructional Design.
                         Educational Technology Publications, 38(1), 1-8.
                     ·Keller, J. M. (1987). The Systematic Process of Motivational Design. Performance and
                         Instruction, 26(9), 1-8.
                     ·Merrill, M. D., Tennyson, R. D. and Posey, L. (1992). Teaching Concepts: An Instructional
                         Design Guide (2nd Ed.). Englewood Cliffs, New Jersey: Educational Technology
                         Publications.
                     ·Merrill, M. D., Lee, Z., and Jones, M. K. (1990). Second Generation Instructional Design
                         (ID2). Englewood Cliffs, New Jersey: Educational Technology Publications.
                     ·Reigeluth, C. M. (1983). Instructional Design: What Is It and Why Is It? In C. M.
                         Reigeluth (Ed.), Instructional Design Theories and Models: An Overview of Their
                         Current Status. Hillsdale, New Jersey: Erlbaum Associates.
                     ·Spears, W. D. (1983). Processes of Skill Performance: A Foundation for the Design and
                         Use of Training Equipment. (NAVTRAEQ-VIPCEN 78-C-0113-4). Orlando, Florida:
                         Naval Training Equipment Center.
                 ·Tennyson, R. D. and Michaels, M. (1991). Foundations of Educational Technology: Past,
                 Present and Future. Englewood Cliffs, New Jersey: Educational Technology Publications.
AFMAN 36-2234    1 November 1993                                                                                  25


                                                Chapter 3
                                                Planning
Overview

  Introduction    Planning the instructional system structure and functions includes determining ISD
                  process management and evaluation strategies, and estimating resource requirements
                  and constraints. It also includes determining the instructional needs and concepts. This
                  planning should take place before developing an instructional system or revising
                  existing courses can begin.

                  The instructional developer or design team may be responsible for doing the
                  preliminary planning activities, or some of the planning decisions may have been made
                  by another Air Force organizational level or sometimes a contractor. Although not
                  a specific phase of the ISD process, planning is a key event and occurs throughout the
                  process.

                  Note: During this discussion on planning and throughout this manual, several plans
                  are frequently mentioned. Though mentioned, proliferation of documentation is
                  discouraged. A minimal record of decisions made for future reference is often
                  sufficient. Also, in some organizations a single plan with subsets may be adequate.

 Additional       For more information on planning, see:
 Information
                  · Briggs, L. J. and Wager, W. W. (1981). Handbook of Procedures for the
                    Design of Instruction (2nd Ed.). Englewood Cliffs, New Jersey: Educational
                    Technology Publications.
                  · Dick, W. and Carey, L. (1990). The Systematic Design of Instruction (3rd
                    Ed.). Glenview, Illinois: Harper Collins Publishers.
                  · Knirk, F. G. and Gustafson, K. L. (1986). Instructional Technology: A
                    Systematic Approach to Evaluation. New York: Holt, Rinehart and Winston.
                  · Rossett, A. (1987). Training Needs Assessment. Englewood Cliffs, New
                    Jersey: Educational Technology Publications.



                                              Section A
                                  Determine Instructional Need

Introduction      The first activity before entering the ISD process is to determine that personnel need some kind of
                  instruction. Assessing instructional need is a critical activity that should be performed before any
                  other planning occurs or additional resources are committed to a project. A good assessment should
                  tell you if the "need" can be satisfied with instruction or may require some other solution such as a
                  policy change, new procedures, better working conditions, or others which are normally solved by
                  management.
26                                                                                      36-2234       1 November 1993


What Are             The term "instructional need" has several definitions (Stufflebeam, 1985). The definitions most often
Instructional Needs? used are:
                               ·Discrepancy view. A need is the difference between "what is" and "what should be." In this
                                   definition, the difference between what "is being taught" and what "should be taught" is the
                                   discrepancy.

                               ·Democratic view. Needs are identified by a group of experts (instructional developers, project
                                  managers, and others) who, by the democratic process of majority rule, determine what
                                  changes need to be made to the instruction.

                               ·Diagnostic view. Need is determined by identifying concepts, principles, and procedures whose
                                   absence or deficiency would hamper the students in meeting job performance requirements.

                          ·Analytic view. Need is determined by accurately predicting the future instructional needs based on
                          the current instructional situation.

How To Identify           Instructional need is identified when there is a lack of skill, knowledge and attitudes that personnel
Instructional Needs       should have in order to perform an activity adequately.

                          Examples of types of skills, knowledge and attitudes that personnel may not have are:

                               ·Behavioral - skills in using tools and test equipment
                               ·Cognitive - knowledge of information
                          ·Affective - knowledge of effective interpersonal skills

Who Determines       Instructional developers or the design team can receive a statement of instructional need from any Air
Instructional Needs? Force organizational level, or the instructional developers may perform an instructional needs
                          assessment in response to a performance problem, or it may be part of a statement of work for a new
                          acquisition.

What Signals              Instructional needs may be present when:
Instructional Needs?
                              ·A problem surfaces in an area where there is no current instruction.
                              ·Technical or doctrinal changes make existing instruction obsolete.
                              ·A new weapon system is planned.
                              ·Instruction in a topic is mandated.
                          ·Educating for future assignment.

Stages of Assessing       The four stages involved in assessing instructional needs are:
Instructional Needs
                              ·Planning the assessment.
                              ·Defining the problem.
                              ·Documenting the deficiency.
                          ·Developing the solution.

How To Do It              Instructional needs assessment is the means of identifying whether there is a need to develop or revise
                          instruction to solve an identified problem. A performance problem might be related to a design in
                          which the instructional strategy does not support the learning process. The steps of instructional
                          needs assessment are:
AFMAN 36-2234            1 November 1993                                                                                   27



  St ep                      Activity                 Purpose
  1                          Determine and state      ·Determine purpose and objective of the assessment.
                             purpose                  ·Develop plan for conducting the needs assessment.
                                                      ·Document the plan.
  2                          Identify data            ·Identify data that describes the actual performance and the
                             requirements             desired performance.
  3                          Select data collection   ·Select appropriate method of collecting data such as:
                             method                   ··Interview
                                                      ··Questionnaire/survey
                                                      ··Records and reports
                                                      ··Group discussion
                                                      ··Work samples
                                                      ··Observation
  4                          Collect and analyze data ·Collect sufficient data to document the performance
                                                      deficiency.
                                                      ·Analyze data to identify the performance deficiency.
  5                          Develop instruction      ·Develop or revise appropriate instruction to solve the
                                                      performance deficiency.


                                                  Section B
                                   Determine Instructional System Concepts
Introduction              The total instructional system concept provides the framework for applying the ISD process. The
                          instructional system concept provides your best initial estimate of what the instruction should do and
                          what it should look like. Determination of an instructional system concept is guided by the
                          determination of the needs and the application of learning theory.

Instructional Concept When planning the instructional system concept, make a preliminary estimate of the requirements
Elements              and constraints to be considered in fielding the total instructional system. These should include
                          requirements for the system functions of:

                              ·Management - directing and controlling instructional system development and operations
                              ·Support - providing for and maintaining all parts of the system
                              ·Administration - day-to-day processing and record keeping
                              ·Delivery - means of bringing instruction to the student
                              ·Evaluation - assessment of how well the system and the students perform
                          ·Quality improvement - process and product compliance with approved plans, procedures, and
                          processes

What the              When conceptualizing the overall instructional system, address:
Instructional Concept
                         ·Overall description of the instruction
Covers                   ·Mix of instructional methods and media
                               ·Overall length of instruction
                               ·Location of the instruction
                               ·Anticipated student load
                          ·Alternative solutions to resource constraints
28                                                                              36-2234        1 November 1993


Planning            The instructional system concept is determined from information about:
Considerations
                        ·Type and amount of instruction that may be needed
                        ·Target audience
                        ·Estimated funding requirements
                        ·Equipment likely to be needed
                        ·Type and size of facilities that may be needed
                        ·Appropriateness of conducting training on-site
                        ·Estimated time required to deliver the system
                        ·Possible impact on personnel
                    ·Use of existing and/or modified training equpment

Sources of          Concept planning information may be obtained from:
Information
                        ·Existing courses
                        ·Subject matter experts
                        ·Learning principles
                    ·Higher level functional or policy guidance

Ensuring That the   Achieving an instructional aim accomplishes the goal of meeting the need. When developing the
Concepts Meet the   overall description of what instruction should do and look like (the concept), consider each
                    instructional aim to ensure that you meet the need. The following table describes the instructional
Needs               aim for each learning phase.

 Learning Process   Learning Phase              Instructional Aim
 Expectancy         Motivation                  Build relevancy and communicate the goal.
 Perception         Apprehendin g               Focus attention.
 Working Storage    Acquisition                 Present information in manageable units.
 Encoding           Processing                  Build upon existing knowledge.
 Storage            Retention                   Merge new information with existing
                                                knowledge.
 Retrieval          Recall                      Attach new skills, knowledge, or attitudes
                                                (SKA) to environmental cues.
 Validation of      Feedback                    Test accuracy of new SKA.
 Understandi ng
 Transfer           Generalizati on             Allow for generalization of recall cues.
 Valuing            Personalizin g              Reinforce meaningfulness of new SKA.


Output              Training system concepts provide the structure for organizing and integrating all of the activities
                    required by a total instructional system.

                    As planning proceeds, you should adjust the parts of the system concept to fit real-world constraints
                    or take advantage of opportunities that may arise.



                                        Section C
                     Determine Resource Requirements and Constraints
AFMAN 36-2234            1 November 1993                                                                                    29


Introduction              The instructional system concept may suggest major considerations from which you can estimate the
                          requirements for equipment, facilities, personnel, and time, which, along with funding, should
                          translate into the ideal instruction for meeting the identified need.

                          All of these requirements categories are subject to constraints that may limit your design and cause
                          you to look for alternatives.

Early Planning            You need to include resource requirements and constraints in your early planning to ensure that you
                          have enough time to secure the resources, or in the case of a constraint, you have time to solve or
                          "work around" the problem.

Requirements              The resource requirements for an instructional system should generally fall into the following
Categories                categories:

                               ·Equipment - How many personal computers will you need? Will you need special equipment to
                                   be built? When will you need it?

                               ·Facilities - How large should the facility be? What are the power requirements? Are you
                                   involved with the facility design reviews?

                               ·Personnel - How many instructors/instructional developers will you need? What experience do
                                   they need? Will instruction/courseware be contracted? If so, to what degree?

                               ·Time - How much lead time do you need to procure the equipment, facilities, and personnel?
                                   How long will it take to complete course development? How long will the instruction take?

                                ·Funding - What are the funding requirements to obtain the equipment, facilities, and
                          personnel you need to develop and operate the instructional system? What will be the life cycle
                          costs to operate and maintain the system? If training on-site, what are temporary duty costs?

Who Is Responsible? Although other activities may have responsibilities for providing resources, the instructional systems
                          manager has the overall responsibility for securing needed resources.

If You Can't Get          If you can't get the required resources, you should work around the constraint or select another
Resources                 alternative. For example:
                          • If you can't get your part-task trainer, borrow operational equipment from the using
                               command.
                          • If you need eight computer terminals and only have four, operate the course on two shifts.
                          • If you need hand tools and test sets that are required by technical order, borrow or use substitute
                          equipment.

                                                   Section D
                                         Develop ISD Management Plan
Introduction              As previously stated, planning is the keystone of instructional development. When planning to
                          develop an instructional system, you need to develop an ISD management plan. The ISD
                          management plan is a subset of the system training plan (STP).

Why Have a Plan?          A properly developed ISD management plan ensures that you have a "roadmap" to keep the
                          instructional development process on course.

                          Information in the plan is periodically compared to the actual progress to ensure that the intent of the
                          plan is being carried out and that a quality instructional product is delivered on time and within
                          budget. The ISD management plan meets milestones set out in the STP.
30                                                                                     36-2234        1 November 1993



Who Is                     Managers are responsible for developing an ISD management plan for each instructional
Responsible?               development project. Everyone involved in the project is responsible for doing their part to keep the
                           project on course.

What Is in the Plan? Content of the ISD management plan is determined by managers in the instructional activity.
                           However, the plan should contain adequate information to manage the instructional development
                           project.

                           The plan may contain information such as:

                               ·Approval dates/signature
                               ·Definition of the project
                               ·Overall project responsibility
                               ·Individual task responsibilities
                               ·Milestones
                               ·Identified constraints
                           ·Support requirements


                                                     Section E
                                            Develop ISD Evaluation Plan
Introduction               Evaluation should be integrated throughout each activity of the ISD process. Whether you call it
                           evaluation or quality improvement— it's important. As a manager, one of your top priorities is to
                           develop an ISD evaluation plan to ensure that the instructional development process and products are
                           of high quality. Criteria for evaluation and acceptance are the key to evaluation. These criteria
                           should be specific enough to be used to measure the quality of products submitted by a contractor.
                           Training effectiveness standards are crucial.

Quality Concerns           Quality is your first and last concern when making plans to develop a new instructional system or
                           revise an existing system. The concern for quality continues throughout each phase of the
                           development process.

                           Evaluating or assessing the quality of the process and products of each phase of instructional
                           development is the centerpiece of ISD.

Why Have a Plan?           An ISD evaluation plan is necessary to establish what and how you are to evaluate during the
                           instructional development process. The plan, which is the "benchmark" for quality, ensures that the
                           ISD process results in a total quality system.

Who Is                     Managers (such as project officers, supervisors, or training specialists) are responsible for developing
Responsible?               a comprehensive ISD evaluation plan. Some organizations may have an evaluation office prepare this
                           plan. However, everyone is responsible for quality.

What Is in the Plan? The ISD evaluation plan includes information sufficient to ensure that the ISD process results in total
                           quality in both process and products. The plan may include, but is not limited to, the following
                           information:

                               ·Identification of responsibilities including taskings
                               ·Scope and purpose of the evaluation
                               ·How and when the evaluation activities are to be accomplished
                           ·Documentation and report requirements
AFMAN 36-2234            1 November 1993                                                                                    31



                                                        Chapter 4
                                                       ANALYSIS
Overview

Introduction              When a needs assessment has indicated a need for some form of instruction, and the necessary ISD
                          project planning has been done, it is time to enter the analysis phase of instructional development.
                          During this phase, instructional developers conduct various forms of analyses such as occupational,
                          job, mission, task, learning, resource, and target analyses. The nature and scope of each ISD project
                          determines which of the various analyses you conduct. For example, revising an existing course to
                          cover a new piece of equipment would not require another job, learning, or target audience analysis.
                          Instructional systems that are developed or revised based on objective, valid and reliable analysis are
                          likely to be more accurate and appropriate than instruction that is not.

                          Managers should evaluate products of the analysis activities in terms of the initial evaluation plan for
                          the ISD project and update the evaluation plan as required. Also, since the management plan ensures
                          that the project remains on course and schedule, the management plan should be updated to reflect
                          any necessary adjustments.

Where Are You in theIn order to better visualize the process, an ISD model with analysis highlighted is provided in Figure
Process?            5.




Objectives                The objectives of this chapter are to:

                               · Explain the various types of analyses that may be conducted in the analysis phase.
                               · Explain update of the ISD evaluation plan.
                                · Describe update of the ISD management plan.


Additional                For additional information on the analysis phase of instructional development, see:
Information
32                                                                         36-2234        1 November 1993


                     •    Beckschi, P. F., Lierman, B. C., Redding, R. E. and Ryder, J.M. (1993) Procedural Guide
                          for Integrating Cognitive Methods into Instructional Systems Development Task Analysis.
                          Brooks Air Force Base, Texas: Air Force Materiel Command.
                      • Briggs, L. J. and Wager, W. W. (1981). Handbook of Procedures for the Design of
                     Instruction (2nd Ed.). Englewood Cliffs, New Jersey: Educational Technology Publications.
                      • Dick, W. and Carey, L. (1990). The Systematic Design of Instruction (3rd Ed.).
                            Glenview, Illinois: Harper Collins Publisher.
                      • Gagné, R. M. (1985). The Conditions of Learning (4th Ed.). New York: Holt, Rinehart and
                          Winston.
                      • Leshin, C. B., Pollock, J. and Reigeluth, C. M. (1992). Instructional Design Strategies and
                          Tactics. Englewood Cliffs, New Jersey: Educational Technology Publications.




                                        Section A
                         Occupational/Educational/Mission Analysis
Introduction         Normally, the analysis phase begins with an occupational, educational, or mission analysis. The
                        term used to identify this first stage of analysis should depend on where your ISD project
                        resides, i.e., in the aircrew, acquisition, education, or technical training community. The
                        requirement to conduct this form of analysis may depend on the application, scope, and
                        nature of the project. This level of analysis identifies the duties and tasks of an occupation
                        or job, the goals and content area of an educational requirement, or the characteristics of a
                        mission. A needs assessment should already have been conducted to determine if there is a
                        problem for which instruction is the appropriate solution. If the assessment confirmed an
                        instructional need, you would usually begin instructional development at the analysis phase.
                        However, in some cases, you may be able to enter directly into the design phase of ISD. This
                        section addresses the first stage of analysis.

Why Analyze?     The initial analysis of the occupation or job, educational, or mission requirement provides you with
                 information needed to begin to determine instructional requirements. For example, during the
                 occupational or job analysis you identify the duties and tasks to examine during task analysis. From a
                 mission analysis you should be able to identify such characteristics as mission role diversity,
                 equipment utilization requirements, or danger associated with equipment operation, which you should
                 use to specify training equipment or skill integration requirements. Instructional developers or the
                 design team should refer to the USAF Occupational Measurement Squadron where a wide variety of
                 support information resides.

What Are They?   Occupation, educational, and mission analysis are defined as follows:

                     ·Occupational/Job Analysis - Identifies the jobs which define an occupational entity and
                         identifies duties and tasks which comprise each job.
                     · Educational Analysis - A process of reviewing the educational requirements, developing
                         educational goals, and developing statements of how to achieve the goals.
                     · Mission Analysis - A process of reviewing mission requirements, developing collective task
                         statements, and arranging the collective tasks in a hierarchial relationship.
AFMAN 36-2234           1 November 1993                                                                                     33


Who Is Responsible? Managers are responsible for ensuring that the necessary analyses are conducted. In most cases, other
                          individuals such as instructional developers, subject matter experts (SME), or system analysts should
                          conduct the actual analyses or at least provide technical assistance. Assistance may be needed from
                          one or more of the following:
                               ·SMEs
                               · Occupational Measurement Squadron ( OMS) personnel
                               · System engineers
                               ·System analysts
                               ·Contractors
                               ·Standing committees (e.g., Commission Education Committee)

                          Responsibility is to ensure that the data needed for further analysis and course design work have been
                          obtained.

Sources of Analysis       Some sources of data for occupational, educational, or mission analysis are:
Data
                              · Existing Occupational Survey Reports ( OSR)
                              ·Job inventories
                              · Technical orders (TO)
                              · Air Force (AF) directives
                              ·Department of Defense (DoD) directives
                              · System or equipment specifications/requirements
                              ·System Program Office (SPO) input
                              ·Major Command ( MAJCOM) input
                              · Maintainability and reliability data
                              · Mission Task Analysis Report ( MTAR)
                              ·Contractor data
                              ·Subject matter literature

                          Other data sources will likely exist depending on whether a job, educational, or mission analysis is
                          being conducted.

How To Conduct the The process of conducting an analysis involves a number of steps. The actual number may depend on
Analysis           the type and scope of the analysis being conducted. During the analysis, you may perform some of
                          the steps concurrently, others sequentially.

                          Note: Before collecting and analyzing data, check to see if an OSR already exists that covers the
                          desired area. A survey report serves the following purpose:

                               ·List the tasks.
                               ·Identify who performs the tasks.
                               ·Indicate which tasks are difficult to learn and perform.
                               ·Identify which tasks should be emphasized in training.
                               ·Show who and how many people are performing the tasks.
                               ·Indicate how often the tasks are performed.
                          ·Establish a priority for training.
34                                                              36-2234        1 November 1993


     Normally you should do the following:

         ·Collect data. Data may be collected using several methods such as:


             ··Interviews with experts
             ··Job inventories
             ··Interviews with incumbents
             ··Observations
             ··Questionnaires
             ··System comparisons (new system to existing similar system)
             ··Publication reviews
               ··Tasking orders

         ·Identify the duties. Analyze the data to identify the duties and write duty statements to describe
             the work activity. Organize the data by referencing each duty to a source document,
             indexing the duties and using a cross-reference system if necessary.

         ·Identify the tasks. Analyze the duties to identify the tasks that make up each duty. Write a task
             statement for each task.

         ·Validate the list. Once the list has been developed, review and validate with SMEs to ensure
             completeness and accuracy.

         ·Prioritize the tasks. Select tasks in order of importance for instruction on the basis of:

             ··Task learning difficulty
             ··Criticality of task
             ··Frequency of performance

         ·Assign preliminary instructional method.

         ·Document the results. The results of the analysis should be documented in some traceable form
             such as a print-based report or computer database.




                                  Section B
                                Task Analysis
AFMAN 36-2234     1 November 1993                                                                                       35


Introduction       When the instructional goal is to produce a capability to perform a particular job, the instruction
                   developed should be tied directly to the job tasks. Task analysis is a method for describing the actions
                   or behaviors that make up the tasks the student should learn to perform. A detailed task analysis
                   identifies the behavioral elements the student should exhibit to demonstrate task mastery. Not all ISD
                   instruction is based on task analysis. For example, in Air Force educational courses, the translation
                   of educational goals into measurable behaviors usually does not involve traditional task analysis, but
                   sample behaviors are derived from analysis of the type and level of learning required and the
                   knowledge content of the subject area.

                   Where task analysis is performed, it is important to accurately and completely describe all of the
                   tasks, since these task descriptions or "statements" should be used to develop the instructional
                   objectives which constitute the framework for instruction.

                   Good task analysis is key to the design, development, and delivery of effective and efficient
                   instructional systems. A thorough analysis of all tasks should identify which tasks need to be taught,
                   under what conditions, and what standard of performance should be achieved.

What It Is         A task is an observable and measurable unit of work activity or operation which forms a part of a
                   duty, with one or more duties making up a job. Most tasks in the Air Force are procedural, consisting
                   of a series of steps performed to produce a specific outcome. For example, aircraft fuel systems
                   technicians have many tasks as part of their overall duties. One of their tasks may be to fuel an F-16,
                   but to fuel that aircraft requires many tasks. These tasks could include grounding the aircraft,
                   positioning the fuel hose, and so on.

                   Task analysis is the process of breaking a task down to identify:

                       ·Component steps of a task
                       ·Sequence of those steps
                       ·Condition(s) under which the task should be performed such as tools, equipment, and materials
                           required to perform the task
                       ·Standard of performance that should be achieved to produce a satisfactory outcome


Purpose of Task    Instructional developers, during the task analysis, examine each task in order to determine the job
Analysis           performance requirements. This includes identifying which tasks should be performed, under what
                   conditions they are performed, and the standards of acceptable performance. This information
                   becomes the training requirements for the system. These training requirements are stated in terms of
                   task statements which are used to develop the instructional objectives for the course, construct a
                   hierarchy of objectives, sequence the instruction, and determine resource requirements.

Who Does Task      Instructional developers or the design team are normally responsible for conducting the task analysis.
Analysis?          However, in the case of contractor-developed instruction, contractors are responsible for conducting
                   task analysis and providing the results of the analysis to the Air Force.
36                                                                                       36-2234         1 November 1993


How To Conduct the A task analysis involves many activities that the instructional developer should accomplish. If an
Analysis           occupation, job, or mission analysis has identified the tasks for which instruction is needed, the task
                           analysis process begins by analyzing the task statements to identify subtasks or steps. If the job or
                           mission analysis has not been conducted, then data should be collected to identify the duties and
                           tasks. Refer to Section A for how to do job/mission analyses. This discussion assumes that this
                           analysis has been done. The steps that are normally performed in task analyses are as follows.

                               ·Identify subtasks. Use the task list that has been prepared and validated in the job analysis to
                                   identify the subtasks. Subtasks are work activities that combine to make up a task. Some
                                   reasons for identifying subtasks are:

                                    ··Subtasks are more easily analyzed to identify supporting knowledge and skills.
                                    ··Instruction is easier to sequence when the tasks are broken into subtasks.

                               ·Identify subtask relationship. Some subtasks should be performed sequentially, while other
                                   subtasks can be performed independently.

                               ·Validate the subtasks. The subtasks should be validated to ensure that the right tasks are
                                   identified and the right relationship made. Validation can be done by interviewing SMEs or
                                   by observing tasks performed on the job.

                               ·Select the tasks for instruction. After the subtasks have been thoroughly analyzed and the
                                    results validated, the next stage of task analysis is to select the tasks to use in the instruction.
                                    There are several factors you should consider:

                                    ··Can most job incumbents perform the task without instruction?
                                    ··How often is the task performed on the job?
                                    ··Will job degradation occur if there is no instruction?
                                    ··Is the task critical to the job or mission performance?
                                    ··Is it economical to teach the task?
                                    ··Is there sufficient time to teach the task adequately?
                                    ··Is the task difficult to learn?
                                    ··How soon will the graduate be required to perform the task on the job?
                                    ··What percentage of the personnel are required to perform the task?
                                    ··Will geographical, procedural, or environmental conditions make it unreasonable to teach
                                               all job incumbents to perform the task?
                                    ··If individuals have been taught to perform another task, should they be able to transfer what
                                               they have learned to this task?

                           ·Document the tasks. A variety of formats can be used to document your analysis of the tasks. As a
                               minimum, identify support information for each task. Documenting the task should ensure
                               traceability of the quality improvement (QI) during the task analysis process. Adequate
                               documentation ensures that you will have the information for developing the objectives in the
                               design phase of the ISD process.


Additional                 For additional information on task analysis, see:
Information
                               ·Carlisle, K. E. (1986). Analyzing Jobs and Tasks. Englewood Cliffs, New Jersey: Educational
                                   Technology Publications.
                               ·Wolfe, P., Wetzel, M., Harris, G., Mazor, T. and Riplinger, J. (1991). Job Task Analysis: Guide
                                   to Good Practice. Englewood Cliffs, New Jersey: Educational Technology Publications.
AFMAN 36-2234            1 November 1993                                                                                     37



                                                      Section C
                                                  Learning Analysis
Introduction              After the task analysis has been completed and the tasks to be taught have been selected, you are
                          ready for the next stage in the analysis phase, learning analysis. The results should enable the
                          instructional developer to design an effective and efficient instructional system based on the desired
                          learning outcomes.

What It Is                Learning analysis is the process of analyzing the tasks to be taught to establish learning outcomes in
                          terms of types of learning involved and level of learning desired.

When Should You Do Learning analysis should be done immediately after the task analysis has been completed and before
It?                designing the instructional system. However, this analysis may also be conducted while the objectives
                          are being developed.

Who Should Do It?         Instructional developers or the design team are responsible for conducting the learning analysis. It is
                          likely that the developer may require the assistance of SMEs in order to do a good learning analysis.

Learning                  When you conduct a learning analysis, you should:
Analysis Steps
                              ·Identify the skills and knowledge needed to support performance.
                              ·Build a learning hierarchy of knowledge and skills to be taught.
                              ·Identify the types of learning involved.
                              ·Determine the level of learning needed.
                              ·Identify prerequisite knowledge and skills required.


Conducting Learning The learning analysis should differ depending on whether the instruction is performance-oriented or
Analysis            knowledge-oriented. In the latter case, rather than listing the skills and knowledge needed to support
                          a task performance, the instructional developer looks directly at categorizing type and level of
                          learning needed to satisfy the instructional goal.

                              ·Identify knowledge and skills. Analyze each task and subtask to determine supporting skills
                                  and knowledge needed to enable task performance.

                              ·Categorize types of learning. There are many ways of categorizing types of learning. Some of
                                  the most common are:

                                   ··Intellectual skill
                                   ··Cognitive strategy
                                   ··Verbal information
                                   ··Motor skill
                                   ··Attitude

                              ·Identify prerequisite knowledge and skills. The next stage of learning analysis is the
                                  thorough analysis of each task statement. This analysis should allow the instructional
                                  developer to identify any prerequisite learning that may be necessary, such as skills,
                                  knowledge, and attitudes that the students should have before they can master the tasks to be
                                  taught in the course.
38                                                                                    36-2234        1 November 1993


Integration of Type As discussed previously, types of learning are integrated. As an instructional designer, you will do
and Level of Learningmore than simply analyze individual tasks. The integration of multiple objectives in terms of a
                          comprehensive purpose in which the learner is engaged is called enterprise.

                          During learning analysis, especially of complex performances, you will identify learning goals that
                          require the integration of multiple objectives in order to accomplish a purposeful planned learning
                          activity.

Additional                Additional information on tasks, prerequisite learning, and the hierarchy of learning is provided in
Information               Chapter 5 under the discussion on developing objectives.



                                                      Section D
                                                  Resource Analysis

Introduction              Resources are critical factors in the instructional system, from the initial planning, through
                          instructional development, to operation and maintenance of the system. During the initial planning
                          stage, long-lead items such as equipment and facilities will need to be identified in order to ensure
                          that there is sufficient time to secure these and other resources. If you are faced with a resource
                          constraint, you may need time to select an alternative to some planned strategy or delivery approach.
                          Remember that instruction, whether an entire course or a module of a course, is limited by many
                          factors including budget, personnel, maximum course length, and others. The instruction should be
                          carefully designed to fit these resource limits.

What It Is                Resource analysis is the process of determining the type and quality of resources that are required to
                          design, develop, operate, and support an instructional system.

Resource                  Resources for the instructional system include:
Categories
                               ·Equipment
                               ·Facilities
                               ·Funds
                               ·Personnel
                                ·Time

Why Analyze               Resources should be analyzed in order to identify:
Resources?
                               ·Course development resources
                               ·Quantity of those resources
                               ·When the resource is needed to meet the scheduled training delivery date
                               ·Total cost of resources
                                ·Resource constraints

Who Is Responsible? Managers of the instructional system have the overall responsibility for identifying and securing the
                          needed resources. There are many training and support organizations involved in analyzing,
                          identifying, and providing resources for instructional systems. For example, resource management,
                          support services, and contractors are responsible for analyzing and identifying the resources they may
                          need to meet their responsibilities for designing, developing, implementing, supporting, operating,
                          and maintaining the instructional system.

Scope of Resource         The scope of resource analysis includes both long-range and day-to-day concerns.
Analysis
AFMAN 36-2234            1 November 1993                                                                                  39



Conducting Resource The resource analysis results in an estimate of resource requirements for the instructional system for
Analysis            both development and operation. One of the simplest ways to conduct the initial resource analysis is
                          to look at each task and ask a series of questions to estimate what resources may be needed. Sample
                          resource categories and questions are provided below.

    Resource                           Questions
    Equipment                          ·What types of equipment may be needed (training, support, test)?
                                       ·Will training equipment need to be developed?
                                       ·Is the equipment classified? Will it require TEMPEST/COMSEC requirements?
                                       ·What are the specific equipment requirements (computers, maintenance stands,
                                       multimeters, etc.)
                                       ·How will the equipment be used in the course?
                                       ·What quantities will be required?
                                       ·What is the lead time for equipment and parts?
                                       ·Will safes be required to store classified documents?
                                       ·What is the life cycle of the equipment?
                                       ·If faced with an equipment constraint, can alternative equipment be used? If so, what
                                       equipment?
    Facilities                         ·What type of facilities will be required (classroom, laboratory)?
                                       ·Will a vault be required for storing classified material?
                                       ·Will the vault require certification by an outside agency?
                                       ·Will it be necessary to have secure classrooms?
                                       ·How much space will be required?
                                       ·Are facilities available?
                                       ·If facilities are available, will they require modification?
                                       ·Are there special environmental requirements?
                                       ·Are there maintenance and repair facilities available and are they adequate?
    Funds                              ·What will the initial personnel, equipment, and facilities cost?
                                       ·What are the recurring costs associated with the system?
    Human Resources                    ·How many instructional developers, computer programmers, video production
                                       personnel, etc., will be required to meet the training delivery date?
                                       ·Will instructors be needed? If so, how many?
                                       ·What are the student load/throughput requirements?
    Time                               ·What is the scheduled delivery date?
                                       ·How much time will be required to develop the instruction?
                                       ·Are there any equipment lead time requirements?
                                       ·If facilities need to be constructed or modified, how
                                       long will it take?
                                       ·What is the estimated module or course length?
                                       ·How much time will be required to add instructors?
.                          Finding answers to these and other questions should help you
                           estimate the resource requirements for the instructional system

Resource                  During the instructional development process you may encounter some type of resource constraint. In
Alternatives              order to deliver an effective, cost-efficient instructional system on time you may find the needed
                          resources or a suitable alternative. The following table provides several alternatives to consider.
40                                                                              36-2234        1 November 1993



                                 Constraint                      Alternatives
                                                                 ·Borrow or share equipment belonging to other school
                                                                 organizations or MAJCOMs.
                                                                 ·Use prototype equipment.
                                                                 ·Use trainers or simulators rather than the actual
                                                                 equipment.
                                                                 ·Increase group size on the equipment.
                                                                 ·Operate multiple shifts.
                                                                 ·Increase class intervals.
                                 Facilities                 •Borrow or share equipment belonging to other school
                                                                 organizations or MAJCOMs.
                                                            Use temporary facilities.
                                                                   ·Use MAJCOM or other school          organization
                                                                 facilities.
                                                                   ·Operate multiple shifts.
                                                                   ·Decrease group size.
                                                                   ·Increase class intervals.
                                 Funding                           ·Reduce the resource requirements.
                                                                 ·Seek alternative funding sources.
                                 Human Resources                   ·Reduce the number of graduates produced.
                                                                 ·Borrow instructional developers and instructors from
                                                                 other training organizations or MAJCOMs.
                                                                 ·Reduce multiple instructor requirements.
                                 Time                         ·Borrow additional personnel in order to complete
                                                                 instructional development more quickly.
                                                            ·Reduce course length.
                                                            ·Select alternative methods or media.


Updating Resource   In the initial planning stages of the ISD project you may have been able to identify some of the
Requirements        resources that were required for the instructional system, and during resource analysis you were able
                    to identify or estimate most of the resources required. However, it is unlikely that you can completely
                    and accurately identify everything you may need. Therefore, as the instructional development process
                    continues there may be a continuing need to update the resource requirements to ensure that adequate
                    resources are available.

                                               Section E
                                        Target Audience Analysis

Introduction        The learning analysis identified the skills, knowledge, and attitudes the students needed to have
                    before starting the course. You need to conduct a target audience analysis to determine student
                    characteristics before you start designing the instructional system.

What It Is          Target audience analysis is the process of determining the entry-level skills or behaviors that students
                    should have prior to entering a course of instruction. Entry-level skills or behaviors are determined
                    during task analysis. This analysis also identifies the general characteristics they should have such as
                    reading grade level, physical strength, attitude, and previous experience. This information facilitates
                    instructional design considerations such as instructional content, level of content, motivational needs,
                    and instructional methods.
AFMAN 36-2234       1 November 1993                                                                                   41


Why Analyze?         Conducting an analysis of the target audience allows the designer to base the instructional system on
                     the skills, knowledge, and attitudes of the target audience. This reduces the likelihood that the
                     instruction will be inadequate. For example:

                     You design a unit of instruction based on the assumption that the students know basic algebra.
                     However, when the students arrive, you quickly learn that they do not know basic algebra; therefore,
                     the instruction is probably inadequate.

Goals of Target      Target audience analysis produces various data depending on the nature and scope of the analysis.
Audience Analysis    Examples of the data produced are:

                         ·    Range of aptitudes
                         ·    Previous background and experiences
                         ·    Previous education
                         ·    Interests
                         ·    Size of target audience
                         ·    Demographics
                         ·    Computer literacy


Goals of Target      The goal of target audience analysis is to develop a complete and accurate description of individuals
Audience Analysis    in the target group.


Use of the           The data produced during analysis of the target audience is used to determine:
Data
                         ·    Course content
                         ·    Media
                         ·    Delivery methods
                         ·    Course length
                         ·    Equipment needs

                                              Section F
                                      ISD Evaluation Plan Update
Introduction         One of the key activities in planning was the development of the ISD evaluation plan. The
                     plan ensures that the principles and concepts of the Quality Air Force (QAF) are carried out in
                     the process and products of each ISD phase. Thus, this plan becomes the benchmark for
                     evaluating the instructional system. The evaluation plan is updated at the end of the analysis phase
                      as applicable. Since this plan was developed during initial project planning you may need to
                     update the plan periodically.
42                                                                                     36-2234        1 November 1993


Assessing Quality         ISD is a quality management process. In the analysis phase, there are different ways to assess
                          quality. It is possible for ISD projects to have different quality indicators depending on the nature of
                          the project itself. One of the easiest and simplest ways to assess the quality of the analysis phase is to
                          develop a job aid using questions that are focused on quality improvement issues. Some examples of
                          questions that would be appropriate for a job aid on the analysis phase of ISD are:

                              ·Does the evaluation plan address quality of both the analysis process and products?

                              ·Is the evaluation plan for the analysis phase both effective and cost-efficient?

                              ·Are the metrics or standards for the analysis process and products realistic and adequate? If not,
                                  what should be changed to ensure that the standards are both realistic and adequate?

                              ·Can the analysis process be improved? If so, how?

                              ·Do the products of the analysis phase provide adequate and reliable data for analysis?

                              ·Does the analysis phase result in sufficient data to design the instructional system?


Why Update the            Each ISD evaluation plan should be different. It would be difficult to develop an evaluation plan that
Plan?                     is "on target" throughout the entire life cycle of the instructional system. Therefore, when the
                          analysis phase is completed, you may need to update the plan to reflect the results of the evaluation
                          activities. An updated plan should ensure that you have the most current and accurate evaluation
                          information as you enter the design phase of ISD.

Who Is Responsible? The manager of the instructional system has the overall responsibility for updating the ISD evaluation
                          plan at the end of each phase of the process.


What Should Be            Updating the ISD evaluation plan may include, but is not limited to:
Updated?
                              ·    Adding or deleting information.
                              ·    Revising evaluation schedules.
                              ·    Documenting results of analysis phase process and products evaluation.
                              ·    Adding additional analysis products for evaluation.
                              ·    Providing rationale for changes made to the plan.


Tracing the Quality       The quality of the analysis process and the resulting products is very important to the instructional
Process                   development process. Therefore, the products of the analysis phase should be evaluated to ensure that
                          they meet the original intent of the program. The plan traces the quality process throughout
                          instructional development.

                                                  Section G
                                          ISD Management Plan Update

Introduction              During your initial planning of the ISD project, the managers developed an ISD management plan to
                          serve as a roadmap to manage the instructional development process and the instructional system. As
                          you complete the analysis phase of the ISD project, you may have gathered additional and better
                          information on which to base your management decisions, so the management plan may need to be
                          updated.
AFMAN 36-2234      1 November 1993                                                                                  43


When Should the     Since the management plan is a "tool" for managing the instructional development process and the
Plan Be Updated?    instructional system, update it at the end of each phase of instructional development, or when any
                    significant change occurs that impacts planning.

Who Is              The manager of the instructional system is responsible for updating the plan at the end of each phase
Responsible?        of ISD or after any significant change has occurred that impacts the current planning.


What Should Be      Update the plan to include the latest information, such as:
Updated?
                        · New or revised milestones
                        · Refinements to project definition
                        · Changes in project constraints
                        · Revisions to support requirements
                        · Identification of new taskings
                        · New information resulting from analysis that impacts project management
                        ·Other pertinent areas
44                                                                                   36-2234        1 November 1993


                                                        Chapter 5
                                                        DESIGN

                                                         Overview

Introduction              At this point in the process, you have completed the required analyses and updated the evaluation and
                          management plans. You are now ready to enter the design phase of ISD. In this phase the
                          instructional design is determined. This should play a key role in the effectiveness and efficiency of
                          the instructional system. A continuing effort in the design phase is quality of the design process and
                          products, with an emphasis on improvements wherever possible.

Where Are You in theAn ISD model, with the design phase highlighted, is provided in Figure 6 in order for you to better
Process?            visualize where you are in the process.




Objectives                The objectives of this chapter are to:

                              ·Discuss elements of instructional design.
                              ·Explain the process of designing instruction.
                              ·Describe planning activities in the design phase.
                              ·Explain the QI process in the design phase.



                                                      Section A
                                                  Develop Objectives
Introduction              The first activity in the design phase is to develop objectives for the tasks that were identified as
                          requiring instruction in the analysis phase. During learning analysis, you categorize tasks into types
                          of learning outcomes. When you develop objectives, it is important that they are consistent with the
                          instructional need as presented in the overall system concept.

What It Is                An objective is a precise statement of the learned capability— skills, knowledge or attitudes (SKA)— a
                          student is expected to be able to demonstrate, the condition under which the SKA is to be exhibited,
                          and the minimum standard of acceptable performance.
AFMAN 36-2234           1 November 1993                                                                                          45



Purpose                   The purpose of an objective is to:

                              ·Serve as the foundation for instructional design.
                              ·Provide the basics for instructional strategy decisions.
                              ·Establish clear, concise student goals.
                              ·Determine content of the instructional system.
                              ·Serve as a basis for criterion tests.


Parts of an Objective Most objectives are made up of three parts:
                              ·Learned capability (behavior)
                              ·Condition
                              ·Standard

                          The three parts are discussed in detail later in this section under "Characteristics of Objectives."


Levels of Objectives Learning hierarchies use various terms to describe levels of objectives. The most common terms used
                          to distinguish the levels are:

                              ·Top level
                                  ··Terminal
                                  ··Primary

                              ·Lower levels
                                  ··Enabling
                                  ··Secondary
                                  ··Supporting
                                  ··Subordinate
                          ··Developmental
                                  The purpose of different levels of objectives is to show the hierarchical relationship of the
                                       objectives, such as which objectives are prerequisite to another objective.

Additional                For additional information on objectives, see:
Information
                              ·AFMAN 36-2236, Handbook for Air Force Instructors.
                              ·Davies, I. K. (1976). Objectives in Curriculum Design. London: McGraw Hill.
                              ·Kibler, R. J. (1981). Objectives for Instruction. Boston: Allyn and Bacon.
                              ·Mager, R. F. (1962). Preparing Instructional Objectives (2nd Ed.). Belmont, California: Fearon
                                  Publishers.


Introduction              Objectives need to be worded carefully so that all readers or listeners have the same understanding.
                          To ensure this clarity, the instructional developer should be thoroughly familiar with all parts of the
                          objective.

                                                               Learned Capability

Introduction              The capability part of an objective states what the students will be required to do to demonstrate that
                          they have learned a specific skill, knowledge, or attitude. Clearly state the capability so that
                          everyone— instructional developer, instructor, and student— can understand it.
46                                                                    AFMAN 36-2234               1 November 1993



What It Is                  A capability is defined as a skill, knowledge, or attitude that is observable and measurable. Learned
                            capability is closely associated with what is normally referred to as the behavioral part of an objective.
                            However, using verbs that are related to specific learned capability helps clear up some of the
                            ambiguity arising about what learning outcome the demonstrated behavior actually represents.
                            Clearly indicating the type of learned capability to be demonstrated helps clarify the intended learning
                            outcome; thus, the behavior is more clearly communicated in the objective.

Things To                   When writing the capability part of an objective, use descriptive statements that are:
Consider
                                ·Observable
                                ·Measurable
                                ·Verifiable
                                ·Reliable

                            Use the job behavior in the objective, when possible. Do not use statements that are so general that
                            they don't describe the observable behavior, such as:

                                ·Know engineering.
                                ·Learn about systems.
                                ·Understand basic circuits.


Examples of                 Several examples of learned capability statements are provided below.
Learned
Capability
Statements
                          Examples of Learned Capability Statements
                          "... the formula, compute the exact surface of the sphere ..."
  "... checklist, perform a preflight on the T-38 aircraft ..."
  "... reference, list the nine events of learning ..."


                                                           Condition
Introduction                The second characteristic or part of an objective to be discussed is condition. A thorough
                            understanding of the conditions under which a task may be performed and a clear statement of those
                            conditions should make a more effective objective. The actual conditions under which the job will be
                            performed should be used in the objective, if possible.

What It Is                  A condition(s) identifies the situation under which a task is to be per formed. A properly prepared
                            objective clearly states the limits and/or conditions of student performance, such as:

                                ·Does the student understand how to use technical orders?
                                ·Is the student allowed to use a checklist?
                                ·What tools/test equipment should a student be allowed to use?
                                ·May students use notes they have taken during instruction?
                                ·May students ask questions?
AFMAN 36-2234          1 November 1993                                                                 47


Things To                There are things to consider when determining conditions.
Consider
                             ·Specify the objects, events, human behavior, words, or symbols which should be presented to the
                                 students.
                             ·State the situation under which the task is performed.


Examples             Several examples of condition statements are provided below.
of
Condition Statements
                                   Examples of Condition Statements
                                   "Given the diameter of a sphere and the formula, compute the ..."
                                   "Using the preflight checklist, perform a ..."
                                   "Without reference, list the nine events ..."
                         The condition statements can be derived from the task analysis work sheet or equivalent.


                                                        Standard

Introduction             The standard of performance is the final part of the objective. The student's performance results in
                         an output, the quantity or quality of which is compared to the standard of performance. The standard
                         of performance specified in an objective should be the same as the standard specified for on-the-job
                         performance, unless there is a valid reason for setting a higher standard.

What It Is               A standard defines the criteria for acceptable performance by the student. It is stated in such terms as
                         completeness, accuracy requirements, time constraints, performance rates, or qualitative
                         requirements. It identifies the measure of proficiency the students should achieve when they perform
                         the behavior under the specified conditions.

Determining              When developing the task list, you probably found that some of the tasks did not have the standard of
the                      performance specified. The standard for many tasks is go/no go. If no standard is specified for the
                         performance, you may be required to set the standard in the objective based on other sources such as
Standard                 experience, similar tasks, or expert opinions. Once the standard of performance has been determined
                         for these tasks, you should verify it against on-the-job performance standards.

Things To                When establishing standards, consider that:
Consider
                             ·Without a standard you cannot determine when the student achieves the objective.
                             ·The criteria for a good standard are completeness and accuracy.
                             ·Standards can be classified in one or more of six types, as shown below.

                                Describe Standards By               Example
                                Referring to standard operating     "... will comply with Air Force directives     and local
                                    procedure                            regulations."
                                Implying standard of "Without       "... state the five principles of CPR (cardiopulmonary
                                Error"                              resuscitation)."
                                Specifying minimum acceptable       "... compute the answer to the nearest tenth."
                                level of performance
                                Specifying time requirements        "... minimum speed of 35 words per minute."
                                Specifying rate of production       "... at a minimum of 20 units per day."
                                Specifying qualitative              "... to idle smoothly..."
                                requirements
48                                                                   AFMAN 36-2234              1 November 1993



Examples of                Some examples of standards that may be used in objectives are given below.
Standards
                         Examples of Standards
                         "... compute the exact surface of a sphere." (without error implied)
 "... owed from last quarter to the nearest dollar."
 "... measure the resistance of series circuit with no more than 5% error."
 "... principle of leadership as defined in Air Force Leadership Pamphlet."
 "... field-strip and reassemble an M-16 rifle within 15 minutes.'


                                     Guidelines for Developing Objectives
Introduction               Once you understand the components of an objective, you are ready to start formulating objectives from
                           the list of task statements, skills, and knowledge behaviors developed during task/learning analysis.
                           Using the information on the task list, what you have learned about objectives to this point, and a few
                           guidelines, you should be able to develop effective objectives.

Guidelines                       Several guidelines for developing objectives are provided below.
for Developing
Objectives
                                 Type                               Guidelines
                                    General                         · Use task descriptions developed during the analysis
                                                                        phase.
                                                                    ·Analyze each task or knowledge item on the task list to
                                                                        determine objectives that are required for each item.
                                                                    ·Document each objective on a worksheet.
                                                                    ·Use learning analysis results to assign skills and knowledge
                                                                        to support each objective and subobjective.
                                                                    ·Document results on worksheet.
                                                                    · Ensure that capability statement is the same as that
                                                                        required on the job, if possi ble.
                                                                    ·State the capability in terms that everyone under stands.
                                                                    ·Use an active verb to describe the desired capability.
                                                                    ·Don't use ambiguous verbs such as "know," "understand,"
                                                                        etc.
                                                                    ·Use capability statements that are:
                                                                        ··Observable
                                                                        ··Measurable
                                                                        ··Reliable
                                                                        ··Verifiable
                                                                    · Select conditions that match job condi tions as closely as
                                                                        possible.
                                                                    ·Ensure that conditions are realistic.
                                                                    · Use a standard that meets job performance
                                                                        requirements, if possible.
                                                                    ·Use a standard that is clear and understood by everyone.
                                                                    ·Use a standard that accurately measures student
                                                                        achievement of the objective.
                                                                    ·Ensure that the standard is complete.
                                                                    ·Ensure that the standard is accurate.


                                              Writing Objectives for Types of Learning
AFMAN 36-2234             1 November 1993                                                                 49



Introduction                Types of learning outcomes were described in Chapter 2. The section on learning analysis
                            discussed tying tasks to types of learning outcomes. In writing objectives to specify these
                            outcomes, verbs may be used to classify each type of learning outcome. By including one of these
                            verbs in the objective, the intended capability is more clearly communicated and the conditions of
                            learning appropriate to that type of learning outcome are more readily applied. The learning
                            capability verbs are shown in the table below.

                                       Capability                                   Capability Verb
                                       Intellectual Skill

                                           ·Discrimination                          Discriminates
                                           ·Concrete Concept                        Identifies

                                           ·Defined Concept                         Classifies
                                           ·Rule                                    Demonstrates

                                           ·Higher-Order Rule                       Generates
                                               (Problem Solving)
                                       Cognitive Strategy                           Adopts
                                       Verbal Information                           States
                                       Motor Skill                                  Executes
                                       Attitude                                     Chooses


                                                Hierarchy of Objectives
Introduction       During task analysis, you identified the steps or procedures that make up a task. In order to properly
                   teach these steps or procedures, additional objectives had to be developed. These different levels of
                   objectives, which go by various names, can be structured into an objective map that depicts the
                   relationship of the objectives and their sequence in the course. This map is sometimes called an objective
                   hierarchy.


Purpose                     The purpose of the hierarchy is to design the instructional system and sequence learning.


Sequencing of          A curriculum or course requires decisions about
Objectives             the sequencing of objectives. The goal of good
                       instructional design is to establish sequences
                       within courses that promote effective learning.
                       The sequence and lessons within a course should
                       be based on the prerequisite relationship among
                       the objectives. The most obvious sequence
                       follows the order from simple to complex or from
                       general to specific. The table below summarizes
                       the major considerations regarding sequential
                       arrangement within a topic for each type of
                       learning outcome.
                                                 Major Principles of                                   Related Sequence Factors
                                                 Sequencing
 Intellectual Skills      Presentation of learning situation for each new skill   Verbal information may be recalled or newly
                          should be preceded by prior mastery of subordinate      presented to provide elaboration of each skill and
                          skills.                                                 conditions of its use.
50                                                                    AFMAN 36-2234                1 November 1993


  Cognitive Strategies  Learning and problem-solving situations should         Verbal information relevant to the new learning
                        involve recall of previously acquired relevant         should be previously learned or presented in
                        intellectual skills.                                   instructions.
  Verbal Information    For major subtopics, order of presentation is not      Prior learning of necessary intellectual skills
                        important. New facts should be preceded by             involved in reading, listening, etc., is usually
                        meaningful context.                                    assumed.
 Attitudes            Establishment of respect for source is an initial step. Verbal information relevant to choices should be
                      Choice situations should be preceded by mastery of previously learned or presented in instructions.
                      any intellectual skills involved.
 Motor Skills         Provide intensive practice on part skills of critical   First of all, learn the executive subroutine (rule).
                      importance and practice on total skill.
Source: Gagné, M. R., Briggs, L. J., and Wager, W. W. (1992). Principles of Instructional Design (4th Ed.). New York:
Harcourt Brace Jovanovich College Publishers.

Levels of Objectives          Objectives can be categorized into two levels, as shown below.
                                   Level                            Description                                         Other Names
                                   Terminal                         An objective the learners                           ·Primary
                                                                    will be expected to                                 ·Main
                                                                    accomplish when they have                           ·End
                                                                    completed the in struction.
                                                                    Made up of subordinate
                                                                    objectives.
                                   Enabling                         An objective that should be                         ·Secondary
                                                                    attained in order to accom-                         ·Subordinate
                                                                    plish a terminal objec tive.                        ·Supporting
                                                                                                                        ·Develop-
                                                                                                                            mental


Progression from            The figure below shows the progression from simple individual objectives to the more complex end goal
Simple to Complex           or terminal objective. The integration of multiple objectives, or enterprises, are developed along this
                            simple to complex continuum. The highest plateau on this continuum is the metaskill. At this point all
                            of the individual skills, knowledge, attitudes and cognitive, perceptual, and motor processes required for
                            performance are integrated.
AFMAN 36-2234           1 November 1993                                                               51




Example of Objective Figure 8 is an example of an objective hierarchy.
Hierarchy




                           Prioritizing, Clustering, and Sequencing Objectives

Introduction             Once the terminal and enabling objectives have been developed, it is necessary to prioritize, cluster, and
                         sequence them into units of instruction. A unit of instruction may be defined as any module, block, or
                         lesson. Effectiveness and efficiency of the instructional system should depend, in part, on how well the
                         units of instruction are structured.
52                                                                         AFMAN 36-2234               1 November 1993


Prioritize Objectives Prioritizing objectives may not be required in all instructional development projects. However, there may
                           be times when you may be unable to train all of the needed tasks due to some resource constraint.

                           For example:

                           "You need 25 days to cover all objectives to the level specified. However, due to a student workyear
                           constraint, the course can be only 20 days in length."
Guideline                  Have the user prioritize the line items in the training standard. Then the objectives are prioritized to meet
                           the user's need.
When Should                If the instructional developer expects that a resource constraint may prevent you from providing all of the
You Prioritize?            instruction that is required to meet job performance requirements, request that the standard line items be
                           prioritized during meetings such as the Utilization and Training Workshop ( U&TW) or Training
                           Planning Team ( TPT). Another way is to have the users prioritize their requirements during coordination
                           of the standard.
Who Is                     Users are responsible for determining the priority of their needs. Instructional developers or the design
Responsible?               team should advise and make recommendations to the user, as necessary.

Clustering                 Clustering or grouping objectives enables the instructional developer to develop logical and meaningful
Objectives                 instructional units. Without this clustering, it would be impossible to structure an effective and efficient
                           instructional program. The basic guidelines for clustering objectives are explained on the next page.
                                      Guidelines For Clustering Objectives
                                      Cluster objectives that are prerequisites to other objectives.

                                         For example, basic electronic skills and knowledge may be required for many tasks in
                                         a course; therefore, they may be clustered in the same unit and taught in the core area
                                         of the course.
                                      Cluster objectives that are related to the same system or engage the same type of action.

                                         For example, several tasks related to performing a particular maneuver in an aircraft
                                         may be clustered into a single instructional unit.
                                      Cluster objectives with common skills and knowledge.

                                         For example, some maintenance tasks require identical skills and knowl edge across
                                         different systems such as computer maintenance or aircraft refueling.
                                      Cluster objectives with potential for the same instructional method or delivery system.

                                          For example, knowledge objectives utilizing a method such as lecture may be
                                          clustered together. Also, objectives with the same type of learning may be grouped
                                          together to facilitate learning.


Sequencing                Effective and efficient instruction depends on properly sequenced objectives. Sequencing objectives should
Objectives                be accomplished within the unit or module, as well as the course itself. Note that simplifying conditions
                          as a step of sequencing will help ensure that the simplest tasks are taught very well. Two basic guidelines
                          for properly sequencing objectives are provided below.
                      Guidelines For Sequencing Objectives
                      Teach prerequisite skills and knowledge first.

                          For example, students should be taught to solder before they are
                          required to perform tasks requiring that skill.
  AFMAN 36-2234                 1 November 1993                                                                 53


     Follow the fixed sequence or logical order in performing a task.

                                 For example, the step-by-step procedures of performing a
                                 preflight should be taught before the student is taught to taxi the
                                 aircraft.



                                                                Section B
                                                              Develop Tests

  Introduction                    Tests serve many purposes in the Air Force. Tests may have already been used when the target audience
                                  analysis was conducted, or pretests may have been developed as a prerequisite for attending a course. To
                                  ensure that tests adequately measure the objectives they support, the performance required in the test
                                  should match the performance required in the objective. A good way to develop tests that measure the
                                  objectives is to prepare them immediately after the objective is written.

                                  Note: Test item format, and the actual wording of objectives for that matter, depends on the media having
                                  been selected by prior analysis or directed by content. Otherwise, rewrites may become a major problem.


  Purpose                         The primary purpose of testing is to assess the student's attainment of the behavior specified in the
                                  objective.

                                  Tests also serve several secondary purposes such as to:

                                      ·Identify problems or weaknesses in the instruction.
                                      ·Indicate whether a class is performing up to standards on specific objectives.
                                      ·Indicate instructor proficiency.

                             Type of                                 Best Method                                  Activities That Indicate
                            Learning                                  of Testing                                      Achievement of
                            Outcome                                                                                      Objectives
                       Intellectual
                       Skills:                                  Multiple choice and                           Detect similarities or
                       ·Discriminations                         true/false                                    differences

                                                                Constructed response                          Recognize examples or non-
                       ·Concepts                                (labeling, sorting,                           examples
                                                                matching)

                                                               Performance of                                 Apply rule, principle or
                       ·Rules                                  integrated tasks or                            procedure
                                                               constructed response
                                                               (short answer)
Verbal Information                        Constructed response (fill in the blank,       Recall information
                                          essay questions)
Cognitive Strategies                      Student explains process to examiner           Self-report or audit trail of work done
Motor Skills                              Performance test                               Perform smooth, coordinated action
Attitudes                                 Observe student in different situations        Observe actual situated behavior


  Types of Tests                  The basic types of tests used in the Air Force are described below.
                                Type of Test      Purpose of Test
54                                                                         AFMAN 36-2234               1 November 1993


                                Criterion · Used to measure the student's attainment of the objective.
                                          ·Used to measure the effectiveness of the instruction.
                                 Pretest · Used to measure the student's ability to attain each
                                             objective.
                                          ·Used after the instructional system becomes operational to
                                             determine how much instruction individual students need.

                                            Diagnostic
                                            ·Used to determine attainment of supporting skills and
                                                knowledge necessary to perform the terminal objective.
                                            ·Used during validation to predict success, to identify and
                                                correct weaknesses in the instruction.
                                            Survey
                                            ·Used to determine what prospective students already know
                                                and can do before receiving instruction.
                                            ·Used during development of instruction to gather data for
                                                    design of instruction.
                           These tests are described in more detail below
Criterion Test             Criterion tests are prepared and used to evaluate the students' attainment of the criterion objective and to
                           measure the effectiveness of the instructional system. Each criterion test is based solely on the
                           requirements specified in the objective which it is intended to measure. The test should measure each
                           objective within the parameters established by the objective. To show that they have attained the
                           objective, the students must meet or exceed the standard specified in the objective.


Pretest                    Pretests are designed to measure the students' ability to achieve each objective. Generally, a pretest is used
                           after the instructional system is in operation. When some form of planned pacing is used to accommodate
                           the varying needs of students, the pretest is administered to each student just prior to the instructional
                           activity to determine the extent of existing skills and knowledge. How well the student performs on the
                           pretest determines what and how much instruction is then required.

Diagnostic Test            As indicated, the criterion test is used to enable the instructional system designers to evaluate the students'
                           attainment of the objective and to help validate the instructional system. Test items should also be
                           prepared to determine attainment of the supporting skills and knowledge which contribute to the ability to
                           perform the criterion objective. This is the purpose of diagnostic testing.

                           During validation, the instructional system designers can effectively use diagnostic test items to predict
                           success, to identify problem areas, and to adjust instruction for individual differences. If testing is limited
                           to criterion tests only, it might be difficult to determine specifically what students have not learned.

Survey Test                Survey tests are designed to determine what prospective students already know and can do before
                           receiving instruction. The survey test is administered while the instructional system is being developed
                           and provides important design data. The results of the survey test will aid the instructional system
                           designers in deciding which objectives require instruction and how much, and which can be deleted
                           because the target audience has already learned them.

Test Construction for The outcomes of planned instruction consist of student performances which show that various kinds of
Types of Learning     capabilities have been acquired. The types of learning have been identified and discussed: intellectual
                           skills, cognitive strategies, verbal information, motor skills, and attitudes. There is a need to assess
                           student performance to determine whether the newly designed instruction has met its design objectives.
                           Assessment may also be done to learn whether each student has achieved the set of capabilities defined by
                           the instructional objectives. The table below lists the types of learning outcomes and describes the best
                           method of testing and the activities that indicate achievement of objectives.
 AFMAN 36-2234                1 November 1993                                                                                           55


      Type of Learning                                        Best Method                                                       Activities That Indicate
      Outcome                                                 of Testing                                                        Achievement of
                                                                                                                                Objectives
ectual Skills:
                                                                                                                                Detect similarities or differences
  ·Discriminations                                            Multiple choice and true/false
                                                                                                                                Recognize examples or non-examples
                                                              Constructed response (labeling, sorting,
  ·Concepts                                                   matching)                                                         Apply rule, principle or procedure

                                                              Performance of integrated tasks or
                                                              constructed response (short answer)
  ·Rules
      Verbal Information                                      Constructed response (fill in the blank,                          Recall information
                                                              essay questions)
      Cognitive Strategies                                    Student explains process to examiner                              Self-report or audit trail of work done
      Motor Skills                                            Performance test                                                  Perform smooth, coordinated
                                                                                                                                action
      Attitudes                                               Observe student in different situations                           Observe actual situated behavior

                                 There are several characteristics to be considered when developing tests. These characteristics ensure that the tests measure what is
 Characteristics                 intended each time they are administered. The characteristics are shown in the following table.
 of Tests
      Characteristic                                   Definition
                   Validity                                                               Content
                                                            ·Degree to which the test measures what it is intended to measure
                                                                                         Predictive
                                                                      ·Degree to which the test predicts performance
                     Reliability                       ·Degree to which the test yields the same results consistently
                                                       Test-Retest
                                                       ·Consistency across two administrations to the same students
                                                       Split-halves
                                                       ·Consistency across two forms of the same test
                     Usability                         · Tests that are easy to administer, score, and interpret

                                 Most Air Force tests can be classified into two main groups: performance and predictive tests. A common question is: When should
 Assessment Method               designers use performance tests and when should they use paper-pencil tests? These are the wrong categories for comparison. The
                                 comparison should really be between performance tests and predictive tests.

                                 A performance test is one in which the student actually performs the skill required by the terminal objective. If the objective of the
 Performance Test                lesson is to recall information, then a test where the student has to recall the information by writing it on a piece of paper is a
                                 performance test. Many concept and rule-using-type performances are tested with paper-and-pencil tests. For instance, many problem-
                                 solving skills involving the use of scientific principles can be observed from written performance tests.

                                 Many types of tasks, especially equipment operation tasks, involve many different capabilities that have to be performed in an integrated
                                 manner. For example, the task of bleeding a hydraulic brake system involves recall of a procedure (information learning), physical
                                 performance of the steps (motor performance), recognition of the parts and tools (concepts), observation of the brake fluid conditions in
                                 the system (rule using), and attitudes (cleanliness and safety). In these types of tasks, performance cannot be measured by a paper-and-
                                 pencil test. A performance test would require a real or operational mock-up of a brake system. Because performance tests require the
                                 student to demonstrate mastery of the task previously learned, they are said to have content validity. Content validity is based on
                                 objective-to-test correlation. For a test to be considered as content-valid, there must be a high objective-to-test correlation. This is true in
                                 both performance and predictive testing.
56                                                                AFMAN 36-2234              1 November 1993


Predictive Test    Performance tests of integrated tasks are generally time-consuming because they often have to be
                   conducted one-on-one with real equipment or simulators. If the actual behavior cannot be tested in a
                   performance test (because it is too costly, dangerous or impractical), the next best option is to test the
                   behaviors that enable performance of the desired skill, and from that information make a prediction as to
                   whether the student would be able to perform the task. For example, if a student could write the steps
                   for bleeding a brake system, there is a better probability that the student could actually perform the task
                   than someone who didn't know the steps. Tests that do not test the actual behavior, but test component
                   or related behaviors, are valid to the extent that they predict student performance on the actual task.

Types of Tests     In the past, most predictive tests were written paper-and-pencil type tests, because they are easy to
                   produce, administer and score. The most common types of written test questions are essay, short answer,
                   fill-in-the-blank, labeling, multiple-choice, matching, and true-false. Today's media provide other
                   testing options. Computers provide different types of input systems that can have a high degree of
                    fidelity with real-world tasks. Even a simple input device such as a joystick or a mouse allows for
                   identification by pointing with a cursor. More elaborate devices such as magnetic field detectors,
                    infrared detectors, etc., allow the computer to detect even more complex behavior.

                   How does an instructional designer decide what type of test to construct or what type of item to use? The
                   best type of test is one which gives the decision maker the best information regarding the student's
                   mastery of the objective. Different types of test items have advantages and disadvantages with regard to
                   good test construction. These advantages and disadvantages have to be considered in terms of validity
                    and reliability of the test.

Comparison of      Performance and predictive tests are compared below.
Performance and
Predictive Tests
AFMAN 36-2234               1 November 1993                                                                57



    Predictive Test Item                                                         Performance Test Item
    Requires students to demonstrate knowledge by responding to various ·        Requires students to accomplish a job-like task
    types of written questions.                                                  under controlled conditions.

·Emphasizes verbal or symbolic aspects.                                      ·Emphasizes nonverbal aspects.

·May require students to find, read, and use technical materials.
                                                                          ·May require students to find, read, and use certain
                                                                              technical material (job aids, for example).
·Items are knowledge the student should learn to perform or make decisions
    on the job.                                                           ·Items are skills that students should perform, or the
                                                                              decisions they may make on the job.
·Items are normally independent questions and are not dependent on
    sequence. However, in some cases such as scenario-based testing, it ·Items are dependent on sequence in which they are
    may be necessary to develop test items that are dependent on sequence.    presented.
                                                                          ·Errors early in the sequence may affect final outcome
·Errors on one item should not affect performance on another item.            of the task.




Test Construction            ·What to measure. Analysis of objectives should identify what should be
Factors                       measured. To determine what to measure, list the tasks to be performed or
                              objective statements to be covered by the test. One or more test items may be
                              needed to adequately measure each objective. Tests should measure application
                              of principles, knowledge of factual information, ability to perform task, and
                              transfer of knowledge and skills to solve similar problems.

                               · Testing level. The level of testing (know, comprehend, etc.) should correlate
                                 with the stated level of learning for that portion of the instruction being
                                 tested no higher and no lower.
                               · Test length. Adequate coverage of the objective is the major factor in
                                 determining the length of test that is required. Longer tests are normally more
                                 reliable since they usually cover the material better.

                               · Selection and arrangement of test items. Select test items that cover the most
                                 essential and significant portions of the material. Test items selected should be
                                 clear, concise and well-written to minimize misunderstandings. Items of the
                                 same type should be grouped together in a test, if possible. Individual test
                                 items should also be arranged in approximate order of difficulty, which allows
                                 the students to progress as far as they can without spending excessive time on
                                 difficult items at the first part of the test.
58                                                               AFMAN 36-2234             1 November 1993


Test Review and   Review and analysis of tests or measurement devices during the summative evaluation process ensures
Analysis During   that they measure what they are supposed to measure. Normally, data from the first several
                  administrations (classes) of the test will provide sufficient data to complete the summative evaluation
Summative         process. However, if the development team is not confident that adequate data has been collected, the
Evaluation        summative evaluation process can be extended until the necessary data has been collected.

                  During the summative evaluation period, it is suggested that data be collected and analyzed after each
                  administration of the test. Analysis of the data should identify any potential problems with the testing
                  instrument. For example, if a test item is a high-miss (usually 50 percent or more) or students fail to
                  perform the specified task within the prescribed time limit, the item should be analyzed to determine if
                  there is a problem. Analysis may identify a problem with the test item or it could be that the instruction
                  being provided does not adequately cover the objective that the test item is to measure. Regardless of the
                  source of the problem, action should be taken to correct any identified problem to ensure quality of the
                  process and products of the summative evaluation process.

Test Review and   Once the summative evaluation process has been completed, which includes test validation, the
Analysis During   instructional system is placed into an operational status. Once the system is operating under normal
                  conditions, curriculum developers or the instructional staff should periodically review and analyze the
Operational       composite data resulting from all administrations of the tests since the instructional system became
Evaluation        operational or the last time the data was analyzed. It is suggested that the frequency of the test data
                  review cycle be based on the number of times the test is administered (student flow). However, if
                   student flow through a course is low, it is suggested that the composite test data be reviewed at least
                   once each year. The number of versions of a particular test will impact how often data needs to be
                  analyzed. The review and analysis during this period is part of the operational evaluation process which
                  ensures the quality of the instructional system under normal operating conditions.

                  As with test item analysis during the summative evaluation process, all test items should be analyzed to
                  determine if there are problems with any of the test items. For example, are there any identifiable trends
                  such as low-miss or high-miss items? Are most students having difficulty completing one particular
                  task? Any item identified as a potential problem should be analyzed and the necessary corrective action
                  taken.



                                           Section C
                                    Review Existing Materials

Introduction      After developing the objectives and tests, you should determine if materials already exist that may
                  support the objectives. It is possible that some of the material found during the review may not totally
                  satisfy the need. In this case, don't hesitate to modify the materials. Even the use of some portions of
                  existing materials may be economically advantageous.

Why Review        Several benefits to be gained from using existing material are:
Existing
                      ·Time - Developing instructional materials is time-consuming. Therefore, using existing materials
Materials?                should save time.
                      · Personnel - Using existing materials saves duty hours that can be spent developing other
                           portions of the instruction.
                      ·Material - Valuable materials may be saved.
                       ·Money - Time, human resources, and materials cost money.
AFMAN 36-2234 1 November 1993                                                                                             33
Where Can        Materials exist to cover almost every subject. Several sources of existing materials are:
You Find
                    ·DoD
Materials?          ·Other services
                             ·Other federal agencies
                             ·Industry/commercial organizations
                             ·Colleges and universities


Types of                  Existing materials can be found in many different forms, for example:
Existing
                              ·Textbooks/publications/technical orders/handbooks
Material                      ·Slides/video
                              ·Audio cassettes
                              ·Computer-based (ICW, CAI)
                              ·Job aids
                          ·Training aids

 How To                   In order to select the appropriate materials, a deliberate and thorough review of existing materials
 Select                   should be conducted. After it has been determined what instructional materials are needed to
                          support the objectives and materials have been gathered for review, the review process is ready to
 Materials                begin. A good way to conduct a review is to use a job aid. The job aid should help standardize the
                          process and allows a comparison between materials under review. Following are examples of job
                          aids for the review of existing materials.

                                               Job Aid For Existing Material Reviews
                                               ·Does the material meet the requirements of the objective(s)?
                                               ·Is the content level of the material appropriate?
                                               ·Is the material accurate?
                                               ·Is the material current?
                                               ·Does the material address motivational factors?
                                               ·Is the material properly sequenced?
                                               ·Does the material provide sufficient guidance?
                                               ·Are sufficient practice exercises provided?
                                               ·Are the measurements adequate?·Is the material proprietary or copyrighted?

                           Other types of job aids or forms can be used to review and select materials. Keep the job aids or
                           forms as simple as possible.
34                                                                             AFMAN 36-2234 1 November 1993


                            Job Aid Material Review Form

                            Evaluator:                                           Date:

                                1. Objective:
                                2. Type of Media:
                                3. Evaluation of Material                        Poor      Good Excellent
                                   Content
                                       ·Accuracy                                 1 2 3 4 5
                                       ·Currency                                 1 2 3 4 5
                                       ·Level                                    1 2 3 4 5
                                   Structure
                                       ·Organization                             1 2 3 4 5
                                       ·Sequence                                 1 2 3 4 5
                                   Suitability
                                       ·Supports Objective                       1 2 3 4 5
                                       ·User Friendly                             1 2 3 4 5
                                       ·Pace                                     1 2 3 4 5
                                       ·Guidance                                 1 2 3 4 5
                                       ·Feedback                                 1 2 3 4 5
                                       ·Motivational                             1 2 3 4 5
                                       ·Measurement                               1 2 3 4 5
                                4. What do I like about the material?
                                5. What do I dislike about the material?
                                6. Can the material be modified to improve its utility? If so, what should be done?




 Finding the                The exact materials needed may or may not exist, or, if they do, may require modification before
 Right Material             they can be used in course development. If this is the case, consider modifying or updating the
                            material, since it is normally more cost-effective and efficient to do so.

                            Modification of existing materials may include:

                                ·Adding new material
                                ·Expanding the existing material
                            ·Deleting material
                                ·Updating material
                                ·Resequencing material


 Copyrighted Material If existing material is copyrighted, you should obtain permission of the publisher before using it.


 Additional                 For additional information on reviewing existing materials, see:
 Information
                            ·Dick, W. and Carey, L. (1990). The Systematic Design of Instruction (3rd Ed). Glenview, Illinois:
                            Harper Collins Publishers.
                            ·Knirk, F. G. and Gustafson, K.L. (1986). Instructional Technology: A Systematic Approach to
                            Education. New York: Holt, Rinehart, and Winston.



                                                        Section D
AFMAN 36-2234 1 November 1993                                                                                                                  35
                                                 Design Instructional Plan

 Introduction              Once the objectives and tests have been developed and existing instructional materials have been
                           reviewed for usability, you are ready to start designing instruction. The effectiveness and
                            efficiency of the instructional system may depend, to a large degree, on how well the instruction
                           is designed.

                                             Select Instructional Method
 Introduction              In the design phase, one of the first and most important tasks is that of selecting the instructional
                           method. The method selected may directly impact both the quality of the instructional system and
                           its cost-effectiveness. In order to select the most appropriate method, several key factors should be
                           considered.

 What It Is                Instructional method is the procedure or process used to attain an objective.
                           Examples of instructional methods are:

                                ·Lecture
                                ·Demonstration
                                ·Self-study
                                ·Computer-based training (CBT)
                                ·On-the-job training (OJT)


 Who Is                    The instructional developer has the overall responsibility for selecting the instructional method.
 Responsible?              However, in cases where the design team approach is used, team members play an active, vital role
                           in selecting the most effective, cost-efficient method of instructional delivery.

 Instructional             There are a variety of instructional methods which can be selected. The most common methods
 Methods                   are shown below:


 Method                                                   Definition
          Lecture         A formal or semiformal oral presentation of information by a single individual; facts, concepts, problems, relationships,
                          rules or principles presented orally either directly (as by classroom instructor) or indirectly (as by video).

 P
 R
 E
 S
 E
 N
 T
 A
 T
 I
 O
 N

 M
 E
 T
 H
 O
 D
 S
          Demonstration   Presentation or portrayal of a sequence of events to show a procedure, technique, or operation; frequently combines
                           an oral explanation with the operation or handling of systems equipment or material. May be presented directly (as by a
                          classroom instructor) or indirectly (as by video).
          Exhibit         A visual or print display used to present information; for example, actual equipment, models, mockups, graphic
                          materials, displays, chalkboard, or projected images.
36                                                                                       AFMAN 36-2234 1 November 1993

           Indirect      Verbal interaction among two or more individuals which is heard by the student; may be a dramatization, such as role
           Discourse     playing, or a dialogue between panel members, or a teaching interview (a question and answer session between
                          instructor and visiting "expert").
           Assigned      Printed verbal materials such as books, periodicals, manuals, or handouts. Reading may be course-assigned or self-
           Reading       assigned.
           Teaching      Question and answer session between the instructor and visiting "expert" following a highly structured plan.
           Interview
   I       Questioning   An instructor- and/or courseware-controlled interactive process used to emphasize a point, stimulate thinking, keep
   N                     students alert, check understanding, or review material. Questioning may be direct, as by a classroom instructor, or
 S T                     may be designed into a film or television presentation.
 T E
 U R
 D A
 E C
 N T
 T I
   O
 V N
 E
 R M
 B E
 A T
 L H
   O
   D
   S
           Programmed    An instructor and/or courseware controlled interactive process used to systematically demand a sequence of
           Questioning   appropriate student responses; may be used directly (as by an instructor in a classroom) or indirectly (as by
                          programmed booklets or teaching machines, including computers).
           Student       The provision by which students are given the opportunity to search for information, as by questioning a classroom
           Query         instructor, tutor, coach, or an appropriately programmed computer.
           Seminar       A peer-controlled group interactive process in which task- or objective-related information and experience are
                         evoked from the students. Questions may be used to evoke student contributions, but the seminar is distinguished
                          from questioning.
           Discussion    An instructor-controlled interactive process of sharing information and experiences related to achieving a training
                         objective.
  A        Performance   Student interactions with things, data, or persons, as is necessary to attain training objectives; includes all forms of
 K P                     simulation (for example, games and interaction with hardware simulators) and interaction with actual equipment or
 N P   M                 job materials (for example, forms).
 O L   E                 Performance may be supervised by classroom instructor, tutor, coach, or peer to provide needed feedback.
 W I   T
 L C   H
 E A   O
 D T   D
 G I
 E O
 N
           Case Study    A carefully designed description of a problem situation, written specifically to provoke systematic analysis and
                         discussion.
AFMAN 36-2234 1 November 1993                                                                                               37
 Selection        Several factors, categorized in three major areas, should be considered when selecting the
 Considerations   instructional method. The examples below are not meant to be all-inclusive.

                           Constraints

                             ·Geographical spread of target audience. If the target audience is widely spread, it may not be
                                feasible to bring students to a central location for instruction. If this is the case, classroom
                                instruction may not be the appropriate method. You may want to consider other methods
                                 such as OJT or self-study. Self-study is individual study on the job site or duty location using
                                instructional methods such as career development courses (CDCs) or interactive courseware
                                (ICW). Also, you may want to consider some other form of distance learning such as
                                satellite.

                             ·Availability of students. If there will be an insufficient flow of students due to constraints such
                                 as lack of travel funds, if the number of students to be trained is low, or if workload
                                 requirements will not allow students to be away from the work center for long training
                             periods, it is not likely that formal classroom instruction is appropriate. Again, a better method
                                 may be OJT or self-study. Also, you may want to consider ICW or satellite if the design and
                                 development cost can be justified.

                             ·Availability of instructors. If the necessary instructors are not available at the resident training
                                center or field unit, you may want to consider other methods such as self-study or satellite.

                             ·Availability of facilities and equipment. If there is a lack of facilities or equipment to handle
                                the student flow, consider using OJT, self-study, or ICW.

                           ·Development time. Methods such as ICW require considerable development time. If there is
                           limited time for development or only a few students are scheduled to receive the instruction,
                           consider using other methods such as self-study or OJT.
                           Cost-Effectiveness

                             ·Trained personnel requirement (TPR). Relatively expensive delivery systems such as ICW
                                may be justified if the TPR is large and instruction is required for a long period.

                                ·Content stability. If the content requires frequent updates or revisions, ICW is less suitable
                                than classroom, OJT, or self-study.

                               ·Amount of practice required. If practice is required, consider ICW, since practice time is
                           limited only by student and equipment availability, whereas in the classroom or OJT, an
                           instructor is required.
38                                                                         AFMAN 36-2234 1 November 1993

                       Instructional Considerations

                         ·Task criticality. The criticality of a task is determined by two basic factors: whether the task is
                             done under emergency conditions and how serious the results are if it is not done right. If
                         task performance is critical, consider classroom instruction or OJT. ICW is also being used to
                             learn critical tasks; however, using other self-study methods to learn critical tasks is
                             questionable.

                         ·Learning difficulty. The difficulty of learning is related to the complexity of the task (task
                            difficulty) and to the types or levels of performance and knowledge needed to meet task
                            requirements. Tasks that are difficult to learn may be taught using the classroom, OJT, or
                            ICW.

                         ·Instructional fidelity. If the requirement for instructional fidelity (the degree to which training
                             should represent actual defense system performance) is high, select a method that uses the
                             actual equipment, simulators, part-task trainers, or ICW to teach the process or procedures.

                         ·Interaction level. If the learning process requires a great deal of interaction, OJT is probably
                         the best, since it is highly interactive. If the group size is small, classroom instruction can
                         provide moderate interaction. The use of ICW may also be considered. Except for ICW, self-
                             study is an unsuitable method if the process requires high interactivity.



                                                    Select Media

 Introduction          No single medium is the most appropriate choice for every instructional situation. Selecting the
                       appropriate media ensures that the information to be learned is presented to the students by the
                       most effective and efficient means possible.

 What Are              Media are the means, instrument, or material used to communicate information; in other words, a
 Media?                means used to give information to the students. Examples of media range from the classroom
                       instructor to study guides, CBT, satellite training, interactive video, or numerous other types of
                       media.

 Who Is               Selecting media for the instructional system is the overall responsibility of the instructional
 Responsible?         developer. If the design team approach is used, the appropriate team members will assist the
                      designer in selecting the most effective, cost-efficient media for the system.

 Media Types           Many different media exist for delivering instruction. Some of the most common types are shown
                       below. Note: If copyrighted media are selected, get copyright permission.
                                    INSTRUCTIONAL MEDIA TYPES
                                     Instructional Media Group                            Representative Examples
                                     Classroom instructor with
                                              classroom aids                              Lecturer
                                       ·Classroom instructor                              Demonstrator
                                                                                          Tutor/coach
                                                                                          Overhead projector
                                       ·Instructional aids                                Film strip (silent)
                                                                                          Slides
                                                                                          Chalkboard
                Multimedia                                          Prenarrated slides
                                                                    Prenarrated film strips
                                                                    Slide/workbook/tape recorder combinations
                                                                    Video cassette television
                                                                    Interactive courseware (ICW)
AFMAN 36-2234 1 November 1993                                                                                                                           41
                          Print                                                       Books
                                                                                      Computers
                                                                                      Programmed instruction booklets
                                                                                      Microfiche
                          Peer (or peer group)                                        Role playing
                                                                                      Discussion groups
                                                                                      Tutoring/coaching
                          Training devices and simulators                             Actual equipment trainers
                                                                                      Gaming
                                                                                      Interactive computer (simulation)
                                                                                      Flight training simulators


 Media                              Media characteristics make them either suitable or unsuitable for particular instructional
 Characteristics                     situations. These characteris tics should be considered to ensure that the appropriate media are
                                    selected to deliver the instruction. Following are the characteristics of the most common media.
                                       CHARACTERISTICS OF INSTRUCTIONAL MEDIA
 Material       Advantages                                                   Limitations
 Printed Media 1. Include common types of materials                          1. Sophisticated types more costly to prepare
                2. Wide variety of applications                              2. Require suitable reading ability
                3. Simple types quick to prepare
 Overhead       1. Can present information in systematic, developmental      1. Require special equipment and skills for more advanced preparation
 Transparencies sequences                                                    2. Are large compared with other projectors
                2. Use simple-to-operate projector with presentation rate
                 controlled by instructor
                3. Require only limited planning
                4. Can be prepared by variety of simple, inexpensive
                methods
                5. Particularl y useful with large groups
 Audiotape      1. Easy to prepare with regular tape recorders               1. Have a tendency for overuse, as lecture or oral textbook reading
 Recordings     2. Can provide applications in most subject areas            2. Fixed rate of information flow
                3. Equipment for use is compact, portable, easy to operate   3. Low fidelity of small portable recorders
                4. Flexible and adaptable as either individual elements of
                instruction or in correlation with programmed
                materials
                5. Duplication easy and economical
 35-mm Slide 1. Require only filming, with processing and mounting by        1. Require some skill in photography
 Series         film laboratory                                              2. Require special equipment for closeup photography and copying
                2. Result in colorful, realistic reproductions of original   3. Can get out of sequence and be projected incorrectly if slides are handled
                 subjects                                                    individually
                3. Prepared with any 35-mm camera for most uses
                4. Easily revised and updated
                5. Easily handled, stored, and rearranged for various uses
                6. Increased usefulness with tray storage and remote
                 control by presenter
                7. Can be combined with tape narr ation for greater
                effectiveness
                8. May be adapted to group or individual use
 Multimedia     1. Can demand attention and create strong emotional          1. Require additional equipment, complex setup, and careful coordination
 Presentations impact on viewers                                             during planning, preparation, and use
                2. Can compress large amounts of information into            2. Equipment and production costs high for complex programs
                short presentation time
                3. Provide for more effective communications in certain
                situations than when only a single medium is used
 Video and      1. Particularly useful in describing motion, showing         1. High cost for studio production equipment
 Film           relationships, and giving impact to topic                    2. Resolution limited with video for fine detail
                2. Allow instant replay of video recording                   3. Incompatibility of some video format types
                3. Video tape reusable                                       4. Value of investment in motion picture equipment reduced as video replaces film
                4. Easy to record lip sync on videotape
                5. May include special filming techniques (animation,        Note: Videotape fast replacing 16mm film medium.
                time-laps)
                6. Combine stil l and motion on videodisc
                7. Standardized film projector available everywhere
 Interactive    1. Presents text information and graphic images              1. Requires computers and programming knowledge
 Courseware 2. Interacts with learners on individual basis through           2. Requires essential hardware and software for
                asking questions and judging responses                       development and use
                3. Maintains record of responses                             3. Incompatibility of hardware and software among
                4. Adapts instruction to needs of learner                    various systems
                5. Controls other media hardware
                6. Can interface computer and video for learner-
                controlled programs
40                                                                                       AFMAN 36-2234 1 November 1993


 Media Selection by             During the initial stages of media selection many of the types of media available were excluded as
 Learning Outcomes              being inappropriate. The following table (Reiser and Gagné, 1983) takes media exclusion and
                                selection a step further. The table provides the implications for excluding and selecting media
                                 based on the desired learning outcome of the objective of the instruction.

                        Learning Outcome                            Exclusions                                          Selections
                        Intellectual Skills                         · Exclude media having no                           · Select media providing
                                                                     interactive feature                                   feedback to learner
                                                                    ·Exclude printed discourse for                         responses
                                                                    nonreaders                                          ·Select audio and visual
                                                                                                                           features for
                                                                                                                        nonreaders
 Cognitive Strategies                                               · Exclusions same as for                            · Select media with same
                                                                        intellectual skills                                features as those for
                                                                                                                           intellectual skills
 Verbal Information                                                 · Exclude only real equipment or                    · Select media able to
                                                                      simulator with no verbal                             present verbal messages
                                                                      accompaniments. Exclude                              and elaborations.
                                                                      complex prose for                                 Select audio and pictorial
                                                                      nonreaders                                           features for nonreaders
 Attitudes                                                          · Exclusions same as for                            · Select media able to
                                                                    verbal information                                     present realistic
                                                                                                                        pictures of human model
                                                                                                                         and the model's message
 Motor Skills                                                       · Exclude media having no                           · Select media making
                                                                      provision for learner                                possible direct
                                                                    response and feedback                               practice of skill, with
                                                                                                                           informative feedback


 Media Selection by             The media selected to deliver the instruction should determine, to a great degree, the effectiveness
 Learning Outcomes              and efficiency of the instructional system. Some media selection guidelines to be considered are:

                                   ·Design of the specific instructional environment in relation to system constraints and
                                       instructional objectives.
                                   ·Instructional strategy that has been planned, based on the types of learning involved.
                                   ·Extent to which individualization of the instruction would be cost-effective.
                                   ·Availability of the work-hours, know-how, and funds required to develop, produce, and
                                   maintain instruction using the selected media.
                                   ·Availability of the resources needed to deliver the instruction.
                                   ·Impact on cost-effectiveness of the instruction.



                                              Select Media for Integrated Activities

 Introduction                   Most types of complex skills involve multiple objectives from different domains of learning. A
                                 skill that involves two or more objectives from different learning domains involves integrated
                                learning activities. Media selection for integrated learning activities must take into consideration
                                the enterprise and the learner's schema, metaskills, and experience.

 Enterprise                     An enterprise is an integrated, purposeful activity that usually leads to accomplishment of a goal.
                                For example, an individual might have an enterprise to construct and implement an air campaign
                                plan in a war situation. An individual does not have to have all the prerequisite skills to engage in
                                an enterprise. The importance of an enterprise is that it is purposeful and relevant to the learner.
                                This motivates the learning behavior necessary to complete the component tasks.
AFMAN 36-2234 1 November 1993                                                                                41
 Schemas          A schema is an individual's organization of knowledge. Schemas may take the form of scripts (a
                            kind of story or scenario that organizes information) or frames (a structure that looks like a table
                             or matrix into which information fits). Different levels of learners have different types of
                            schemas. A novice learner (in a particular subject area) has a very sketchy schema or structure
                            into which new information can be placed. An experienced learner (one who has had some
                            training in a subject area) has a better structure and therefore is a quicker learner than the novice.
                            Finally, an expert has a very highly developed schema and is probably capable of rapid learning
                            with very little learning support.

 Metaskills                 Metaskills are cognitive strategies that an individual applies to the processing of new information
                             in a novel situation (a scenario not previously experienced). These skills include chunking or
                            organizing new information, recalling relevant schemas, adding the new information to the old
                            schemas, and creating new schemas. Although metaskills are probably subject-independent,
                            different individuals have different metaskill capabilities depending upon their experience with a
                            particular subject content. For example, an expert has developed metaskills and can relate better
                            to a novel situation than a novice. An expert is more efficient at processing new information and
                            applying it to the novel situation.

 Learner Experience         It is helpful to know how experienced a learner is when selecting media or teaching strategies.
                            The more experience, the higher the level of metaskills and strategies the learner will be able to
                            employ. Experienced learners can deal with larger steps of instruction and more complex learning
                            environments. Novices, on the other hand, require simplification of complex contexts so they
                             don't experience information overload while learning.

 Media Selection            When designing learning environments, the fidelity of the training situation should take learner
 Guidelines                 experience into consideration. It is generally better to teach a novice in a simplified context, so
                            that the amount of information and noise is reduced to a manageable level. At this level, part-task
                            trainers (PTT) are often used to teach component skills that will be integrated later as the learner
                            becomes more experienced.

                            Experienced learners can handle greater information loads and can disregard noise, so the context
                            should be more lifelike, yet not full-fidelity. Here, training aids with integrated subsystems are
                            often used so the learner can learn how they work together and how procedures that involve more
                            than one subsystem are performed.

                            Experts are capable of learning very quickly in high-fidelity environments. They transfer their
                            knowledge from other similar environments and actually enjoy learning using real equipment or
                            very high-fidelity simulators. For instance, if you are training an F-14 pilot to fly an F-16, you
                            don't have to go back over what is already known; the learner simply has to know the differences
                            between the planes that will affect how they are flown.

 Media Selection for The chart below shows approaches to consider when selecting media for integrated learning
 Integrated Activities activities. Examples of learning activities for each approach are provided with possible media for
                            supporting the activities.

                            Consider the learning activity for which you are developing training and select the appropriate
                            media to achieve the integrated goal, end goal, or terminal objective.
                                    Approach                     Example of Activity              Example of Media
                                    Provide alternate media      Function of Parts                CBT
                                    for presentation and
                                    practice
                                                                 Procedures                       PTT or Simulator
                                    Provide multiple media for Emergency procedures               Classroom, CBT, Simulator
                                    the same task
                                    Provide intermediate         Air refueling                    PTT, Simulator, Aircraft
                                    practice exercises
42                                                                               AFMAN 36-2234 1 November 1993

                                    Provide repeated, spaced Landing an aircraft                  Simulator, Aircraft
                                    practice


                                      Determine Instructional Strategies

 Introduction              Now that the instructional method and media have been selected and the various types of learning
                           have been considered, the instructional strategy can be determined. Determining the instructional
                           strategies enables the instructional activities to be designed. Selection of the instructional strategy
                           needs to be consistent with the prior learning analysis and objectives hierarchy decisions. It also
                           needs to support the instructional aims and overall instructional concept.

 What Are                  Chapter 2 on learning theory described how the events of instruction are related to the internal
 Instructional             processes of learning. From a learning theory perspective, the purpose of instruction is to activate
                           internal processes in order to facilitate the acquisition of new skills, knowledge, or attitudes
 Strategies?                (SKA). Different kinds of learning outcomes require different means for activating the internal
                           processes. These means are called instructional strategies.

                           The following table shows the relationship between learning processes and phases and provides
                           examples of general strategies to support learning. These are activities that support cognitive
                           strategies, which were discussed in Chapter 2.

 Learning Learning         Instructional       Strategies to                    Examples
 Process  Phase            Aim                 Support the
                                               Processes
 Expect-     Motivation    Build relevancy and · Set the stage.                 · Tell a story.
 ancy                      communicate the     ·Personalize the context.        ·Provide a demonstration.
                           goal.               ·Create uncertainty.             ·Ask leading questions.
 Perception Appre-         Focus attention.    · Use novel or interesting       · Use color.
            hending                                examples.                    ·Use print techniques such as
                                               ·Activate the learner's               bold face type or italics.
                                                   senses.                      ·Introduce sounds, smells, real
                                                                                     objects, video.
 Working     Acquisition   Present information · Organize the content.          · Use mnemonics.
 Storage                   in manageable units. ·Produce a visual image that    ·Chunk the information.
                                                    illustrates abstract        ·Outline the information.
                                                    information.                ·Use imaging techniques (such as
                                                                                     concept mapping and
                                                                                     Information Mapping® ).
 Encoding Processing       Build upon existing · Put content into               · Provide analogy, metaphor,
                           knowledge.              meaningful context.               simile.
                                                                                ·Provide meaningful examples
                                                                                     and nonexamples.
 Storage     Retention     Merge new           · Encourage rehearsal.           · Create new examples.
                           information with    ·Provide for spaced review.      ·Paraphrase the information.
                           existing knowledge.                                  ·Have learner verbalize new
                                                                                     SKA.
 Retrieval   Recall        Attach the new SKA · Provide situations in           · Practice application of new
                           to environmental       which new information              SKA.
                           cues.                  should be used.               ·Have learner teach the new
                                                                                     SKA.
 Validation Feedback       Test accuracy of      · Compare performance to       · Provide feedback to learner.
 of Under-                 new SKA.                 acceptable standard.
 standing
AFMAN 36-2234 1 November 1993                                                                                                43
 Transfer    Generali-zation Allow for             · Provide collaborative       · Illustrate how new SKA might
                             generalization of         learning exercises (team       be used in new situation.
                             recall cues.              problem solving).         ·Have learners generate new
                                                   ·Provide alternative contexts      ways to use SKA.
                                                       in which SKA can be
                                                       used.
 Valuing     Personali-      Reinforce             · Utilize SKA as context for · Reinforce behavior by making
             zation          meaningfulness of         new learning.                  it relevant to work or
                             new SKA.              ·Apply SKA in authentic       another new SKA to be learned.
                                                       activities.


 Purpose of             The purpose of instructional strategy is to outline how instructional activities will relate to
 Instructional Strategy achievement of the objectives.

 Determining                 Several key learning concepts that should be considered when determining instructional strategies
 Strategies                  are:

                               ·Active student participation
                               ·Student feedback
                               ·Planned pacing




 Active Student              When determining the instructional strategy, the concept that active student participation is
 Participation               required for effective and efficient learning to take place should be considered. Individuals learn
                             by doing, thinking, and feeling— by answering questions, discussing, computing, manipulating,
                             putting ideas together, etc. Thus, to ensure that learning has taken place, the instructional
                             strategy should ensure that students are active in the learning process and that they can apply or
                             demonstrate what they have learned. When determining the strategy, there are several
                             considerations.

                      Type of Learning                             Consideration
                      Skill                                        · Demonstrate task which the student is to perform.
                                                                   ·Have each student perform each step of the task.
 Knowledge                                                         · Use questions throughout the lesson.
                                                                   ·Each question should support objectives.
                                                                   ·Each student should participate in the questions.
 Attitude                                                          · Use human modeling to shape student attitude.
                                                                   ·Use guided discussions for affective lessons.
                                                                   ·Give or withhold rewards.
44                                                                          AFMAN 36-2234 1 November 1993

 Student              Students actively participating in the teaching-learning activity may require feedback on how well
 Feedback             they are doing. Feedback not only informs the students how well they are doing, but also serves
                      as a valuable source of motivation. The instructional strategy should be to provide each student
                      with adequate feedback, whether it be the results of a written test, instructor comments, ICW
                      responses, etc., during the performance of a task.

                      Key points to remember about feedback are:

                        ·During the early stages of instruction, feedback should be provided often to keep students
                           informed of how well they are doing and to build their confi dence.
                        ·During the latter stages of instruction, feedback should be provided as necessary.
                        ·Timing, responsiveness, and being constructive are critical.

                      As part of determining instructional strategy, instructional developers should determine what
                      follow-through activities are required. For example, if a student fails to meet the established
                      standards after receiving instruction, will remediation be provided? If so, have the remedial
                      instructional activities and materials been prepared in order toprovide additional assistance to the
                      student? Likewise, if a student does exceptionally well during the instructional period and
                       finishes ahead of other students, are
                      enrichment materials or instructional activities available for the student to participate in until the
                      other students reach mastery?

                      Follow-through activities are an essential part of determining the overall instructional strategy for
                      instructional systems.

     Planned Pacing   A key strategy that should be determined along with student participation and feedback is that of
                      planned pacing. Pacing is the rate at which students go through the instructional sequence.
                      There are several ways to pace the students' progress.

                        ·Group-paced - Students are given the instruction and progress through the sequence as a
                        group, at the same rate. This is a very effective method when teaching groups of students. It
                           allows the group to progress faster or slower than the predetermined rate depending on the
                           ability and need of the group.

                        ·Group lock-step - The group progresses through the instructional sequence at a predetermined
                           pace, completing the instructional sequence on schedule. Normally this is the most costly
                        form of pacing. However, in cases where students' flow through the training sequence is critical,
                           it is very effective. This method is useful when there are constraints such as equipment or
                           facilities that require the students to flow through the sequence on schedule to avoid
                        conflicts.

                        ·Self-paced - Students are allowed to work at their own pace through the instructional sequence
                            within certain parameters. This form of pacing is very effective in courses using CBT,
                            interactive video, self-study, etc.

                      ·Combination pacing - Any of the above-mentioned forms of pacing may be used in combination
                      with another in an instructional sequence. Some of the instruction may be group-paced while
                      other instruction may be self-paced.
AFMAN 36-2234 1 November 1993                                                                                      45

                  There are several techniques which can be used to provide planned pacing to meet the individual
                  needs of the students.

                  •       Proficiencty advancement - This technique is used to advance students who have prior
                        knowledge or practical experience, or who are exceptionally fast learners. Students show their
                        proficiency by passing a criterion test afor the instructional sequence. Students may be
                        advanced through each sequence in which they have passed the criterion test.

                  • Multiple track - The instructional sequence may be divided into various tracks of learning,
                    which allows students to track through portions of instruction that are best suited to their
                    abilities and needs. The best track for a student is uaually determined by administering a
                    pretest.

                  • Modular scheduling - The instruction is divided into different modules and students are
                    pretested to determine which modules they need. Modular scheduling is normally used only
                    when the learning sequence is not critical.

                                Design Instructional Activities
 Introduction     Once the instructional strategy has been determined, the instructional activities can be designed.
                  Design of the activity depends largely on two factors, sequence of instruction and size of the
                  instructional unit.

 Reasons for      There are several reasons for sequencing instruction.
 Sequencing
                      ·Student motivation - Students learn best when they are motivated to do so. In most cases,
                          motivation depends on a sense of direction. Properly sequenced instruction should provide
                       this direction, and give the students a "mental roadmap" of where they are going and how they
                          are going to get there. With this mental roadmap, students are less likely to be confused.

                      ·Meaningful relationship - A proper sequence can provide the students with a pattern of
                        relationships so that each instructional activity will have a purpose. If instruction is
                        meaningful to the students, they should learn more easily and quickly.

                      ·Consistency in content - Proper sequencing helps to avoid inconsistencies in the training
                         content. Consistency of content ensures that skill progres sion is orderly and that prerequisite
                         knowledge and skills have been acquired.


 Sequencing       There are several methods of sequencing instruction.
 Instruction
                      ·Job performance order - The order in which the tasks and subtasks are performed on the job.

                      ·Psychological order - Arranges the instructional content based on the ease of learning.
                       Students are taught the easier tasks first, then progress to the more complex tasks.

                  ·Logical order - Normally, instructional activities should be designed to proceed from the simple
                   to the complex or from the known to the unknown. However, instructional activities may not
                  always lend themselves to these design meth ods. In such cases, you may want to design the activity
                  using both the performance order and the psychological order. This arrangement normally
                   includes the whole-part-whole concept, showing the whole, breaking it down into parts, then back
                  to the whole.
46                                                                       AFMAN 36-2234 1 November 1993

 Guidelines for     Various methods of sequencing can be used to design the instructional activity based on the
 Sequencing          content of the instruction and resource availability. When selecting methods to design the
                    activities, consider the following:

                      ·Place easily learned objectives early in the instructional sequence.
                      ·Provide any common or "core" instruction in the early part of the sequence.
                      ·Sequence subobjectives with the objective they support.
                      ·Place skills and procedures within each objective in job order when possible.
                      ·Introduce concepts at the first point where the understanding of those concepts is a prerequisite
                          for successful performance.
                      ·Provide instruction on prerequisite skills before the time where they should be combined as
                          required on the job.
                      ·Introduce a knowledge or skill in the task in which it is most likely or most frequently to be used.
                      ·Provide for practice of skills and concepts in areas where transfer of like or related skills is not
                          apt to occur.
                      ·Design and provide intermediate practice exercises to allow the student to gain proficiency of a
                          particular enterprise due to difficulty or newness.
                      ·Provide for repeated, spaced practice to gain and maintain proficiency.
                      ·Place complex and cumulative skills late in the sequence.


 Optimum Size       The best approach to designing the proper size or increment of instruction is to start with minimal
 of Instructional   instruction, and rely on validation to show if more instruction is needed in a particular unit. This
                    method combined with feedback from training evaluation may indicate the need for more
 Unit               instruction. If you provide more instruction than is necessary in the beginning, you may not have
                     a good indication that you have done so.

                                            Section E
                                   Develop Implementation Plan

 Introduction       Once the instructional system has been designed and before the development phase begins, the
                    implementation plan for the instructional system is developed. It is important for management and
                    control purposes to have a plan documenting the instructional system.
AFMAN 36-2234 1 November 1993                                                                                   47
 What Is An       An  implementation   plan documents the design of the instructional system and how the system
 Implementation   will be used. Plans may include, but not be limited to, information such as:
 Plan?                 ·Identification
                               ·Parameters of instructional system
                               ·Type of instruction
                               ·Instructional methods
                               ·Instructional content
                               ·Resource requirements
                               ·Design, development, and implementation milestones

                           Implementation plans may include resource and control documents such as:

                               ·Tasking letters, messages, etc.
                               ·Equipment lists
                               ·Personnel documents
                               ·Facility requirements
                               ·Plans of Instruction (POI) and syllabuses
                               ·Training standards
                               ·Course maps
                               ·Course charts
                               ·Resource constraints


 Purpose                   Implementation plans that are well developed have several purposes, which include:

                               ·Document the instructional system.
                               ·Identify resource requirements/constraints such as personnel, equipment, facilities, etc.
                               ·Set the design, development, and implementation milestones.
                               ·Serve as the approval document for operation of the instructional system.
                               ·Serve other purposes as determined by the particular system.


 Who Is Responsible? Implementation plans are the direct responsibility of instructional systems management.
                            Managers should develop a plan that describes or documents the instructional system. In order
                           to develop this plan, input may be required for other organizations such as instructional staff,
                           resource managers, or civil engineers.

                                              Section F
                       Design Instructional Information Management System

 Introduction              Effectively and efficiently managing information is one of the more difficult tasks in instructional
                           systems management. There are always records to be updated, students to be scheduled,
                           equipment to be tracked, and budgets to be met. Regardless of whether the task is accomplished
                           using pencil and paper or computers, it is a task that should be done well. During the initial
                           stages of ISD project planning, management strategies should have focused on managing
                           instructional information.
48                                                                  AFMAN 36-2234 1 November 1993

 Purpose        The purpose of an automated instructional information management system is to better manage
                the system. For example, the automated system can be used by:

                    ·Instructors to update student status
                    ·The registrar to track student status
                    ·Instructional developers to update instructional materials
                    ·Managers to manage resources


 Who Is         Responsibility for designing an instructional information management system normally falls on a
 Responsible?   project manager or officer. However, course managers have the responsibility to ensure that the
                instructional information is adequately managed for their instructional system. In most cases,
                managers may not have an option as to whether an automated information management system is
                designed or not. The decision is normally based on the availability of a management system. If a
                system does exist, it may be used by all who are involved in the instructional system.

 Designing a    There are many things to consider when designing or redesigning a management system. Some
 Management     of these are:
 System             ·What is the system cost?
                    ·What are the hardware capabilities?
                    ·Are there any special environmental requirements for the hardware?
                    ·What are the software capabilities?
                    ·Is the system documentation adequate?
                    ·Are the hardware and software user-friendly?
                    ·Does the system have proven reliability?
                    ·Is the system maintainable?
                    ·Will the system interconnect/interface to existing systems?
                    ·Is the system software compatible with other software?
                    ·Does the hardware have expansion capability?
                    ·Can the software be upgraded or modified easily?
                    ·What instructional information will the system be able to manage?

                Other considerations include:

                    ·Who are the system users?
                    ·What information will they need to manage their jobs?
                    ·What information is common/unique?
                    ·How long should the information be maintained?
                    ·What reports will be required? Standard? One-time?
                    ·What outside agencies need information? Frequency?
                    ·What information will be needed for each training system function?
                    ·What interfaces will be required?



                                      Section G
                              Update ISD Evaluation Plan
 Introduction   In the initial stages of ISD project planning, the ISD evaluation plan was developed. The
                emphasis of the evaluation plan is to ensure total quality in the instructional system, the
                instructional development process, and the products of that process. To ensure that the ISD
                evaluation is effective throughout the life cycle of the project, the plan may need to be updated
                periodically.
AFMAN 36-2234 1 November 1993                                                                                 49
 Assessing Quality ISD is a quality management process. There are different ways to assess the quality of the
                          design phase. One of the simplest ways is to develop a job aid using questions focused on quality
                          improvements. Examples of questions are:

                              ·Does the ISD evaluation plan assess the quality of both process and products in the design
                                   phase?
                              ·Is the instructional design effective and cost-efficient?
                              ·Can the instructional design process be improved? If so, how?
                              ·Are the metrics or standards for the design process and products realistic and adequate? If
                                   not, why not?
                              ·Are the performance standards correct?
                              ·Can the products of the design phase, such as objectives and tests, be improved? If so, how?
                              ·How can the instruction be better accomplished?
                              ·Are the products of the design phase accurate?
                              ·Do the products of the design phase contain adequate information? If not, what information
                                   should be added?
                              ·Do the products of the design phase contain information that is not needed?
                              ·Are products being developed during the design phase that are not needed?


 Why Update the           Updating the plan keeps the evaluation process "on track" and effective through the remainder of
 Evaluation               the ISD process. Therefore, it is necessary to update the plan with the results of the design phase
                           to keep the information current and accurate in order to effectively evaluate the development
 Plan?                    process and products.

 Who Is                   Management has the overall responsibility of developing and updating the evaluation plan.
 Responsible?

 What Should              Updating the plan may include, but not be limited to:
 Be Updated?
                              ·Changes in the scope of the evaluation strategy resulting from the design phase such as:
                                 ··Procedures to be used in evaluating the design process and products
                                 ··Design products to be evaluated such as objectives, test items, etc.
                                 ··Standards to be used to evaluate the design process and products

                              ·Revisions to the evaluation schedule such as:

                                  ··When the design process and products should be evaluated
                                  ··When SME or other expertise is required

                              ·Documenting the evaluation results of the design phase
                              ·Providing rationale for changes made to the evaluation strategy
                              ·Lessons learned during the evaluation of the design process and products


 Tracing                  Quality of the design process and the resulting products is very important to the instructional
 the Quality              development process. Therefore, document the evaluation of the design phase to the point that
                          the quality process can be traced throughout the entire ISD process, including the design phase.
 Process
                          Caution: Document only what you need— never document more than you need

                                               Section H
                                      Update ISD Management Plan
50                                                                      AFMAN 36-2234 1 November 1993

 Introduction       When the design phase is complete, it is likely that the plans for managing the instructional system
                    will require updating. An updated management plan should guide system and instructional
                    development during the design phase. During the design phase, if changes are made that impact
                    management strategies, the plan may again need to be updated to reflect the current information.

 Importance of      Current management plans are essential to ensure that the instructional system continues to be
 Management Plans   developed according to the predetermined plan, instruction is designed using the ISD process, and
                    the entire effort is on schedule and under budget.

 Purpose            The management plan has several purposes:
                                         ·It serves as a tool for managing the system and the instructional
                    development process.
                                         ·It establishes milestones for system and instructional development.
                                         ·It ensures that effective and efficient instructional systems are developed.


 Why Update         Management plans are continually updated to reflect current status of the project. The plan
 Management         should be the latest roadmap showing where the project is, where it is going, and how it's going
                    to get there.
 Plan?

 Who Is             Management is responsible for seeing that the management plan is updated with the most current
 Responsible for    information and status. The information necessary for updating the plan should be provided by
                    the organizations responsible for supporting, operating, and maintaining the instructional system.
 Updating?

 What Should You    Include the latest information resulting from the design phase, such as:
 Update?
                        ·Changes to the overall management strategy for the system and instructional development
                            process
                        ·Refinements to project definition
                        ·Revisions to the resource requirements
                        ·Changes in resource constraints
                        ·New or revised milestones
                        ·Addition or deletion of taskings
AFMAN 36-2234 1 November 1993                                                                                    51
                                         Chapter 6
                                      DEVELOPMENT

Overview


 Introduction     At this point, objectives have been specified, tests developed, training strategies and activities
                  planned, and you are ready to implement your design in the development phase. Adequate
                  planning, analysis, and design should make it easier to develop instruction. Some of the tasks to
                  be discussed in this phase include developing plans of instruction, writing lessons, producing
                  instruction al materials, and developing interactive courseware.


 Where Are        In order to visualize the ISD process, a model with the development phase highlighted is
 You in the       provided in Figure 9.
 Process?




 Objectives       The objectives of this chapter are to:

                      ·Explain the tasks involved in developing instruction.
                      ·Discuss installation of instructional information management systems.
                      ·Define planning requirements for course development.
                      ·Explain the validation process.
                  ·Discuss finalization of instructional materials.

                                      Section A
                     Prepare Plan of Instruction/Course Syllabus

 Introduction     Once the instruction has been designed, a plan of instruction (POI) or course syllabus should be
                  prepared. The POI or syllabus serves as the overall plan for conducting instruction in a particular
                  course; therefore, careful preparation of these documents should help ensure the effectiveness and
                  efficiency of the instructional system. They help standardize the instruction while controlling the
                  quality of the teaching-learning activity.
52                                                                    AFMAN 36-2234 1 November 1993

 Purpose          The POI or course syllabus is a control document used for planning, organizing, and conducting
                  instruction.

 Description      The POI/course syllabus documents the instructional events of a course. It expands the basic
                  course control documents and provides detailed information needed to provide the instruction.
                  Although POIs or syllabuses can be in different formats, they are normally organized by units or
                  modules of instruction with each unit containing information such as:

                      ·Course description, such as title, number, and security classification
                      ·Statement of objectives
                      ·Preferred instructional sequence
                      ·Instructional hours and approximate allocations of those hours to objectives
                      ·Portions of the training standard that the unit of instruction supports
                      ·Instructor requirements, including multiple instructor requirements
                      ·Instructional method, such as lecture, demonstration, performance or self-study
                      ·Support materials, such as student instructional literature or technical orders
                      ·Media utilization
                      ·Equipment utilization
                      ·Instructor guidance
                      ·Lesson plans


 Why Have         The POI/course syllabus is the course control document that serves as the single "blueprint" for
 POIs/Syllabus?   providing instruction in a course. It is also used to develop the lesson plans which are used by the
                  instructors to guide teaching-learning activities during units or modules of instruction.

 Who Is           Instructional developers and instructors normally prepare the POI/course syllabus and revise them
 Responsible?     as applicable. However, course managers have the overall responsibility for monitoring the
                  preparation, as well as ensuring that they remain current.

 Guidelines       There are no specific guidelines for preparing POIs/course syllabuses since they should be
 for POIs         adapted to various course applications to meet the needs of the using organization. However,
                  there are several basic or general guidelines that apply to all POIs. They should:

                      ·Be easy to use.
                      ·Document the plan of instruction.
                      ·Provide adequate information.
                      ·Be easily maintained.
                      ·Meet the organization's need.

                  Also, the format of the lesson plan is determined by the organization providing the instruction.



                                       Section B
                             Produce Instructional Materials

 Introduction     In the development phase, the instructional materials used to support the system should be
                  developed. Material development is a time-consuming and exacting task regardless of the medium
                  that has been selected. It is essential that quality materials be developed, since they carry the
                  information to be learned to the students. Adequate resources are required to develop quality
                  materials in a timely manner.

 What Are They?   Instructional materials refer to printed or other media intended to convey events of instruction or
                  communicate information to the students.
AFMAN 36-2234 1 November 1993                                                                                            53

 Types of                 Some of the instructional materials/media that can be used to deliver instruction are:
 Instructional
                              ·Print-based material
 Materials                    ·Transparencies
                              ·Slide/tape
                              ·Audio/video tapes
                              ·Interactive courseware (ICW), including CBT and CMI
                              ·Interactive video
                              ·Mission scenarios
                              ·Interpretive exercise


 Factors in               Development of instructional media products may be affected by several factors. The relative
 Media                    importance of each of these factors depends on the medium selected. These factors are:
 Development                  ·Development personnel required
                              ·Development time required
                              ·Development cost required


 Development             Media product development requires many activities. The type and number of activities depend
 Activities              upon the materials being developed. For example, some common development activities are
                         provided in the following table.

                     Media                                       Development Activity
                     Print                                               ·Draft/write material
                                                                     ·Edit material
                                                                     ·Publish material
 Transparencies                                                          ·Draft transparency
                                                                     ·Generate reproducible transparency
                                                                     ·Reproduce transparency
 Slide/Tape                                                              ·Storyboard/script slide or tape
                                                                     ·Shoot and edit slide/tape
                                                                     ·Narrate audio
                                                                     ·Print slide/tape
 Videotape                                                               ·Storyboard/script
                                                                     ·Shoot and edit video
                                                                     ·Develop audio
 CBT                                                                     ·Storyboard/script
                                                                     ·Develop graphics
                                                                     ·Program/code computer
 Interactive Video                                                       ·Storyboard/script
                                                                     ·Shoot and edit video
                                                                     ·Develop graphics
                                                                     ·Develop audio
                                                                     ·Program/code computer
                     Mission Scenarios                                  ·Determine mission requirements
                                                                     ·Establish parameters
                                                                     ·Develop mission
                                                                     ·Program/code mission
                           All media products go through stages of development which may vary depending on the type of
                           media being developed.
54                                                                AFMAN 36-2234 1 November 1993

 Who Is         Developing instructional media products normally requires teamwork and various skills.
 Responsible?   Instructional developers are responsible for planning, scheduling, and making sure the
                instructional media get produced. The following table lists team members required for production
                of the different media.

                         Media                   Development Role
                         Print                          · Subject Matter Expert
                                                    ·Instructional Developer
                                                    ·Editor
                                                    ·Graphic Artist
                         Transparencies                 · Instructional Developer
                                                    ·Graphic Artist
                                                    ·Editor
                         Slide/Tape                     · Script Writer
                                                    ·Subject Matter Expert
                                                    ·Photographer
                                                    ·Audio Technician
                                                    ·Editor
                         Videotape                      · Script Writer
                                                    ·Subject Matter Expert
                                                    ·Video Producer, Editor, Photographer
                                                    ·Audio Technician
                         CBT                            · Script Writer
                                                    ·Subject Matter Expert
                                                    ·Graphic Artist
                                                    ·Computer Programmer
                         Interactive Video              · Programmer
                                                    ·Script Writer
                                                    ·Subject Matter Expert
                                                    ·Video Producer, Editor, Photographer
                                                    ·Graphic Artist
                                                    ·Audio Technician
                         Mission Scenarios              · Aircrew Member
                                                    ·Instructional Developer
                                                    ·Computer Programmer
AFMAN 36-2234 1 November 1993                                                                                              55
 Guidelines for   When developing instructional materials, make sure they:
 Product
                    ·Support the objectives.
 Development        ·Are student-centered.
                             ·Build learning on learning.
                             ·Meet the design that was specified in the design phase.
                             ·Use techniques that are consistent with the principles of effective learning.
                             ·Are appealing to the students.
                             ·Are interesting and meaningful to maintain student attention.
                             ·Require student participation, as with ICW.
                             ·Lead students in the direction of the behavior specified in the objective and guide them
                                 toward mastery of the task with proper stimuli and reinforcement.
                             ·Are developed using experts such as programmers, photographers, graphic artists, script
                                 writers, and editors in order to develop quality instructional material.
                             ·Are checked prior to publication/production to ensure quality, e.g., for technical accuracy,
                                 completeness, programming errors, blurred visuals.
                             ·Use appropriate vocabulary at the level of the target population.
                             ·Are properly paced.
                             ·Are easy to understand.
                             ·Include appropriate safety precautions.
                             ·Support the human relations concepts to which the Air Force is committed.


 Additional              For additional information on development of media and materials, see:
 Information
                             ·AFMAN 36-2236.
                             ·Leshin, C. B., Pollock, J. and Reigeluth, C. M. (1992). Instructional Design Strategies and
                                 Tactics. Englewood Cliffs, New Jersey: Educational Technology Publications.



                                              Section C
                      Install Instructional Information Management System

 Introduction            Another activity that takes place in the ISD development phase is the installation of the
                         instructional information management system. Most individuals involved in the management,
                         design, development, and operation of instructional systems will probably never participate in the
                         design or redesign of an instructional information management system. In case you are ever
                         involved in installing an information management system, there are several things you should
                          know.

 Who Is                  A project manager or officer will normally have the overall responsibility for installing a new
 Responsible?            instructional information management system, rehosting an existing system, or modifying the
                         software or hardware of an existing system. Individuals from the organizations receiving the
                         system will more than likely be involved in performing acceptance or operational tests of the
                         system. For example, an instructor may be required to record the results of a test, while an
                         instructional developer may be asked to revise a number of objectives and the associated
                         instructional materials.
56                                                                      AFMAN 36-2234 1 November 1993

 What Should      During the installation and testing of an instructional information management system, there will
 Be Checked?      likely be documents that guide installation and checklists to test system operation. These
                  documents or checklists are normally sufficient; however, if they are not, there are numerous
                  items that should be checked. Examples of items that can be checked are:

                      ·Are the operating instructions adequate?
                      ·Is the hardware user-friendly?
                      ·Is the software user-friendly?
                      ·Are the hardware and software sufficiently documented to support maintenance?
                      ·Are there adequate terminals to do the required tasks in a timely manner?
                      ·Is the information management in each area accurate?
                      ·Is the information management in each area complete?
                      ·Is the system reliable?
                      ·Is the system adequately interfaced with other users in the organization?



                                        Section D
                                Update ISD Evaluation Plan

 Introduction     QI is a common goal throughout the entire ISD process from the initial project planning to the
                  continuing evaluation of the operational system. Remember that ISD is a quality management
                  process that focuses on both process and products. Therefore, it is necessary to have an ISD
                  evaluation plan that becomes the metric or standard for evaluating the ISD process and the
                  products of each phase. To ensure that the plan remains an effective evaluation tool throughout
                  the life cycle of the project, it needs to be updated periodically, especially after each phase of ISD.
                  At the end of the development, the evaluation plan should be updated to keep it current and
                  accurate.

 Assessing        Using ISD to develop instructional systems ensures the quality of the development process as well
 Quality          as the products of that process. The ISD evaluation plan includes procedures for evaluating the
                  process and the products development phase. A good method for assessing the quality of the
                  development phase is to develop a job aid. There are other ways, but they may not be as easy to
                  develop and use. The simplest way to develop a job aid is to use a series of questions such as:

                      ·Does the ISD evaluation plan for the development phase assess both process and product
                          quality?
                      ·Are the quality standards for the development phase realistic and adequate?
                      ·Can the development process be improved? If so, how?
                      ·Can the products of the development phase be improved or simplified? If so, how?
                      ·Are the various products of the development phase accurate and are they compatible with
                          other products of this or earlier phases? For example: Do the objectives, standard, POI,
                          lesson plan, and student materials all agree?
                      ·Are there any products in the development phase that are not needed?
                      ·Are there additional products that should be developed?


 Why Update       In order for the ISD evaluation plan to be an effective tool, it should include the most current and
 the Evaluation   accurate information. An updated evaluation plan keeps the evaluation process "on course" and
                  ensures that the evaluation process is effective throughout the remaining phase of the ISD process.
 Plan?            An updated plan helps ensure process and product quality.
AFMAN 36-2234 1 November 1993                                                                                     57
 Who Is           Course  managers  are  directly responsible for updating the ISD evaluation plan. Other individuals,
 Responsible      such as instructional developers, will likely provide information necessary for updating the plan at
                  the end of the development phase.
 for Updating
 the Plan?

 What Should               The ISD evaluation plan should be updated periodically to include new or revised information
 Be Updated?               such as:

                               ·Changes in the evaluation strategy for the development phase. For example:

                                   ··Types of products to be evaluated such as training materials, lesson plans, ICW
                                   ··Procedures to be used in evaluating the process and products of the development phase
                                   ··Standards or metrics to be used in the evaluation

                               ·Revisions to the evaluation schedules such as:

                                   ··Number or quantity of products to be evaluated
                                   ··When the development process and products should be evaluated

                               ·Documentation of the results of the development phase evaluation
                               ·Rationale for changes made to the evaluation strategy during the development phase
                               ·Lessons learned during evaluation of the development phase


 Tracing                   QI is an important part of the ISD process. In the development phase, emphasis is still on
 the Quality               quality. An important part of the quality process is to be able to trace what has been done in the
                           development phase to ensure both process and product quality. Therefore, document the quality
 Process                   process used to evaluate the development phase.

                            Document only what is necessary to trace the quality process.

                                                 Section E
                                          Update Management Plan

 Introduction              As the development phase is concluded, it is likely that the management plan, which was last
                           updated during the design phase, may again require updating to keep it current and accurate. If the
                           plan is to remain an effective management tool, it should be updated continually so that it provides a
                           roadmap for developing and managing the instructional system. Some of the information in the
                           plan that may require updating as a result of the development phase is project milestones, resource
                           requirements, and resource constraints.

 Why Update                In order to ensure that the management plan remains an effective tool for managing during the
 the Plan?                 implementation phase, it should be updated with any applicable changes resulting from the
                           development phase of ISD. A management plan with outdated project information is an ineffective
                           tool for managing the ISD process. Therefore, the plan should be the latest roadmap showing
                           where the project is, where it is going, and how it is going to get there.

 Who Is                    Managers of the instructional system have the responsibility of keeping the management plan
 Responsible               updated with the most current information and status. Most of the information necessary for
                           updating the management plan should come from the instructional staff or support organizations.
 For Updating?
58                                                                   AFMAN 36-2234 1 November 1993

 What Should    As the development phase is being completed, the management plan should be updated if
 Be Updated?    significant changes have occurred. Include new or revised information resulting from the
                development phase, as applicable. Include information such as:

                    ·Changes to the overall management strategy for the system resulting from the development
                        phase
                    ·Refinements to project definition
                    ·Revisions to resource requirements
                    ·Changes in resource constraints
                    ·New or revised milestones
                    ·Addition or deletion of taskings



                                         Section F
                                    Validate Instruction

 Introduction   At this point in the instructional development process, objectives have been developed, tests written,
                instructional methods and media selected, and instruction is being developed. Yet, there is no
                assurance the instruction will be effective. Therefore, the instruction should undergo validation to
                prove that the instruction provides graduates with skills, knowledge, and attitudes to meet job
                performance requirements. If deficiencies are found in the instruction during validation, they are
                corrected before course implementation. Validation consists of internal reviews, individual try-
                outs, and small-group tryouts which are conducted as a part of formative evaluation and
                operational (field) tryouts which make up summative evaluation.

 What Is        Validation assesses the effectiveness of instruction while it is being developed with the intention of
 Validation?    improving it. It is a process of repetitive cycles of develop ment, tryouts, and revisions until
                 evidence shows that the instruction is effective.

 When Should    When possible, validation should be done as segments, units, or blocks of instruction are
 Validation     developed or revised. Instructional developers and instructors should not wait until all of the
                instruction has been developed before testing its effectiveness.
 Be Done?

                                            Develop Validation Plan

 Introduction   For an instructional system to be effective, adequate planning should take place in the initial stages
                of training development. A part of that planning is the evaluation plan, which often includes a
                plan of how the instruction is to be validated. Validation planning is essential for successful
                implementation of an instructional system.

 Purpose        A validation plan provides instructional developers and instructors with a road map for validating
                the instruction. A validation plan provides structure and creditability to the validation process.

 Who Is         Validation planning is the responsibility of managers within the instructional organization. This
 Responsible?   responsibility is often delegated to instructional developers since they often provide much of the
                information that goes into the validation plan such as the validation schedule, number of individ-
                ual tryouts, and number of tryouts to be conducted.
AFMAN 36-2234 1 November 1993                                                                                             59
 What's In a      Validation plans may contain information such as:
 Validation Plan?
                             ·Description of instruction to be validated (objectives, method, medium)
                             ·Who may conduct the validation
                             ·Validation procedures
                             ·Validation schedules
                             ·Program schedule constraints
                             ·Number of tryouts to be conducted in each of the tryout activities
                             ·Number and availability of students to be used in the tryouts
                             ·Sources and how the results should be documented
                             ·How problems should be resolved


 Getting Ready           Prior to starting validation, you should:
 To Validate
                             ·Understand each activity in the validation process.
                             ·Know who is expected to conduct the various activities.
                             ·Know when the activities are to occur.
                             ·Ensure that the instruction is ready.
                             ·Ensure that students have been scheduled.
                             ·Know how to document any deficiencies.
                             ·Know procedures for revising instruction, if applicable.



                                           Conduct Internal Reviews

 Introduction            The internal review, which is a formative evaluation activity, is the first step of the actual
                         validation process. This review, which is also called a technical accuracy review, identifies
                         inaccuracies and weaknesses in the materials under review. Materials should be thoroughly
                         reviewed, since this may be the last opportunity to revise draft materials before they are tried out
                         on the students. If possible, and when applicable, conduct internal reviews each time instruction is
                         developed, updated or revised.

 Purpose                 The purpose of the internal review is to verify the accuracy of the instructional materials as they are
                         developed in order to identify inaccuracies and weaknesses in the materials so they can be
                         corrected.

 Who Should              Internal reviews should be conducted by:
 Review?
                             ·SMEs
                             ·Instructional developers
                             ·Instructors

                         An individual selected to conduct a review should be:

                             ·A subject matter expert
                             ·A concise and constructive critic
                             ·Knowledgeable about instructional design and development
60                                                                                            AFMAN 36-2234 1 November 1993

 What Should               Instructional materials to be reviewed include, but are not limited to:
 Be Reviewed?
                              ·Objectives
                              ·Test items
                              ·Storyboards/scripts
                              ·Audiovisual materials such as slides, films, videotapes, transparencies
                              ·Job aids
                              ·Printed materials
                              ·ICW such as CBT and CMI


 How To Conduct            There are many ways to review instructional materials for accuracy, completeness, and quality.
 a Review                  The bottom line is to cross-check the materials against the data sources such as technical orders,
                           regulations, directives, and checklists. One method of helping conduct the review is to develop a
                           job aid. An example is provided :

                  Sample Job Aid for Internal Review
                          1. Is the content of the material accurate?

                      2.    Is the material current?

                      3.    Is the material complete?

                      4.    What are the "good" parts of the material?

                      5.    Are there any "bad" parts in the material?

                      6.    Does the sequence of the material build learning on learning?

                      7.    Are the practice exercises adequate?

                      8.    Are the review exercises adequate?

                      9.    Do the materials/lesson effectively teach the behavior specified in the
                            objective?

                   10. Is the objective adequately evaluated?

                   11. Is the content of the material compatible?

                   12. Can the materials be improved? If so, how?




 During a                  When conducting a review, the reviewers should:
 Review
                              ·Take careful notes while conducting the review.
                              ·Make specific comments.
                              ·Identify weaknesses in the materials.
                           ·Recommend ways to improve the materials.


 After a                   After the review, the reviewers should:
 Review
                              ·Discuss their review findings.
                              ·Determine what revisions or changes should be made to the materials.
                              ·Decide the best way to make the necessary corrections to the materials.
                           ·Make revisions and changes to the materials, as applicable.

                                               Conduct Individual Tryouts
 AFMAN 36-2234 1 November 1993                                                                                            61

Introduction          Conducting individual tryouts, which is a formative evaluation activity, is normally the next step
                      in the validation process. During this step, as the instruction and materials are being developed,
                      they are tried out on individual students. The instruction and materials should be tried out on
                      several students, if practical, to add validity and reliability to the data collected during the tryout.
                      It may not always be possible to conduct individual tryouts due to resource constraints.

Purpose               The purpose of individual (one-on-one) tryouts is to determine the effectiveness of small segments
                      or units of instruction and materials as they are developed, updated or revised.

Select                A great deal of care should be used when selecting students to participate in the individual
Students              tryouts. During the selection process, consider the following factors:

                          ·Students selected for the tryouts should be from the target audience and fall within the
                              predetermined range of:

                              ··Aptitude
                              ··Skills
                              ··Attitude
                              ··Prior knowledge
                              ··Background experience

                              If students do not fall within the range, tryout results can be skewed. Thus, student
                              performance cannot be generalized to the target audience.

                          ·Students for the first tryouts should be selected from the upper percentage ranges in aptitude
                              and background because:

                              ··Brighter students are often more likely to point out and analyze weaknesses in the
                                    instruction and materials.
                              ··If better students cannot learn the material, less capable students may not be able to.
                              ··If lower-level students are used in the individual tryouts and they do well, there is no
                                    way to tell if the instruction and materials are at the proper level.
                              ··It is easier to work down from a known point of difficulty than to work up from an
                                    unknown point of difficulty.
                              ··It is often simpler to add material to make a lesson easier than to delete material to make
                                    it more difficult. However, this is not the case in lessons dealing with electronic
                                    media presentations.


Media Use             The nature of the tryout should depend, to some degree, on the media selected for use in the course.
During Tryout         Certain types of media selected for use in the course may be too expensive for use during the
                      individual tryouts or it may not be available. However, there are ways to validate the instruction
                       and materials without having all of the media selected for the course. Following are examples.

                If Media Selected Is                                   How To Conduct Individual Tryout
                Paper-based media                                      Use the actual media that will be used in the course
                                                                       during individual tryouts.
                Available such as job aids,
                simulators, trainers

                Capable of being quickly
                and economically developed
                such as slides, graphics
62                                                                             AFMAN 36-2234 1 November 1993

 Not available                                                            Devise storyboard versions of the instruction.

                    Dangerous to use                                      For example:
                                                                              ·Paper script can be used in place of ICW,
                    Expensive to develop                                          films.
                                                                              ·Drawings and illustrations can be used in place
                                                                                  of ICW, slides.
                                                                              ·Mockups can be used to replace the actual
                                                                                  media.

 Before a                 Before conducting the individual tryouts, instructional developers should prepare the students for
 Tryout                   the tryouts. Students need to know:

                              ·The purpose of the tryout.
                              ·Their role in the tryout.
                              ·That they are not being evaluated; the instruction and material are.
                              ·That their active participation is essential if the individual tryout is to be successful.
                              ·That their feedback is necessary in determining adequacy of the instruction and materials.

                          If instructors are involved with the individual tryouts, they should be aware of their role and the
                          role of the student.


 During a                 During the individual tryouts, instructional developers should:
 Tryout
                              ·Closely observe students as they use the material.
                              ·Make careful note of where students seem to have problems or uncertainties.
                              ·Give assistance to students only when it is essential to student progress.
                              ·Administer the relevant test item at the appropriate time.
                              ·Get the students' view about the difficulties encountered during the tryout.

                          Sources of individual tryouts information are provided below.



                    Source                                                Activity/Information
                    Diagnostic Tests                                      ·Administer pretest to identify entry behavior.
                                                                          ·Administer posttest to assess learning as a result of
                                                                             the tryout.
 Student Performance During Learning                                      ·Observe and record students' performance.
                                                                          ·Determine which exercises or tasks result in
                                                                             errors; types of errors; how many students are
                                                                             making the same error(s).
 Student Comments                                                         ·Get student reaction to the instruction and
                                                                             materials, especially their difficulties.
                                                                          ·Ask students for suggestions on how the
                                                                             instruction and materials can be im proved.
  AFMAN 36-2234 1 November 1993                                                                                    63
Typical          Often,  when  conducting individual tryouts, problems are identified that are typically found during
Problems         the first tryouts. Some of the typical problems are:
                              ·Improper sequencing of the instruction
                              ·Instruction not clear and concise
                              ·Lack of supporting instructional materials
                              ·Confusing test items
                              ·Test items that do not measure objectives
                              ·Insufficient practice time


After a                   When the individual tryouts have been completed, analyze the resulting data to determine if error
Tryout                    patterns or problems have occurred on successive tryouts. If so, changes or revisions to the
                          instruction or materials may be appropriate.

                          Example: Each student participating in the individual tryouts fails to meet the performance
                          standard for a particular objective. Review the objective, training materials, and test, and revise
                          as necessary.

                          In most cases, several tryouts should be conducted before making any significant revisions or
                          changes to the instruction or materials.

                          When significant revisions or changes are required in the instruction or materials, it is
                          recommended that additional individual tryouts be conducted in order to determine if the problem
                          was solved.



                                       Conduct Small-Group Tryouts

Introduction              After the individual tryouts have been completed and all necessary revisions have been made to the
                          instruction, it is time to conduct the next stage of validation, which is the small-group tryouts. In
                          this stage, which is the last activity in formative evaluation, the instruction and materials are tried
                          out on small groups of students if practical. Again, a lack of resources may prevent or reduce the
                          number of small-group tryouts that can be conducted. Up to this point, the success of the instruct-
                          ion has been based on a limited sampling of students with higher aptitudes. It should be pointed
                          out that the instruction and materials are developed for average students; thus, small-group tryouts
                          are focused on the average group.

Purpose                   The purpose of conducting small-group tryouts is to determine if the instruction and materials
                          work under conditions approximating the actual teaching-learning activity.
64                                                                  AFMAN 36-2234 1 November 1993

 Select        Student selection for the small-group tryout is very important in terms of validating the
 Students      effectiveness of the instruction and material. Students selected to participate in the tryout should
               be representative of the target audience. If possible, students selected should:

                   ·Be evenly distributed between low and high aptitudes
                   ·Have varying skill levels
                   ·Come from different backgrounds

               Even distribution of students helps determine if the instruction and materials will be effective
               under operational conditions.

               The number of students included in the small groups should be determined based on factors such
               as:

                   ·Need for teams of students within the small group (for example, some tasks may require
                       students to work in teams of two; if so, the small-group size should be based on multiples
                       of two)
                   ·Planned normal group size of the operational system
                   ·Availability of equipment
                   ·Availability of facilities


 Time is a     To this point in the validation process, time required to perform a task has not been of major
 Critical      concern. However, time becomes a critical factor in the small-group tryouts. Learning the material
               or performing a task is not sufficient; students should be able to learn the information or perform
 Factor         the task within a reasonable time period. Therefore, effort should be made to develop instruction
               that can be accomplished within a realistic time period based on training requirements and the
               capability of average students.

 Before a      Before trying out instruction on small groups, you should:
 Small-Group
                   ·Determine the number of students to be included in the small group.
 Tryout            ·Determine the number of groups to be used in the tryouts.
                   ·Select representative students from the target audience.
                   ·Ensure that the instruction and materials have been revised to include the applicable
                       information resulting from individual tryouts.
                   ·Ensure that student materials are available in adequate quantities.
                   ·Ensure that instructional resources such as equipment, personnel, and facilities to be used
                       during the tryout approximate the operational conditions.
                   ·Ensure that the instructional information management system is operating for data
                       collecting, analysis, and reporting.
  AFMAN 36-2234 1 November 1993                                                                                         65
During a         When conducting small-group tryouts, you should:
Tryout
                           ·Ensure that the time required for each student to complete the material is accurately
                               recorded. This information is used to determine unit times, course length, and course
                               content.
                           ·Record accuracy of student responses. This information should help determine deficiencies
                               in the instruction or materials.
                           ·Establish the number of trials a student should be permitted to meet performance
                               requirements.

                       Don't supplement the instruction. Supplementing the instruction may skew the results of the
                       tryout.


After a                Conduct a sufficient number of small-group tryouts to ensure that the data collected is both valid
Tryout                 and reliable. Once the data has been collected, it should be analyzed to determine:

                           ·Median time required to complete each segment or unit of instruction (this information is
                               used to set the approximate times for lessons, segments, units, or modules of instruction).
                           ·Need to revise equipment requirements, make changes to facilities, and adjust personnel
                               authorizations.
                           ·Instruction and materials requiring revisions or changes.
                           ·Priority for accomplishing revisions or changes and plan of accomplishment.

                       As with the individual tryout, if the instruction or materials require significant revisions or
                       changes, it is recommended that additional small-group tryouts be conducted to determine if the
                       revisions were effective.

                               Conduct Operational (Field) Tryouts

Introduction           The operational tryout, which is the only activity in summative evaluation, is the final step in the
                       validation process. This evaluation activity is conducted under normal operating conditions by an
                       instructor. Field tryouts of instruction may vary from a single block or module of instruction to an
                       entire course. The instruction to be validated will depend largely on whether it is a new course or a
                       block or two of an existing course that has been revised.

Purpose                The purposes of operational tryouts are to:

                           ·Determine if the instructional system actually works under operational conditions.
                           ·Provide feedback from a large sample of the target audience in which to base final revisions
                               or refinements to the instructional system prior to it becoming operational.
                           ·Work out any implementation or operational problems, such as equipment and facilities.
                           ·Provide feedback from field units on quality.


Student                For operational tryouts, students are selected to participate from the target population, using the
Selection              normal student scheduling process.
66                                                                              AFMAN 36-2234 1 November 1993

 Before a            Before conducting the field tryouts, ensure that:
 Tryout
                         ·Resources are available, such as equipment, facilities, and instructors.
                         ·Instruction and materials have been revised based on the results of the small-group tryouts.
                         ·Materials are available in adequate quantities.
                         ·Students have been scheduled to participate in the tryouts and have been informed of their
                             role.
                         ·Size of tryout class is compatible with operational conditions.


 During a            Conducting an operational tryout is like operating a course under normal day-to-day conditions.
 Tryout              However, when conducting operational tryouts, you should:

                         ·Ensure that instruction is conducted in the normal operating environment.
                         ·Collect validation data such as time requirements, test results, instructor and student
                             comments, and problem areas.
                         ·Use adequate data samples to ensure valid and reliable data.
                         ·Gather feedback from field on quality of course graduates.


 Collect             Operational tryout data is collected before, during, and after the instruction is provided.
 Data
                         ·Before conducting instruction, the instructional developer or instructor should:

                             ··Determine if students have met course prerequisites and identify their entry skill and
                                 knowledge level.
                             ··Collect data using such methods as pretest, oral examination, or directly asking students
                                 if they have specific skills or knowledge.

                         ·While conducting instruction, the instructional developer or instructor should:

                             ··Identify breakdowns in instruction and check student progress.
                             ··Record duration of instruction.

                         ·After conducting instruction, the instructional developer or instructor should:

                             ··Administer posttest.
                             ··Interview students.
                             ··Critique instruction.
                             ··Gather supervisors' critiques of graduates.

                     The field data collection is summarized below.


            Stage                               Data To Be Collected                                        Data Collection
                                                                                                            Methods
            Before                              ·Student entry skill/knowledge level                        ·Pretest
                                                                                                            ·Oral examination
                                                                                                            ·Student interviews
 During                                         ·Number of errors students make                             ·Observation
                                                ·Questions raised by students                               ·Recording student
                                                ·Student work samples                                            questions
                                                ·Duration of instruction                                    ·Collecting work
                                                                                                                 samples
  AFMAN 36-2234 1 November 1993                                                                                                             67
After                                                ·Student learning gains                                                 ·Posttest
                                                     ·Student views of instruction, materials                                ·Student interviews
                                                     ·Supervisor's critique                                                  ·Student critiques
                                                                                                                             ·Supervisor
                                                                                                                                  critiques


After a Tryout          When adequate numbers of operational tryouts have been conducted, you should:

                              ·Analyze data gathered during the tryouts.
                              ·Revise the instructional system as necessary.

                        As with other forms of validation, continue to try out, revise, and try out as long as the quality of
                        the instructional system is improved.



                                                 Section G
                                      Finalize Instructional Materials

Introduction            Once validation has been completed and revisions have been made, the instructional materials
                        should be finalized. During finalization, ensure that all of the last-minute changes are made to
                        the instructional materials and they are ready for use. It is important to finalize all of the materials
                        prior to implementing instruction to ensure that they are accurate and complete.

Purpose                 Finalization of instructional materials serves several purposes, which are to ensure that the
                        materials are:

                              ·Current and accurate
                              ·Complete
                              ·Ready to use in the teaching-learning activity


Who Is                  Instructional developers are normally responsible for ensuring that instructional materials are
Responsible?            updated and ready to be used when the course is implemented. However, instructional system
                        management should monitor the task, since they have overall system responsibility.

What Needs              Finalization of the instructional materials includes, but is not limited to:
To Be
                              ·Plans that have been developed, such as implementation and management plans
Updated?                      ·Course control documents, such as training standards, and POIs
                              ·Materials used in the teaching-learning activity, such as study guides and workbooks


What Should             The types and numbers of different materials that are developed for a course should determine
Be Done?                what needs to be done during finalization of the instructional materials. An easy way to ensure
                        that all materials are finalized is to develop a job aid consisting of questions on specific areas such
                        as plans or control documents. The following job aid is provided as an example.

                 Sample Instructional Material Finalization Job Aid
                 Plan

                 Validation                                                    ·Has the validation report been approved?
                                                                               ·Have necessary changes been made?

                 Implementation                                                ·Is the implementation plan complete?
                                                                               ·Does the plan include current information?
                                                                               ·Has the plan been approved?
68                                                   AFMAN 36-2234 1 November 1993

 Control Documents

                           Training Standard   ·Has the training standard been revised/changed?
                                               ·Has the training standard revision/change been approved?
                                               ·Has the training standard been published?

                                               ·Has the POI/syllabus been updated?
                           POI/Syllabus        ·Is the POI/syllabus complete?
                                               ·Has the POI/syllabus been approved?
                                               ·Has the POI/syllabus been published and distributed?
 Instructional Materials

                           Printed
                                               ·Have student workbooks been updated?
                                               ·Are student workbooks complete?
                                               ·Have student workbooks been published?
                                               ·Have the lesson plans been updated?
                                               ·Are the lesson plans complete?
                                               ·Have the lesson plans been approved and published?
                           Audiovisual
                                               ·Have the transparencies been updated?
                                               ·Are the transparencies complete?
                                               ·Are the transparencies ready for use?
                                               ·Have the slides been updated?
                                               ·Are the slides complete?
                                               ·Are the slides ready for use?
                           ICW
                                               ·Has the program been updated?
                                               ·Is the programming complete?
                                               ·Has the ICW been operationally tested?
  AFMAN 36-2234 1 November 1993                                                                                    69
                                       Chapter 7
                                   IMPLEMENTATION

Overview

Introduction      After the instruction has been validated, you are ready to implement the instructional system.
                   Once the instructional system becomes operational, it will require continuous support, mainten-
                  ance, and evaluation to ensure that it operates effectively and cost-efficiently and produces
                  graduates who meet job performance requirements.

Objectives        The objectives of this chapter are to:

                      · Discuss implementation of the system functions.
                      · Describe the activities that occur during system implementation.
                      ·Discuss the operational evaluation process.


Additional        For additional information on instructional system implementation , see:
Information
                      ·   Knirk, F. G. and Gustafson, K. L. (1986). Instructional Technology: A Systematic
                          Approach to Education. New York: Holt, Rinehart and Winston.



                                        Section A
                                Implement System Functions

Introduction      The system functions of management, support, administration, and delivery should be in place and
                  working if the instructional system is to operate effectively and cost-efficiently. System functions
                  provide the structure that supports, operates, and maintains the system.

Additional        For additional information on training system functions, see:
Information
                      ·Bills, C. G. and Butterbrodt, V. L. (1992). Total Training System Design Function: A Total
                           Quality Management Application. Wright-Patterson AFB, Ohio.
                      ·Fishburne, R. P., Williams, K. R., Chatt, J. A., and Spears, W. D. (1987). Design
                           Specification Development for the C-130 Model Aircrew Training System: Phase I
                           Report. Williams, AFB, Arizona: Air Force Human Resources Laboratory (AFHRL-
                           TR86-44).
                      ·JWK International Corp. (1990). Final Training System Baseline Analysis Report (EWOT).
                           Dayton, Ohio: JWK International Corp.
                      ·Williams, K. R., Judd, W. A., Degen, T. E., Haskell, B. C. and Schutt, S. L. (1987).
                           Advanced Aircrew Training Systems (AATS): Functional Design Description. Irving,
                           Texas: Seville Training systems (TD-87-12).



                                    Management Function

Introduction      Management is a key system function. The management function should be in place and working
                  throughout the life cycle of the instructional system from the initial planning stage on. Effective
                  management should help produce an effective instructional system.

What It Is        Management is the practice of directing, controlling, and supporting the instructional system.
70                                                                        AFMAN 36-2234 1 November 1993


 Who Is                Each level within the school or responsible organization has certain management responsibilities.
 Responsible?          For example:

                          ·   Faculty manage the teaching-learning activities.
                          ·   Instructor supervisors manage the scheduling of courses.
                          ·   Instructional developers manage instructional development.

                       In addition, other support organizations such as Resource Management and Civil Engineering
                       manage special areas that support the instructional system.


 Management            The basic activities of management are:
 Activities
                          ·Planning for the design, development, implementation, support, operation, and maintenance
                              of the instructional system.

                          ·Organizing the resources, which involves identifying, arranging, and bringing together
                             resources required for the instructional system.

                          ·Coordinating instructional system operation and support.

                          ·Evaluating the effectiveness and efficiency of each element in the instructional system.

                          ·Reporting status and progress of the development of instruction or operation of the
                             instructional system.


 Management            Following are examples of tasks performed by management in support of the instructional system.
 Tasks

                           Activity                          Examples of Tasks
                           Planning                          · Establish logistic support.
                                                             ·Identify facility requirements.
                                                             ·Plan quality improvement programs.
        Organizing                                           · Establish lines of communication between
                                                                 development team and management.
                                                             ·Schedule people, work, and resources.
        Coordinating                                         · Establish external lines of communication to
                                                                 support organizations to gain logistics,
                                                                 funding, and other support.
        Evaluating                                           · Monitor milestones, budgets, and production.
                                                             ·Collect and analyze feedback.
        Reporting                                            · Provide status briefings.
                                                             ·Report inspection findings.


                                                       Support Function

 Introduction          The importance of the instructional system support function cannot be overstressed. Without
                       adequate support, you may be unable to implement the instructional system, or, at best, its
                        operation may be ineffective and inefficient. Support is required from a wide variety of
                       instructional organizational elements in order to implement, operate, and maintain an
                       instructional system.
  AFMAN 36-2234 1 November 1993                                                                                         71

What It Is            The support function is defined as those long-range, as well as day-to-day, tasks performed in
                      order to implement, operate, and maintain an instructional system. Several examples of support
                      functions are:

                          ·Maintaining equipment and facilities
                          ·Supplying components for the equipment and materials for the courses
                          ·Providing services such as engineering, visuals, publications


Support Activities    Some of the basic support activities include:

                          ·Supplying equipment, parts, materials
                          ·Maintaining equipment, facilities
                          ·Producing instructional materials
                          ·Constructing instructional aids, facilities
                          ·Providing funding, services


Who Is                As with the other instructional system functions, managers have the responsibility for ensuring
Responsible?          that the instructional systems are adequately supported for the life cycle of the system. Support
                      for the instructional system should be provided by organizations such as:

                          ·Civil Engineering
                          ·Resource Management
                          ·Visual Services
                          ·Information Management

                      These are only a few of the many support organizations that may be needed to support the
                      implementation and operation of the instructional system.


Support Tasks         Examples of some of the tasks performed in support of the instructional system are listed below.


                 Organization                                Example of Tasks
                 Civil Engineering                           · Constructs instructional facilities.
                                                             ·Modifies existing facilities such as by adding new electrical
                                                                 outlets or air conditioning.
                 Resource                                    · Provides human resources for instructor support, and
                    Management                                   maintenance personnel.
                                                             ·Manages funds, equipment, and facilities.
                 Information                                 · Edits instructional materials such as study guides,
                     Management                                  handouts, or instructor guides.
                                                             ·Publishes instructional materials.
Contracting                                                  · Develops contracts for maintenance and other services.
                                                             ·Processes local purchase forms to procure supplies and
                                                                 equipment.
Maintenance                                                  · Performs quality improvement inspectio ns on
                                                                 instructional, support, and test equipment.
                                                             ·Performs scheduled and unscheduled maintenance on
                                                                 instructional, support, and test equipment.
                                                             ·Fabricates trainers.
72                                                                                 AFMAN 36-2234 1 November 1993

                     Visual                                       · Develops and controls visual materials such as slides
                        Information                                  and film strips.
                                                                  ·Manages visual equipment such as televisions, VCRs, and
                                                                     slide projectors.


 Relationship to           Implementing and operating an instructional system requires a great deal of planning and
 Implementation            preparation. Part of that effort is to ensure that the necessary support functions are available.



                                            Administration Function

 Introduction              The administration function conducts the day-to-day operation of the instructional system. As
                           managers and instructional developers, you should be aware of all the administrative activities that
                           are performed on a daily basis by the various instructional organizations in support of the
                           instructional system.

 What It Is                Administration is the part of management that performs day-to-day tasks such as maintaining
                           documentation, typing reports, keeping equipment, supply, and other records, and maintaining
                           student records.

 Administrative            The basic administrative activities that support the instructional system are:
 Activities
                               ·Providing documents, such as instructional standards, plans of instruction, and student
                                   workbooks.
                               ·Maintaining records, such as personnel and instructional equipment.
                               ·Administering student support, such as processing students "in" and "out" of the site.
                               ·Administering staff support, such as leave processing and maintenance of personnel
                                   programs.
                               ·Scheduling resources, such as personnel, equipment and facilities.
                               ·Monitoring resources, such as equipment and funds.


 Who Is Responsible? Managers have the responsibility of ensuring that the administrative activities are performed in
                           support of the instructional system. However, various instructional organizations have specific
                           responsibilities to support system operations. For example, some of the organizational elements
                           that may be engaged in administration are:

                               ·Registrar
                               · Typing pool
                               ·Staff support elements
                               · Student support elements
                               ·Information management
                               ·Contract office (if fees are required)


 AdministrativeTasks Examples of some of the tasks that the various organizational elements perform are listed below.

                                    Organizational Element               Examples of Tasks
                                    Registrar                            ·Track student entries.
                                                                         ·Maintain student status.
                                                                         ·Print and distribute status reports.
  AFMAN 36-2234 1 November 1993                                                                                             73
                                   Typing Pool                     ·Type course control documents.
                                                                   ·Type course materials.
                                                                   ·Type reports.
                                   Student Support                 ·Process students "in" and "out" of the responsible
                                                                       instructional organization.
                                                                   ·Maintain student health and welfare programs.
                                   Information Management          ·Edit instructional materials.
                                                                   ·Publish instructional materials.
                                                                   ·Maintain supply of instructional materials.
                                   Staff Support                   ·Provide administrative support for instructional
                                                                       staff, such as processing leaves.
                                                                   ·Administer programs such as suggestion, or
                                                                       awards and decorations.

Relationship              The instructional system administration functions should be in place and functioning if the
to Implementation         instructional system is to be successfully implemented. For the instructional system to work,
                          materials need to be printed and distributed, students scheduled and tracked, and health and
                          welfare concerns addressed. The support, operation, and maintenance of instructional systems
                          depend on these and other administration functions.

                                               Delivery Function

Introduction              In the design and development phases of ISD, appropriate delivery methods were selected and
                          developed to deliver instruction to the students. Prior to implementing the instructional system,
                          management should ensure that the delivery function is ready to support the operation of the
                          system.

What It Is                The instructional system delivery function is the means by which instruction is provided to the
                          students. Examples of delivery methods are:

                              ·Instructors
                              ·Computers, which includes ICW, CAI, CMI
                              ·Training devices, including simulators, part-task trainers
                              ·Satellite
                              ·Job aids
                              ·Career development and specialized courses
                              ·Correspondence programs, such as Extension Course Institute (ECI) and Professional
                                  Military Education (PME)


Who Is Responsible? The individuals responsible for the instructional delivery function are:
                              ·   Managers - Ensure that adequate planning and analysis have been done prior to selecting
                                  the delivery method and, once the method is selected, see that it is supported.
                              ·   Instructional developers - Select the most appropriate delivery method(s).
                              ·   Instructional staff - use and evaluate the selected delivery method(s) for effectiveness.
74                                                                         AFMAN 36-2234 1 November 1993

 Ensuring Readiness   At this point, the delivery function should be fully developed and operational. Validation should
                      have given an indication of the suitability and readiness of the delivery system; however, prior to
                      implementing the instructional system you should "check it out" to be sure that everything is
                      ready. You need answers to questions about the delivery function, such as:

                          ·Are there adequate instructors to support the instructional requirements?
                          ·Have the instructors been qualified, and are they certified to deliver the instructions?
                          ·Are the student workbooks printed in adequate numbers?
                          ·Is the necessary equipment available and operational, such as computers, projectors,
                               simulators?
                          ·Has the programming of the ICW been completed?
                          ·Have slides and/or transparencies been produced?



                                              Section B
                                          Conduct Instruction
 Introduction         At this point in the ISD process, the instructional system has been developed, and the instructional
                      system functions are in place and ready to support implementation of the instructional system. It
                       is now time to conduct the instruction.

 Additional           For additional information on conducting instruction, see AFMAN 36-2236.
 Information

 Introduction         Before you actually start conducting instruction, "last-minute checks" need to be made to ensure
                      that the instructional system is ready to implement.

 Why Make             Adequate preparation throughout the instructional development process and these last-minute
 Preparations?        checks before starting to conduct instruction ensure that each instructional system component is
                      ready. These checks are also a quality assessment of the development process and an evaluation
                      of the ISD application to this point.

 Who Is               Everyone involved in the support, operation, and maintenance of the instructional system has
 Responsible?         responsibilities for making final preparations to conduct instruction. This includes:

                         ·Managers
                         ·Instructional developers
                         ·Instructors
 AFMAN 36-2234 1 November 1993                                                                                75
What Should    During final preparations to conduct instruction, each component   of the instructional system
Be Checked?    should be checked "one last time" to ensure that everything is ready. Some of the items to be
                        checked are:

                            ·Equipment

                                ··Is instructional, support, and test equipment available?
                                ··Is the equipment available in adequate quantities?
                                ··Is all equipment operational and ready to use?
                                ··Is logistics support, such as spare parts and maintenance, available?

                            ·Facilities

                                ··Are the necessary instructional facilities available?
                                ··Have all necessary facility modifications been completed?

                            ·Human Resources

                                ··Are adequate personnel, including instructors, maintenance personnel, and students,
                                    available to conduct the instruction?
                                ··Are the instructors qualified to conduct the instruction?
                                ··Are maintenance and support personnel properly trained?
                                ··Have instructors and students been scheduled for classes?

                            ·Funds

                        ··Have adequate funds been programmed to conduct the instruction, including funds for
                        personnel, facilities, equipment, and fees?

                                Time

                                ··Did instructional developers have adequate time to design and develop an effective and
                                    efficient instructional system?
                                ··Did the instructional staff have adequate time to prepare to conduct the instruction?

                            ·Materials and Supplies

                                ··Are the instructional materials available in adequate quantities?
                                ··Are adequate instructional and office supplies available to conduct instruction?



                                       Guidelines for Conducting Instruction

Introduction            At this point in the ISD process, you have made the final check of each component in the
                        instructional system to ensure that everything is ready for implementation of the instructional
                        system. If everything has checked out, there should be relatively few problems when you start
                        instruction.
76                                                                      AFMAN 36-2234 1 November 1993

 Who Is           Managers of the instructional system have the overall responsibility for providing the instruction;
 Responsible?     however, all individuals who play a role in conducting instruction share in the responsibilities.
                  Some of these individuals are:

                      ·Managers - have overall responsibility for managing the support, operation, and
                           maintenance of the instructional system.
                      ·Instructional developers - have responsibility for ensuring that deficiencies identified
                           during system operation are corrected.
                      ·Instructional staff - have responsibility for conducting the instruction and evaluating
                           student performance.
                      ·Instructional evaluators - have continuing responsibility for evaluating a graduate's Air
                           Force performance throughout the life cycle of the instructional system.
                      ·Support organizations - have responsibility to provide logistic support and services
                           necessary to conduct instruction.



 Conducting the   Once the instructional system is implemented, it should continue to operate until there is no
 Instruction      longer a need for the course, or the course is revised to the point that it is given a new
                  identification. Throughout this time there are ongoing activities that ensure system integrity.
                  Some of them are listed below.

                      ·Resource management is probably the single most critical issue for managers of the
                          instructional system as well as the instructional staff. Every resource should be
                          managed effectively and efficiently. For example:

                           ··Students should be scheduled for instruction in a timely manner so time is not wasted.
                           ··Instructors, when not in the teaching-learning activity, should be utilized to work on
                                     course-related items, such as writing test items for the test item pool, or posting
                                     changes to instructional materials.
                           ··Managers should continually check to ensure that the necessary equipment is available
                                     in sufficient quantities and is maintained in an operational status. Unneeded
                                     equipment should be returned to supply or to the lender, if borrowed.

                  ·Conduct of instruction is fundamental to system integrity. No matter what has been done to
                  this point, the system can fail if the instruction is not properly conducted. To ensure that
                  instruction is both effective and efficient, remember:

                                ·· Instruction should always be student-centered. Never allow instruction to be
                           focused on the method or media.
                           ··Instruction should always be delivered in a professional manner regardless of the
                                     media.

                      ·Evaluation of the process and products of each phase of ISD ensures that the quality of the
                          system is continually maintained. While the instructional system is operational, periodic
                          operational evaluations ensure the quality of the instructional system.

                      ·Staff development is an ongoing activity during the conduct of instruction. Instructional
                          developers and instructors should periodically attend staff development sessions to
                          ensure that they continue to develop professionally and technically. This should help
                          ensure the effectiveness of the instructional system.



                                       Section C
                              Conduct Operational Evaluation
  AFMAN 36-2234 1 November 1993                                                                               77
Introduction    After the instruction is validated, a summative evaluation has been completed, and the system
                        functions are in place, the instructional system is ready for implementation. Once the system is
                        implemented and starts producing graduates, it is time to begin conducting operational
                        evaluations. Operational evaluation is a continuous process that assesses how well course
                        graduates are meeting the established job performance requirements.

Objectives              The objectives of this chapter are to:

                            ·    Describe the operational evaluation process.
                            ·    Explain internal evaluation.
                            ·    Explain external evaluation.



Introduction            Evaluation is a continuous activity that is integrated throughout each stage of ISD, beginning
                        with analysis and continuing throughout the life cycle of the system. Its focus is quality
                        improvement. The last stage of the evaluation process is operational evaluation.

What It Is              Operational evaluation is the continuous process of gathering and analyzing internal and
                        external feedback data to ensure that the system continues to effectively and cost-efficiently
                        produce graduates who meet established requirements. It is a quality improvement activity.

Purpose                 The two main purposes of operational evaluation are to:

                            ·    Ensure that graduates continue to meet established job performance requirements.
                            ·    Continually improve system quality.



What Should You         When evaluating, look for both strengths and weaknesses in the system. Focus on:
Look For?
                            ·How well the graduates are meeting job performance requirements.
                            ·Whether instruction is being provided that is not needed.
                            ·Whether any needed instruction is not being provided.
                            ·How well each system component is contributing to overall system quality.
                            ·Ways to improve the graduate's performance as well as the system.



Operational             The two operational evaluation activities are:
Evaluation
                            ·    Internal evaluation - gathers and analyzes internal feedback and management data
Activities                       from within the training environment to assess the effectiveness and quality of the
                                 instructional process. Internal evaluation data is normally gathered by the instructional
                                 developers and instructors.

                            ·    External evaluation - gathers and analyzes external feedback data from the field to
                                 assess graduates' on-the-job performance in an operational environment. Most external
                                 evaluation data is gathered by evaluators from the organization providing the
                                 instruction or is provided by the graduates and their supervisors directly from the field.
                                 However, in some cases, external evaluation data is gathered and provided to the
                                 organization by both Air Force and non-Air Force consultants, advisory bodies, Board
                                 of Visitors, accrediting agencies, and professional certification groups.
78                                                                           AFMAN 36-2234 1 November 1993

 Additional            For additional operational evaluation information, see:
 Information
                           ·    AFMAN 36-2236.
                           ·    Briggs, L. J. and Wager, W. W. (1981). Handbook of Procedures for the Design of
                                Instruction (2nd Ed.). Glenview, Illinois: Harper Collins Publishers.



                                            Internal Evaluation
 Introduction          Internal evaluation activities begin with implementation of the instructional system and
                       continue throughout the life cycle of the instructional system. Some organizations call this
                       evaluation activity a "course review." Internal evaluations look at the instructional system from
                       within to determine system effectiveness and quality.

 What It Is            Internal evaluation is the acquisition and analysis of internal feedback and management data,
                                 such as test data, student critiques, instructor comments, and data correlation from
                                 within the instructional system.

 Purpose               The purpose of internal evaluation is to improve the effectiveness and quality of the
                               instructional system.

 Possible Causes for   Although instructional systems are validated prior to implementation, students may still have
        Problems       difficulty with the instruction during day-to-day system operation. Possible causes of student
                       problems are:

                           ·Instructors do not follow the POI or course syllabus.
                           ·The developed course is different from the course that is actually implement ed.
                           ·Resources required to support, operate, and maintain the system are inadequate.
                           ·Instructional materials are not correlated.
                           ·Students do not meet course prerequisites.

                       Periodic internal evaluations may identify weaknesses (problems) as well as strengths of the
                       instructional system.



 Data Collection       Several methods of collecting internal evaluation data are listed:


                   Data Collection Method                                        Purpose
                   Review Course Control                                         · To determine if there are any
                   Documents                                                        discrepancies between the planned
                                                                                    course and the course that was
                                                                                    actually implemented.
 AFMAN 36-2234 1 November 1993                                                                                                79
Review Resources                                                                      · To ensure that facilities (instructional
                                                                                          and support) are available and
                                                                                          adequately maintained.
                                                                                      ·To ensure that equipment (instructional,
                                                                                          support, and test) and supplies are
                                                                                          available.
                                                                                      ·To ensure that human resources
                                                                                          (instructional developers, instructors,
                                                                                          students, and mainte nance personnel)
                                                                                          are available.
                                                                                      ·To ensure that there is adequate time
                                                                                          (adequate course length, sufficient
                                                                                          time to maintain the course).
                                                                                      ·To ensure that funds are adequate to sup-
                                                                                          port, operate, and maintain the course.
Visit Instructional Facilities                                                        · To evaluate the quality of
                                                                                          implemented instruction (ensure that
                                                                                          the visit is long enough to ensure
                                                                                          observation of representative
                                                                                          instruction).
                                                                                      ·To check equipment, instructional media,
                                                                                          training aids and devices for
                                                                                          condition, operation, and
                                                                                          appropriateness.
                                                                                      ·To check instructional literature such as
                                                                                          study guides and workbooks for
                                                                                          quality and availability.
Evaluate Instructor Performance                                                       · To check if instructor follows the plan
                                                                                          of instruction, uses instructional
                                                                                          media properly, responds to student
                                                                                          needs, and is qualified to teach.
                                                                                      ·To check instructor evaluation forms to
                                                                                          determine if noted weaknesses have
                                                                                          been corrected.
Monitor Measurement Program                                                           · To check the measurement program
                                                                                          for compromise. If a test has been
                                                                                          compromised,
                                                                                          it cannot provide useful feedback.
                                                                                      ·To monitor the measurement program to
                                                                                          ensure quality.
                                                                                      ·To evaluate instruction in terms of
                                                                                          student performance. Use
                                                                                          performance mea sures to determine
                                                                                          students' achievement of objectives.


Conducting an                Collect sufficient internal evaluation data for the analysis. Insufficient data may skew the
     Internal                         analysis results, possibly leading to incorrect decisions being made. Job aids can be
                                      used to gather internal evaluation data. An example of a job aid is provided below.
     Evaluation

                                      Check        Data Source
                                                   · Does the POI/course syllabus reflect the operational course?
                                                   · Is the POI/course syllabus current and accurate?
                                                   · Does the POI/course syllabus provide adequate guidance?
                                                   · Do the lesson plan and POI/course syllabus agree?
                                                   · Does the lesson plan reflect what is being taught in the course?
80                                                                     AFMAN 36-2234 1 November 1993

                                         ·   Is the lesson plan current and accurate?
                                         ·   Do instructional materials support the lesson plan and POI?
                                         ·   Do instructional facilities meet system requirements?
                                         ·   Do support facilities meet system requirements?
                                         ·   Does training equipment meet system requirements?
                                         ·   Is the instructional equipment adequately maintained?
                                         ·   Does support equipment meet system requirements?
                                         ·   Are instructors teaching according to the lesson plan?
                                         ·   Are instructors oriented and trained to execute the courses, i.e.,
                                             have they been given the "big picture"?
                                         ·   Are they adequately trained?
                                         ·   Do tests adequately measure the objectives?
                                         ·   Is the test data thoroughly analyzed?
                                         ·   Can improvement be made in the course?

 Student Reaction   The following is an example of a questionnaire designed to obtain student feedback.
     AFMAN 36-2234 1 November 1993                                                                                           81
STUDENT REACTION TO INSTRUCTION

PERIOD_____________________________________________________________________
DATE_________________________________

INSTRUCTOR_________________________________________________________STUDENT_____________________________
____ ______

One way instruction is improved is by sampling student reaction to the instruction. Please answer the following questions.

1.    Prior to this instruction, my experience in this area was
           __________ extensive
           __________ moderate
           __________ little or none

2.    Did your knowledge of the subject increase as a result of the instruction?
           __________ yes
           __________ no

3.    If your knowledge increased as a result of the instruction, to what extent did it increase?
           __________ not applicable (my knowledge didn't increase)
           __________ slightly
           __________ moderately
           __________ extremely

4.    Based on my experience, the level of instruction was
          __________ too advanced
          __________ about right
          __________ too elementary

5.    The organization of the instruction was
           __________ very helpful
           __________ helpful
           _________ not very helpful

6.    The lecture outline (main points of instruction) was
           __________ very helpful
           __________ helpful
           __________ not very helpful

7.    Audiovisual aids were
          __________ of great value
          __________ valuable
          __________ of little or no value
          __________ not used, but could have helped
          __________ not used and not needed

8.    Answers to student questions were
          __________ meaningful
          __________ somewhat helpful
          __________ not helpful
          __________ not applicable (no questions asked)

9.    Should the subject matter covered be changed?
          __________ yes (please explain below)
          __________ no

10. Should the method of instruction be changed?
        __________ yes (please explain below)
        __________ no

11. Overall, the instruction was
          __________ outstanding
          __________ good
          __________ fair
          __________ poor
12. Instruments (including tests) to evaluate student performance were
          __________ outstanding
          __________ good
          __________ fair
          __________ poor

COMMENTS, EXPLANATIONS, OR RECOMMENDATIONS
82                                                                     AFMAN 36-2234 1 November 1993


 Data Analysis   Before beginning analysis of the data, ensure that:

                     ·Data have been collected from each component of the instructional system.
                     ·Adequate data samples are collected in order to validate the reliability of the findings.

                 Following are some methods of analyzing the internal evaluation data.

                     ·Compare the instructional standard with the POI/course syllabus to determine if the
                         requirements of the standard are being met.
                     ·Compare POI/course syllabus with operational course to determine if the planned and
                         operational courses are the same.
                     ·Review POI/course syllabus, lesson plan, and instructional material to determine if they
                         are current, adequate, and in agreement.
                     ·Compare stated resource requirements with actual resources to determine if adequate
                         resources are available to support, operate, and maintain the instructional system.
                     ·Review records to determine if instructors are qualified to teach the course.
                     ·Review test data to ensure that students are meeting course objectives.
                     ·Analyze test data to determine if test items are valid and reliable.



 Revising the    After internal evaluation data are collected and analyzed, the next stage is to correct
 Instructional   deficiencies in the instructional system. If revisions can be made to correct identified
                 problems, they should be made in a timely manner in order to receive the greatest benefit from
 System          the changes.

                 Revisions resulting from the analysis may require reentry into an earlier phase of the ISD
                         process to correct the problem(s). The need to reenter an earlier phase of ISD is
                         determined by the nature and scope of the revision. For example, changing a test
                         item or adding time to a unit of instruction would not require you to reenter an earlier
                         phase of ISD. However, adding a new piece of equipment to the course would more
                         than likely require you to do so.

                                      External Evaluation

 Introduction    How well graduates meet job performance requirements is learned through external
                        evaluation. This evaluation activity relies on input from the field to determine how
                        well graduates are performing.

 What It Is      External (field) evaluation is the process of gathering and analyzing data from outside the
                          instructional environment in order to determine how well recent graduates are
                          meeting job performance requirements.

 Purpose         The purpose of external evaluation is to determine if recent graduates of the course:

                     ·Can meet job performance requirements.
                     ·Need all of the instruction they received.
                     ·Need any instruction they did not receive.
 AFMAN 36-2234 1 November 1993                                                                                             83
Possible Causes for Some possible problems that may be identified during external evaluations are:
       Problems
                             ·Criterion test did not measure graduates' ability to meet job performance requirements.
                             ·Objectives do not reflect job performance requirements.
                             ·Job performance requirements were incorrectly identified during task analysis.
                             ·Job performance requirements changed after task analysis.



   Collecting Data           Several methods of collecting external evaluation are listed below.


                    Methods of External Evaluation
                    Questionnaires
                    Field Visits
                    Job Performance Evaluation
                    Other Sources of Evaluation Input

                                                            Questionnaires



   Introduction          Questionnaires are effective, cost-efficient evaluation tools. The discussion on questionnaires
                         will focus on:

                             ·Advantages and disadvantages of questionnaires
                             ·Types of questionnaires
                             ·How to prepare and distribute questionnaires
                             ·Analysis of data gathered using questionnaires



   Purpose               The purpose of using questionnaires is to:

                             ·Determine the ability of recent graduates to perform specific tasks on which they received
                                 instruction.
                             ·Identify the specific nature of any deficiency.
                             ·Determine what tasks are actually being performed by graduates.
                             ·Identify what instruction is not needed for on-the-job performance.



   Advantages            Advantages of questionnaires include:

                             ·They are comparatively inexpensive to administer.
                             ·They can be used to collect large samples of graduate and supervisor data.
                             ·They yield data that can be easily tabulated and reported.
                             ·Respondents give their opinions freely.
84                                                                           AFMAN 36-2234 1 November 1993

     Disadvantages       Disadvantages of questionnaires include:

                             ·They may not be the most reliable form of evaluation; data validity depends on
                                 preparation and distribution.
                             ·Communication is one-way; respondents may not understand some of the questions.
                             ·They may not ask the most relevant questions.
                             ·They collect only opinions, which may not be as reliable as other methods of collecting
                                 external data.
                             ·Developing effective and reliable questionnaires may be costly and require extensive
                                 experience.
                             ·Low return rates and inappropriate responses affect accuracy.



 Types of                Two types of questionnaires can be used to collect external evaluation data:
   Questionnaires
                             ·One is for the graduates' immediate supervisor. However, responding may be delegated
                                 to the graduates' trainer.
                             ·The other questionnaire is for the graduates. This questionnaire is designed to find out
                                 what graduates think about the instruction they received.

     Preparing               Well-constructed questionnaires that are properly administered are extremely important to
     Questionnaires             the field evaluation process. The following table identifies the five basic stages of
                                questionnaire development.

                 Stage                                Activity
                 Stage 1                              · Define purpose of questionnaire. Focus only on rele vant
                                                         information.
 Stage 2                                              · Determine specific information to be collected. Spec ify
                                                         exactly what is needed in a list of objectives.
 Stage 3                                              · Develop questions that ask for specific informa tion such as:
                                                         ··What conditions/equipment are required to do the job.
                                                         ··Exact action to accomplish the performance.
                                                         ··Standards of performance.
                                                         ··Results of the performance.
 Stage 4                                              · Consider motivational factors when developing question-
                                                         naires. You want the respondents to answer fully and
                                                         conscientiously. Questionnaires should motivate if you:
                                                         ··Explain the purpose of the questionnaire.
                                                         ··Tell the respondents how they can benefit from answer ing
                                                             the questionnaire.
                                                         ··Write clear and concise instructions.
                                                         ··Make questionnaire format uncluttered and easy to answer.
                                                             For example, using boxes for check marks should make
                                                             the questionnaire easier to answer.
                                                         ··Arrange the questionnaire in logical order.
                                                         ··Ask specific questions.
 Stage 5                                              · Test the questionnaire on sample respondents. Ask them to:
                                                         ··Evaluate the cover letter.
                                                         ··Check instructions and questions for clarity.
                                                         ··Explain how they feel about answering the questions.
                                                      ·Revise the questionnaire, if necessary, before distribution.
                      Note: Questions can be taken directly from the task statements in the standard.
AFMAN 36-2234 1 November 1993                                                                                      85

 Guidelines for   Guidelines for developing effective questions are:
   Developing
                      ·Use closed-end questions when you want the respondent to choose answers from a small
   Questions              number of possibilities. This makes tabulation easy but may not give the range of
                          answers desired.
                      ·Use open-end questions when you don't know all the possible answers. The respondent
                          will probably sug gest possibilities.
                      ·Word questions to the respondent's level of understanding. Use vocab ulary and concepts
                          that are easy for the respondent to understand.
                      ·Limit each question to one aspect of a topic.
                      ·Decide on the logical order of the questions (task order, general to specific). Each question
                          increases the respondent's frame of reference and further estab lishes upcoming
                          responses.
                      ·Avoid questions that make it easier to answer one way or another.
                      ·Avoid questions that show biases or exceptions.
                      ·Word questions so they will not threaten the respon dents.
                      ·Supplemental "information-seeking" questions may be used. Such questions may ask how
                          much time the gradu ate spends on individual tasks or what equipment or materials the
                          graduate uses.



 Guidelines for   When constructing a questionnaire, several guidelines should be considered.
 Constructing
                      ·Provide short, concise, and specific directions for completing the questionnaire. The
 Questionnaires           directions should be printed in heavy, bold type, if possible.
                      ·Provide space for the respondent's name, title, organization, and location.
                      ·Number the questionnaires to allow for administrative control.
                      ·Whenever possible, allow the respondent to use the same type marking for all questions.
                          For example, one of the best methods is to allow use of check marks for responses.
                      ·Arrange "yes" and "no" responses vertically rather than horizontally.

                              Yes                 Yes      No
                              No
                              Correct             Incorrect

                      ·Provide clear verbal descriptions when using rating scales. For example:

                              How many times have you attended faculty and staff development training in the
                              past year?

                                  0               7-9
                                  1-3                   10-12
                                  4-6                   13 or more

                      ·Number each page of the questionnaire.
                      ·The questionnaire should be easy to read and mark.
                      ·Print on both sides of the pages to conserve materials, if possible.
                      ·Send self-addressed return envelope with the questionnaire.
                      ·Fold the questionnaire in such a manner that the respondent can refold it the same way to
                          place it in the return envelope after completion.
86                                                                           AFMAN 36-2234 1 November 1993

     Guidelines for     Each questionnaire should have a cover letter. When developing the cover letter, ensure that
     Preparing          it:
     Cover Letters          ·Explains the purpose of the questionnaire and its importance to improving instruction.
                            ·Includes a statement which assures the respondent that the information will be treated
                                confidentially.
                            ·Includes a statement that the evaluation is being conducted per AFI 36-2201.
                            ·Provides information on how to return the questionnaire.
                            ·Indicates the approximate time required to complete the questionnaire.
                            ·Shows the date the questionnaire was mailed and the recommended return date.
                            ·Uses appropriate letterhead stationery signed by a responsible authority.



 Before You             Before distributing the questionnaire, it should be administered to a small number of selected
 Distribute the         individuals to:
    Questionnaire           ·Provide valuable feedback on the quality of the questionnaire.
                            ·Preclude acquiring misinformation resulting from administration of a faulty questionnaire.
                            ·Allow correction of problems in the questionnaire before distribution.

     Distribution of    Distribution of the questionnaire is a critical aspect of external evaluation; you just don't pick
     Questionnaires     a few graduates' names and drop a questionnaire in the mail to them. You plan the distribution
                        to ensure that the data collected is valid and reliable. When distributing the questionnaire, you
                        should:

                            ·Decide to whom you are sending the questionnaire— a recent graduate, his or her
                                supervisor, or both. You may collect important information from both.
                            ·Select a representative sample to ensure valid results. Graduates may perform different
                                tasks or their job requirements may vary depending on the major command,
                                geographic location, or organization level. Therefore, questionnaires should be
                                distributed to each area as evenly as possible.
                            ·Determine how many questionnaires you need to mail out. That decision is based on:
                                ··Expected response rate.
                                ·· Level of confidence (a statistical consideration whi ch means the size of the sample
                                    required for you to be, say, 95 percent sure the sample truly represents the larger
                                    population). The graduate sampling chart on the following page shows how to
                                    determine the number of questionnaires you need based on this consideration.

                        Decide when to distribute the questionnaires. Timing is critical. Usually, questionnaires
                        should be sent to the graduates within three to six months after graduation. Beyond six
                        months, it may be impossible to tell whether the graduate learned the skill or knowledge in the
                        course, or on the job. If the questionnaire is sent too early, the graduate may not have had time
                        to perform many of the tasks that were taught in the course.

                            Note: To ensure that sufficient numbers of the questionnaires are returned for analysis,
                                  contact nonrespondents and encourage their response.

                                            GRADUATE SAMPLING CHART
 Course Graduates
 (During Sampling      Sample Size                  Sample Size                  Sample Size
 Period)               95% Confidence*              90% Confidence               80% Confidence
 AFMAN 36-2234 1 November 1993                                                                                          87
10                 10                                     10                              9
20                 19                                     19                              18
40                 36                                     35                              32
60                 52                                     49                              44
80                 67                                     62                              54
100                80                                     73                              62
120                92                                     83                              69
160                114                                    101                             81
200                133                                    115                             90
250                154                                    130                             99
300                171                                    142                             106
350                187                                    153                             112
400                200                                    161                             116
450                212                                    169                             120
500                222                                    176                             123
600                240                                    186                             129
700                255                                    195                             133
800                267                                    202                             136
900                277                                    208                             139
1,000              286                                    213                             141
1,500              316                                    229                             148
2,000              333                                    238                             151
2,500              345                                    244                             154
3,000              353                                    248                             155
3,500              358                                    251                             157
4,000              364                                    253                             157
4,500              367                                    255                             158
5,000              370                                    257                             159
10,000             383                                    263                             161
25,000             394                                    268                             163
100,000            398                                    270                             164
HOW TO USE THIS TABLE:

1. The table can be used as shown in the following example:

    Annual course production is 4,000 - 95% confidence level desired.* Estimated return rate of usable questionnaires
    is 85%. From the table, 364 usable questionnaires are required. Therefore, this figure should be 85% of the
    questionnaires to mail out. The number of questionnaires to mail is computed as follows:

     85% = 364
    100% X

    X = 364 x 100 = 428 = number of questionnaires to mail
          85

    *   It is recommended that the 95% confidence level be chosen. This is the level commonly used in business and
        education decisions.
88                                                                         AFMAN 36-2234 1 November 1993

     Data Analysis   When a sufficient number of completed questionnaires have been returned, you should begin
                     analyzing the data. In this process, the data is:

                         ·Compiled
                         ·Collated
                         ·Analyzed (data from each command should be analyzed together)

                     Pay special attention to:

                         ·Notes made by respondents on the questionnaires
                         ·Answers to supplemental questions that were included in the question naire

                     Use with caution any data that contains such obvious errors as:

                         ·Halo effect - indiscriminate rating of all items positively
                         ·Central tendency - indiscriminate rating of items in the center of the scale

                     Examine the responses to ensure, insofar as possible, that the information accurately reflects
                     the opinion of the graduates and their supervisors.



 Reporting the       After completing data analysis, the findings should be reported. The report should include
   Findings          information such as:

                         ·Background information on the course that was evaluated
                         ·Scope of the evaluation
                         ·Tasks evaluated
                         ·Analysis results
                         ·Recommendations
                         ·Milestones for corrective actions, if applicable

                     Now that the report is complete, your last action is to distribute the report.


                                                 Field Visits

 Introduction        Field visits are a very effective method of conducting external evaluations. They are normally
                     conducted by an evaluator, often assisted by an instructional developer or instructor. Ideally, field
                     visits should include specialists who are familiar with the graduates' jobs. However, in most cases
                     this is not possible due to limited TDY funds, scheduling constraints, and number and variety of
                     graduates to be interviewed.

 Purpose             The purpose of a field visit is to get first-hand information on the graduates' assignment,
                     utilization, and proficiency on the job, and to validate information gained from other evaluation
                     activities.
 AFMAN 36-2234 1 November 1993                                                                                        89
Advantages     Advantages of field visits are:

                        ·Guidance and information about the evaluation are given directly to graduates and
                             supervisors.
                        ·Information is gathered first-hand by the evaluator. Any questions or assumptions can be
                             clarified.
                        ·Field visits help validate questionnaire data.
                        ·External evaluations build rapport between the instructional activity and the user.
                     ·Additional information can be gained by observing nonverbal messages and asking leading or
                     probing questions.

Disadvantages        Disadvantages of field visits are:

                         ·They are time-consuming. Travel to several different bases requires consider able time.
                             Interviews and observations also require a lot of time if they are done correctly.
                         ·The sample is limited. Since the evaluator only goes to a few bases, the number of interviews
                             and observations conducted is limited.
                         ·The cost is high. Field visits require evaluators to spend limited TDY funds to travel to the
                             various bases.
                         ·Information gathered by the evaluator can be subjective and biased.
                         ·Graduates may feel they are being scrutinized.
                         ·Evaluators are not always skilled at interviewing and observing.



Data Collection      Two methods of collecting data are:

                         ·Interviews
                         ·Observations

                     Evaluators should interview recent graduates and their supervisors and observe the graduates' on-
                     the-job performance when possible. However, observations are almost useless unless the observer
                     is familiar with the tasks being performed.



Preparing for        Visits to the field to collect evaluation data should be adequately planned. Adequate planning
the Field Visit      should ensure that useful data is gathered. To prepare for the visit, you should:

                         ·Develop a list of questions to get honest, pertinent answers and to keep the discussion
                             focused.
                         ·Determine the bases to be visited.
                         ·Establish the schedule for the visit.
                         ·Select the individuals to be interviewed and observed.
90                                                                     AFMAN 36-2234 1 November 1993

 Conducting the   The following are some of the tasks to be performed during the field visit.
 Field Visit
                      ·Inform graduates and supervisors of the purpose of the visit. Tell them that their answers
                           will furnish valuable information for improving the instruction.
                      ·Interview the recent graduates and their supervisors. Supervisors should have the same
                           specialty experience or, in the case of aircrew members, the supervisor should be their
                           flying supervisor.
                      ·Determine the graduates' proficiency.
                      ·Determine how the skills learned during instruction are being used.
                      ·Find out how the graduates are progressing on OJT.
                      ·Guide the interviews with your list of questions. (As the interview progresses, you may need
                           to add, delete, or revise questions.)
                      ·Take accurate and complete notes, especially on information that is freely given.
                      ·Have the supervisor rate the graduates' performance.
                      ·Observe graduates perform tasks. (This may not be beneficial if the evaluator does not have
                           job or task knowledge.) Take careful notes on the graduates' performance. After the task
                           has been completed, ask questions to clarify actions taken by the graduates during task
                           performance.



 Data Analysis    Data collected from interviews and observations is analyzed in the same manner as
                  questionnaires— that is, compiled, collated, and analyzed by major command.

 Reporting the    The results of the field visits and questionnaires should be combined and compared in order to
 Findings         validate the findings. The analysis results of the questionnaires and field visits are compared in
                  order to validate the findings.

                                 Job Performance Evaluation

 Introduction     Job performance evaluations are accomplished jointly by the instructional activity and the using
                  command in the operational environment, at representative Air Force bases.

 Purpose          The purpose of job performance evaluations is to determine how well recent graduates meet the
                  using command's job performance requirements.

 Advantages       Advantages of job performance evaluations are:

                      ·Evaluations are conducted on the job by the supervisor.
                      ·Evaluations are very thorough.
                      ·The supervisor submits reports on a weekly basis, which ensures an accurate assessment of
                          the graduates' performance.
                      ·Data can be used to validate other forms of field evaluations.



 Disadvantages    Disadvantages of job performance evaluations are:

                      ·It usually takes eight to ten weeks to conduct the evaluation.
                      ·The supervisor reports progress weekly.
                      ·The evaluator makes at least two TDYs to each base.
                      ·The sample is limited.
                      ·They normally focus on a single command.
 AFMAN 36-2234 1 November 1993                                                                                            91
Data Collection Data is collected via field reports submitted by the supervisor to an evaluation element for
                         analysis. These reports "recap" the progress made during the previous week.

Preparing for            As with any evaluation method, you should make adequate plans before starting. Planning tasks
the Evaluation           include:

                             ·Selecting recent graduates and their supervisors to participate in the job performance
                                  evaluation.
                             ·Meeting with the supervisor and the graduates to explain job performance evaluations and
                                  getting the supervisor's commitment to support the evaluation.
                             ·Determining tasks to be evaluated based on the training standard. The criteria of
                                  performance is the training standard.
                         ·Establishing evaluation milestones.

Conducting               Once the participants have been selected and briefed on the process and its importance, it is time
Job Performance          to begin the evaluation. The evaluation consists of the following activities:
Evaluations                  ·The supervisor evaluates and records the graduates' performance on each task performed.
                             ·The supervisor reports, on a weekly basis:

                                 ··Tasks performed
                                 ··Frequency of performance
                                 ··Time required to perform the tasks
                                 ··Equipment used


Data Analysis and        When the evaluator receives the job performance reports from the supervisor, they are analyzed to
Reporting                determine how well the graduates are performing the tasks they were taught during the course.
                         Evaluators should watch for reports that indicate the graduate:

                             ·Cannot perform a task that he/she learned in the course.
                             ·Requires excessive help to perform the task.

                         In these situations, data analysis should focus on determining why the graduate is not able to meet
                         job performance requirements.

                         Since the job performance evaluation is normally conducted in conjunction with the other forms
                         of field evaluations, the results of data analysis are included in the Training Quality Report (TQR)

                                    Other Sources of Evaluation Input
92                                                                 AFMAN 36-2234 1 November 1993

 Other Data   Other external data sources that can be used to evaluate the graduates' job performance are:
 Sources
                  ·Inspection team (IG) reports - AF and MAJCOMs periodically inspect instructional activities
                      to determine their effectiveness. Other inspections conducted by these teams may also
                      discover related problems. Use this source of data to determine if graduates are meeting
                      their job performance requirements. Take appropriate action to correct deficiencies. One
                      example of an IG report is the Functional Management Inspection ( FMI).

                  ·Standardization/evaluation team findings - Standardiza tion/evaluation teams periodically
                      inspect instructional activities to determine their effectiveness. Analyze findings
                      indicating a problem and take appropriate action to correct the deficiencies.

              ·AF Form 1284, Training Quality Report (TQR) - The supervi sor of recent graduates reports
              strengths and weaknesses of the instruction that the graduates of the course received. The
              instructional activity should respond to any deficiencies identified in the TQR. Note that one or
              two TQRs by themselves may or may not be justifica tion to change or revise a course. Use
              problems identified in the report to validate findings of other forms of evalua tion methods.
   AFMAN 36-2234 1 November 1993                                                                                           93
                                                  Chapter 8
                                                EVALUATION
Overview
 Introduction             Evaluation is integrated throughout each activity of the instructional development process. It
                          starts in the planning stage with development of an evaluation plan and continues for the life
                          cycle of the training system. The focus of evaluation is continuous improvement in instructional
                          system quality.

 Where Are You in         The ISD model, with evaluation highlighted, is provided in Figure 11. As depicted in the model,
 the Process?             each stage in the ISD process involves evaluation activities.




                                                                             MANAGEMENT              IM
                                                                                                       PR
                                                                                                         OV
                                                                                                           EM
                                                                              ANALYSIS                       EN
                                                          IMPLEMENTATION                                       T




                                                                                            DESIGN
                                    DELIVERY                               EVALUATION                        SUPPORT




                                                                            DEVELOPMENT



                                                                           ADMINISTRATION




                                                                                                                       .
                          Evaluation




 Objective                The objective of this chapter is to summarize:

                              ·Formative evaluation
                              ·Summative evaluation
                              ·Operational evaluation


 Continuous         As previously mentioned, evaluation is an ongoing process. It begins during ISD planning and
 Evaluation Process continues as long as the instructional system is operational. The process includes formative,
                          summative, and operational evaluations. These forms of evaluation are discussed in subsequent
                          sections of this chapter. A brief overview of the evaluation process is provided in the following
                          table in order to acquaint the user of this manual with the continuous evaluation process.
94                                                                         AFMAN 36-2234 1 November 1993


                 Continuous Evaluation Process
                 Form                            Period                                                 Purpose
     Formative                From initial ISD planning through small-          Checks design of individual components
                              group tryout                                      of the instructional system for integration
                                                                                (accomplished periodically - is focused
                                                                                on the components -high data collection -
                                                                                make changes when it is least expensive
                                                                                to revise)
 Summative                    Operational tryout (normally 2 or 3 classes) -    Checks full system integration and its
                              real student throughput, full instructional       components (intense -high data
                              system operation                                  collection - short-term - first time
                                                                                everything is working together)
 Operational                  From completion of the operational tryout         Checks day-to-day system integration
                              continuing for the life cycle of the              and its components (periodic, less data
                              instructional system                              collection, life of system - continuous
                                                                                improvement)

 Additional           For additional information on evaluation, see:
 Information
                      ·Previous chapters in this manual.
                      ·AFMAN 36-2236.
                      ·Briggs, L. J. and Wager, W. W. (1981). Handbook of Procedures for the Design of Instruction.
                          (2nd Ed.). Glenview, Illinois: Harper Collins Publishers.
                      ·Dick, W. and Carey, L. (1990). The Systematic Design of Instruction. (3rd Ed.). Glenview,
                          Illinois: Harper Collins Publishers.
                      ·O'Neil, H. F. Jr., and Baker, E. L. (1991). Issues in Intelligent Computer-assisted Instruction:
                      Evaluation and Measurement. In T. Gutkin and S. Wise (Eds.), The Computer and the Decision
                      Making Process. Hillsdale, New Jersey: Lawrence Erlbaum Associates.

                                              Section A
                                         Formative Evaluation

 Introduction         The formative evaluation process begins during analysis and continues through small-group
                      tryout in the development stage of ISD. Within each stage— analysis, design, and development—
                      formative evaluation seeks to improve the quality of the activities and products of ISD. In some
                      organizations, formative evaluation is equated to four stages of validation— technical accuracy
                      reviews, individual tryouts, small-group tryouts, and operational tryouts.

 What It Is           Formative evaluation is a form of evaluation designed to collect data and information that is used
                      to improve the activities and products of the ISD process while the system is still being developed.
                      Formative evaluation is also used when the design or development phases are re-entered in order
                      to revise or update the system.
 AFMAN 36-2234 1 November 1993                                                                                             95
Formative      Formative evaluation may include any or all of the following activities, depending upon the
Evaluation     community. For example, in the Education, Technical Training and Unit Tranining
               communities, only the first two activities— process and product evaluations— will likely be
Activities     performed in the formative evaluation process. However, in the Aircrew Training and
                        Acquisition communities, it may be necessary to perform all of the activities listed below in order
                        to complete the formative evaluation process.

                        Process Evaluation

                        Process evaluation ensures quality in the analysis, design, and development activities.
                        It checks each activity against standards, or metrics, established during ISD project planning, to
                        assure process quality, while continually seeking improvements within each activity. Process
                        evaluation enables instructional developers to "form" an effective and efficient instructional
                        system based on quality principles.

                        Product Evaluation

                        Product evaluation is an integral part of each stage of the ISD process. Product evaluation focuses
                        on the products of the analysis, design and development activities such as task lists, objectives,
                        tests, plans of instruction and training materials. During product evaluation the focus is again on
                        quality. Products are measured against standards and metrics established in the planning stage of
                        ISD to ensure quality. Product evaluation also helps form a total quality instructional system.
                        Two activities of product evaluation are:

                        Validation, which takes place during training development and is the final activity in the
                        formative evaluation process. This component, which is discussed in Chapter 6, forms the
                        instructional system by trying out instruction on individuals and small groups. Validation
                        identifies quality improvements that should be made to the instruction prior to implementing the
                        system.
                                     ·Quality control, which starts in the initial stages of ISD planning with the strategy of
                        controlling quality, and continues throughout training analysis, design and development. This
                        process ensures that each activity such as equipment acquisition, facility construction, etc., is
                        based on quality principles.

                        Developmental Test and Evaluation (DT&E)

                        DT&E is an active part of training system development. As a formative evaluation activity, it is
                        conducted to demonstrate that training system equipment design and development are complete,
                        design risks have been minimized, and the system meets performance requirements. It ensures
                        the effectiveness of the manufacturing process, equipment, and procedures.

                        Operational Test and Evaluation (OT&E)

                        OT&E completes the formative evaluation process for training system equipment. This formative
                        evaluation activity evaluates the system's operational effectiveness, maintainability, supportability,
                        and suitability. It identifies any operational and logistic support deficiencies, and the need for
                        modification. In addition, OT&E provides information on organizational structure, personnel
                        requirements, support equipment, doctrine, training and tactics. It should also provide data to
                        verify operating instructions, maintenance procedures, training programs, publications, and
                        handbooks.
                        Site Readiness Reviews (SRR)
                        The site readiness review is a formative evaluation activity that focuses on evaluating the
                        readiness of the "bed-down" site for the training system. This evaluation ensures that the site,
                        including training facilities and support equipment, is ready for OT&E of the system. Site
                        readiness reviews help ensure the training system effectiveness.
96                                                                         AFMAN 36-2234 1 November 1993

 Relationship        Each formative evaluation activity contributes to the overall quality of the instructional system.
 of the Activities   They combine to ensure that:

                         ·Instructional development and revision activities are effective.
                         ·Instruction is cost-efficient.
                         ·The products of each development activity meet quality standards.
                         ·The instruction meets training requirements.
                         ·Equipment satisfies operational, training, and support requirements.
                     ·Facilities meet operational, training, and support requirements.

 Period of           Planning for formative evaluation begins in the initial planning stage of ISD. However, formative
 Formative           evaluation activities actually begin during analysis and continue through small-group tryout in
                     development.
 Evaluation

                                            Section B
                                        Summative Evaluation
 Introduction        With the conclusion of small-group tryouts, formative evaluation activities are complete.
                     Summative evaluation is the next stage in the continuous evaluation process. This stage of
                     evaluation involves trying out the instruction on the target population in an operational
                     environment. In some organizations, summative evaluations are conducted after the instructional
                     system becomes operational and includes two components— internal and external evaluation.

 What It Is          Summative evaluation is a form of evaluation designed to collect data and information during the
                     operational (field) tryouts in order to determine the "summed" effect of the instruction under
                     operational conditions and to make any changes or revisions to the system prior to becoming
                     operational. Summative evaluations are also conducted when significant revisions or updates
                     have been made to the instructional system.

 Summative           The only summative evaluation activity is the operational tryouts. Operational tryouts are used to:
 Evaluation
                         ·Determine if the instructional system works under operational conditions.
 Activity                ·Provide feedback from a large sample of target population in which to base revisions prior to
                             implementation of the instructional system.
                         ·Identify possible implementation or operational problems.
                         ·Determine if instruction is cost-efficient.
                     ·Determine if instruction is adequate and needed.

 Evaluating the      Summative evaluations are conducted on fully integrated instructional systems. This form of
 Integrated System   evaluation is essential in determining the effectiveness of the system and correcting any
                     deficiencies prior to implementation.

 Period of           Summative evaluation is focused on the period of operational tryouts. These tryouts begin after
 Summative           the small-group tryouts have been completed and continue until the instructional system is
                     implemented. Normally, the operational tryout period is limited to two or three classes.
 Evaluation

                                             Section C
                                       Operational Evaluation
   AFMAN 36-2234 1 November 1993                                                                                          97
 Introduction    As previously mentioned, the evaluation process is continuous. Once the formative and
                        summative evaluation activities have been completed and the instructional system is implemented,
                        operational evaluation begins. Operational evaluation continues as long as the system is
                        operational.

 What It Is             Operational evaluation is a form of evaluation designed to gather and analyze internal and
                        external feedback data to ensure that the system continues to effectively and cost-efficiently
                        produce graduates who meet established training requirements.

 Operational            Operational evaluation includes the following activities.
 Evaluation
                        Internal Evaluation
 Activities
                        Internal evaluation focuses on evaluating the instructional system internally. This form of
                        evaluation continuously evaluates feedback data such as instructor comments, student critiques
                        and test results in order to continually improve the system and ensure quality.

                        External Evaluation

                        External evaluation focuses on evaluating the instructional system externally. This form of
                        evaluation continually evaluates feedback data from the field such as inspection and evaluation
                        reports to ensure that graduates meet the established job performance requirements.

 Relationship           Each operational evaluation activity contributes to the overall quality of the instructional system
 of Activities          by ensuring that:

                            ·Each system component continues to contribute to the overall effectiveness and cost-
                                efficiency of the system.
                            ·Graduates of the course continue to meet the established job performance requirements.
                            ·Instruction is adequate and necessary.


 Period of              Operational evaluation begins with the implementation of the instructional system and continues
 Operational            for the life cycle of the system.
 Evaluation


BY ORDER OF THE SECRETARY OF THE AIR FORCE



 OFFICIAL                                   MERRILL A. McPEAK, General, USAF
                                            Chief of Staff



EDWARD A. PARDINI, Colonel, USAF
Director of Information Management



SUMMARY OF CHANGES
98                                                                           AFMAN 36-2234 1 November 1993

This revision provides an updated ISD model as well as general aspects of applying the ISD process. It provides for
several application handbooks in the specific areas of technical training, aircrew training, acquisition, education and
others. Information on learning theory has been added. Quality improvement and evaluation have been emphasized
throughout the publication.
AFMAN 36-2234 1 November 1993                                                       99
                             Attachment A - Air Force ISD Documents


     AFPD 36-22, Military Training

     AFI 36-2201, Development, Managing, and Conducting Military Training

     AFI 36-2301, Professional Military Education

     AFMAN 36-2234, Instructional System Development

     AFMAN 36-2236, Handbook for Air Force Instructors

     AFH 36-2235, Information for Designers of Instructional Systems (11 volumes)

        Vol 1, Executive Summary

     Vol 2, ISD Automated Tools/What Works

        Vol 3, Application to Acquisition

     Vol 4, Guide to Training Technologies

     Vol 5, Interactive Courseware (ICW) Design, Development and Management Guide

     Vol 6, Guide to Needs Assessment

     Vol 7, Design Guide for Device-based Aircrew Training

     Vol 8, Application to Aircrew Training

     Vol 9, Application to Technical Training

     Vol 10, Application to Education

     Vol 11, Application to Unit Training
100                                                                     AFMAN 36-2234 1 November 1993

                                               Attachment B - Bibliography


Beckschi, P. F., Lierman, B. C., Redding, R. E. and Ryder, J.M. (1993). Procedural Guide for Integrating
         Cognitive Methods into Instructional Systems Development Task Analysis. Brooks Air Force Base, Texas:
         Air Force Materiel Command.
Bills, C. G. and Butterbrodt, V. L. (1992). Total Training Systems Design Function: A Total Quality Management
         Application. Wright-Patterson AFB, Ohio.
Bloom, B. S. (Ed). (1956). Taxonomy of Educational Objectives. Handbook I: Cognitive Domain. New York:
         Mckay.
Briggs, L. J. and Wager, W. W. (1981). Handbook of Procedures for the Design of Instruction (2nd Ed.).
         Glenview, Illinois: Harper Collins Publishers.
Carlisle, K. E. (1986). Analyzing Jobs and Tasks. Englewood Cliffs, New Jersey: Educational Technology
         Publications.
Davies, I. K. (1976). Objectives in Curriculum Design. London: McGraw Hill.
Dick, W. and Carey, L. (1990). The Systematic Design of Instruction (3rd Ed.). Glenview, Illinois: Harper Collins
         Publishers.
Fishburne, R. P., Williams, K. R., Chatt, J. A. and Spears, W. D. (1987). Design Specification Development For
         The C-130 Model Aircrew Training System: Phase I Report. Williams AFB, Arizona: Air Force Human
         Resources Laboratory (AFHRL-TR86-44).
Gagné, R. M. (1985). The Conditions of Learning (4th Ed.). New York: Holt, Rinehart and Winston.
Gagné, R. M., Briggs, L. J., and Wager, W. W. (1992). Principles of Instructional Design (4th Ed.). New York:
         Harcourt Brace Jovanovich College Publishers.
Gagné, R. M. and Merrill, M. D. (1990). Integrative Goals for Instructional Design. Educational Technology
         Research and Development. 38(1), 1-8.
JWK International Corp. (1990). Final Training System Baseline Analysis Report (EWOT). Dayton, Ohio: JWK
         International Corp.
Keller, J. M. (1987). The Systematic Process of Motivational Design. Performance and Instruction, 26(9), 1-8.
Kibler, R. J. (1981). Objectives for Instruction. Boston: Allyn and Bacon.
Knirk, F. G. and Gustafson, K. L. (1986). Instructional Technology: A Systematic Approach to Education. New
         York: Holt, Rinehart, and Winston.
Krathwohl, D. R., Bloom, B. S. and Masia, B. (1964). Taxonomy of Educational Objectives, Handbook II: Affective
         Domain. New York: David Mckay.
Leshin, C. B., Pollock, J., and Riegeluth, C. M. (1992). Instructional Design Strategies and Tactics. Englewood
         Cliffs, New Jersey: Educational Technology Publications.
Mager, R. F. (1962). Preparing Objectives for Instruction (2nd Ed.). Belmont, California: Fearon Publishers.
Merrill, M. D., Lee, Z., and Jones, M. K. (1990) Second Generation Instructional Design (ID2). Englewood Cliffs,
         New Jersey: Educational Technology Publications.
Merrill, M. D., Tennyson, R. D., and Posey, L. (1992). Teaching Concepts: An Instructional Design Guide (2nd
         Ed.). Englewood Cliffs, New Jersey: Educational Technology Publications.
O'Neil, H. F., Jr., and Baker, E. L. (1991). Issues in Intelligent Computer-assisted Instruction: Evaluation and
         Measurement. In T. Gutkin and S. Wise (Eds.), The Computer and the Decision Making Process.
         Hillsdale, New Jersey: Lawrence Erlbaum Associates.
Reigeluth, C. M. (1983). Instructional Design; What Is It and Why Is It? In C.M. Reigeluth (Ed.), Instructional
         Design Theories and Models: An Overview of Their Current Status. Hillsdale, New Jersey: Erlbaum
         Associates.
Reiser, R. A. and Gagné, R. M. (1983). Selecting Media for Instruction. Englewood Cliffs, New Jersey:
         Educational Technology Publications.
Rossett, A. (1987). Training Needs Assessment. Englewood Cliffs, New Jersey: Educational Technology
         Publications.
    AFMAN 36-2234 1 November 1993                                                                             101
Spears, W. D. (1983). Processes of Skill Performance: A Foundation for the Design and Use of Training
        Equipment. (NAVTRAEQ-VIPCEN 78-C-0113-4). Orlando, Florida: Naval Training Equipment Center.
Stufflebeam, D. (1985). Conducting Educational Needs Assessment. Boston: Kluwer-Nijhoff.
Tennyson, R. D. and Michaels, M. (1991). Foundations of Educational Technology: Past, Present and Future.
        Englewood Cliffs, New Jersey: Educational Technology Publications.
Williams, K. R., Judd, W. A., Degen, T. E., Haskell, B. C., & Schutt, S. L. (1987). Advanced Aircrew Training
        Systems (AATS): Functional Design Description. Irving, Texas: Seville Training Systems (TD-87-12).
Wolfe, P., Wetzel, M., Harris, G., Mazour, T. and Riplinger, J. (1991). Job Task Analysis: Guide to Good Practice.
        Englewood Cliffs, New Jersey: Educational Technology Publications.
102                                    AFMAN 36-2234 1 November 1993

               Attachment C - Abbreviations


      AATS                               Advanced Aircrew Training System
      AETC                               Air Education and Training Command
      AF                                 Air Force
      AFH                                Air Force Handbook
      AFI                                Air Force Instruction
      AFMAN                              Air Force Manual
      AFPD                               Air Force Policy Directive
      AFS                                Air Force Specialty
      ANG                                Air National Guard
      ARCS                               Attention, Relevance, Confidence and Satisfaction
      CAI                                Computer-Assisted Instruction
      CBI                                Computer-Based Instruction
      CBT                                Computer-Based Training
      CDC                                Career Development Course
      CD-ROM                             Compact Disc-Read Only Memory
      CMI                                Computer-Managed Instruction
      CRT                                Criterion-Referenced Test
      DoD                                Department of Defense
      DT&E                               Developmental Test and Evaluation
      ECI                                Extension Course Institute
      FMI                                Functional Management Inspection
      ICW                                Interactive Courseware
      IG                                 Inspector General
      ISD                                Instructional System Development
      IVD                                Interactive Videodisc
      JPA                                Job Performance Aid
      JPR                                Job Performance Requirements
      LP                                 Lesson Plan
      MAJCOM                             Major Command
      MTAR                               Mission Task Analysis Report
      OJT                                On-the-Job Training
      OMS                                Occupational Measurement Squadron
      OSR                                Occupational Survey Report
      OT&E                               Operational Test and Evaluation
      PME                                Professional Military Education
AFMAN 36-2234 1 November 1993                                       103
      POI                       Plan of Instruction
      PTT                       Part-Task Trainer
      QA                        Quality Assurance
      QAF                       Quality Air Force
      QI                        Quality Improvement
      SAT                       Systems Approach to Training
      SKA                       Skills, Knowledge, and Attitudes
      SME                       Subject Matter Expert
      SPO                       System Program Office
      SRR                       Site Readiness Review
      STP                       System Training Plan
      TDY                       Temporary Duty
      TO                        Technical Order
      TPR                       Trained Personnel Requirement
      TPT                       Training Planning Team
      TQR                       Training Quality Report
      U&TW                      Utilization and Training Workshop
      USAF                      United States Air Force
      VCR                       Video Cassette Recorder
104                                                                           AFMAN 36-2234 1 November 1993

                                       Attachment D - Definitions



The following list of definitions includes those terms commonly used to discuss education and training as they relate
to instructional system development and as used in this manual. It is not to be considered all-inclusive.

Association. The connection made between an input (stimulus) and an action (response).

Attitude. (a) The emotions or feelings that influence a learner's desire or choice to perform a particular task. (b) A
positive alteration in personal and professional beliefs, values, and feelings that will enable the learner to use skills
and knowledge to implement positive change in the work environment. Also seeKnowledge and Skill.

Behavior. Any activity, overt or covert, capable of being measured.

Cognition. The mental or intellectual activity or process of knowing, including both awareness and judgment.

Cognitive Strategies. The capability of individuals to govern their own learning, remembering, and thinking
behavior.

Computer-Assisted Instruction (CAI). The use of computers to aid in the delivery of instruction. A variety of
interactive instructional modes are used including tutorial, drill and practice, gaming, simulation, or combinations.
CAI is an integral part of computer-based instruction (CBI) and computer-based training (CBT).

Computer-Based Instruction (CBI) and Computer-Based Training (CBT). The use of computers to aid in the
delivery and management of instruction. CBI and CBT are synonymous and are used interchangeably. CAI (the
delivery of instruction) and CMI (computer-managed instruction) are both elements of CBI and CBT.

Computer-Managed Instruction (CMI). The use of computers to manage the instructional process in CAI or CBT.
Management normally includes functions such as registration, pretesting, diagnostic counseling, progress testing, and
posttesting. CMI is also used to schedule and manage training resources such as trainers and equipment.

COMSEC. An abbreviation for Communications Security. The protection resulting from all measures designed to
deny unauthorized persons information of value which might be derived from the possession and study of
telecommunications and to ensure the authenticity of such communications.

Constraints. Limiting or constraining conditions or factors, such as policy considerations, time limitations,
equipment, environmental factors, personnel, budgetary, or other resource limitations.

Course Chart. A qualitative course control document that states the course identity, length, and security
classification, lists major items of training equipment, and summarizes the subject matter covered.

Course Control Documents. Specialized publications used to control the quality of the instructional system.
Examples are training standards, plans of instruction, syllabi, and course charts.

Courseware. Training materials such as technical data, textual materials, audiovisual instructional materials, and
computer-based instructional materials.

Criterion. (a) The standard by which something is measured. (b) In test validation, the standard against which test
instruments are correlated to indicate that accuracy with which they predict human performance in some specified
    AFMAN 36-2234 1 November 1993                                                                                       105
area. (c) In evaluation, the measure used to determine the adequacy of a product, process, behavior, and other
conditions.

Criterion-Referenced Test (CRT). A test to determine, as objectively as possible, a student's achievement in
relation to a standard based on criterion objectives. During instructional development, the CRT can be used to
measure the effectiveness of the instructional system. The test may involve multiple-choice items, fill-in items,
essays, or actual performance of a task. If given immediately after the learning sequence, it is an acquisition test; if
given considerably later, it is a retention test; if it requires performance not specifically learned during instruction, it
is a transfer test.

Discrimination. The process of making different responses to a stimulus. A discrimination requires a person to
determine the differences among inputs and to respond differently to each.

Distance Learning. Training that is exported, such as from a resident course to a field location. Also called
Exportable Training.

Duty. A large segment of the work done by an individual; major divisions of work in a job.

Evaluation. A judgment expressed as a measure or ranking of trainee achievement, instructor performance, process,
application, training material, and other factors (see MIL-STD-1379D). It includes Formative Evaluation;
Operational Evaluation; and Summative Evaluation.

Exportable Training. See Distance Learning.

External Evaluation. The acquisition and analysis of feedback data from outside the formal training environment to
evaluate the graduate of the instructional system in an operational environment. Also calledField Evaluation. Also
see Operational Evaluation.

Feedback. Information that results from or is contingent upon an action. The feedback does not necessarily indicate
the correctness of an action; rather, it relates the results of the action from which inferences about the correctness can
be drawn. Feedback may be immediate, as when a fuse blows because a lamp is incorrectly wired; or delayed, as
when an instructor provides a discussion pertaining to an exam taken the previous week, or when completed graduate
evaluation questionnaires are reviewed.

Fidelity. The degree to which a task or a training device represents the actual system performance, characteristics,
and environment.

Field Evaluation. See External Evaluation.

Formative Evaluation. An activity that provides information about the effectiveness of training materials to meet
training objectives and the trainee acceptance of training materials as they are being developed. Also called
Developmental Testing. Also see Evaluation.

Generalization. Learning to respond to a new stimulus that is similar, but not identical, to one that was present
during original learning. For example, during learning a child calls a beagle and a spaniel by the term "dog"; a child
who has generalized would respond "dog" when presented with a hound.

Instructional Objective. See Objective.

Instructional System. An integrated combination of resources (students, instructors, materials, equipment, and
facilities), techniques, and procedures performing effectively and efficiently the functions required to achieve
specified learning objectives.
106                                                                        AFMAN 36-2234 1 November 1993


Instructional System Developer. A person who is knowledgeable of the instructional system development (ISD)
process and is involved in the analysis, design, development, implementation, and evaluation of instructional systems.
Also called Instructional Developer, Curriculum developer, Curriculum Development Manager, and other terms.

Instructional System Development (ISD). A deliberate and orderly, but flexible, process for planning, developing,
implementing, and managing instructional systems. It ensures that personnel are taught in a cost-efficient way the
knowledge, skills, and attitudes essential for successful job performance.

Interactive Courseware (ICW). Computer-controlled training designed to allow the student to interact with the
learning environment through input devices such as keyboards and light pens. The student's decisions and inputs to
the computer determine the level, order, and pace of instructional delivery, and forms of visual and aural outputs.

Interactive Videodisc (IVD). A form of ICW instruction that specifically makes use of videodisc technology.
Video and audio signals are pressed onto the laser videodisc; programming codes may or may not be pressed onto the
disc depending on the IVD level. As a result, motion sequence, still-frame shots, computer-generated graphics,
and/or audio may be displayed and heard through a monitor under computer and user control.

Internal Evaluation. The acquisition and analysis of feedback and management data from within the formal training
environment to assess the effectiveness of the instructional system. Also seeOperational Evaluation.

Job. The duties, tasks, and task elements performed by an individual. The job is the basic unit used in carrying out
the personnel actions of selection, training, classification, and assignment.

Job Aid. A checklist, procedural guide, decision table, worksheet, algorithm, or other device used by a job
incumbent to aid in task performance. Job aids reduce the amount of information that personnel must recall or retain.

Job Analysis. The basic method used to obtain salient facts about a job, involving observation of workers,
conversations with those who know the job, analysis questionnaires completed by job incumbents, or study of
documents involved in performance of the job.

Job Performance Requirements (JPR). The tasks required of the human component of the system, the conditions
under which these tasks may be performed, and the quality standards for acceptable performance. JPRs describe
what people should do to perform their jobs.

Knowledge. Use of the mental processes which enable a person to recall facts, identify concepts, apply rules or
principles, solve problems, and think creatively. Knowledge is not directly observable. A person manifests
knowledge through performing associated overt activities. Also seeAttitude and Skill.

Learning. A change in the behavior of the learner as a result of experience. The behavior can be physical and overt,
or it can be intellectual or attitudinal.

Lesson Plan. An approved plan for instruction that provides specific definition and direction to the instructor on
learning objectives, equipment, instructional media material requirements, and conduct of training. Lesson plans are
the principal component of curriculum materials in that they sequence the presentation of learning experiences and
program the use of supporting instructional material.

Media. The delivery vehicle for presenting instructional material or basic communication stimuli to a student to
induce learning. Examples are instructors, textbooks, slides, and interactive courseware (ICW).
    AFMAN 36-2234 1 November 1993                                                                                   107
Metrics. Measurement tools used for assessing the qualitative and quantitative progress of instructional development
with respect to the development standards specified.

Motor Skill. Physical actions required to perform a specific task. All skills require some type of action.

Norm-Referenced Test. The process of determining a student's achievement in relation to other students. Grading
on the curve involves norm-referenced measurement, since an individual's position on the curve (grade) depends on
the performance of other students. Generally, norm-referenced measurement is not appropriate in the Air Force ISD
process.

Objective. A statement that specifies precisely what behavior is to be exhibited, the conditions under which behavior
will be accomplished, and the minimum standard of performance. Objectives describe only the behaviors that
directly lead to or specifically satisfy a job performance requirement. An objective is a statement of instructional
intent.

Operational Evaluation. The process of internal and external review of system elements, system requirements,
instructional methods, courseware, tests and process guide revision as needed to enhance the continued training
effectiveness and efficiency of the training system during full-scale operations. It includes Internal Evaluation and
External Evaluation. Also see Evaluation.

Perceptual Skill. The process of information extraction; the process by which an individual receives or extracts
information from the environment through experiences and assimilates this data as facts (sight, sound, feel, taste,
smell).

Performance. Part of a criterion objective that describes the observable student behavior (or the product of that
behavior) that is acceptable to the instructor as proof that learning has occurred.

Plan of Instruction (POI). A qualitative course control document designed for use primarily within a school for
course planning, organization, and operation. Generally, criterion objectives, duration of instruction, support
materials, and guidance factors are listed for every block of instruction within a course. Also called Syllabus.

Posttest. A criterion-referenced test designed to measure performance on objectives taught during a unit of
instruction; given after the instruction.

Pretest. A criterion-referenced test designed to measure performance on objectives to be taught during a unit of
instruction and performance on entry behavior; given before instruction begins.

Reliability. (a) A characteristic of evaluation which requires that testing instruments yield consistent results. (b)
The degree to which a test instrument can be expected to yield the same result upon repeated administration to the
same population. (c) The capability of a device, equipment, or system to operate effectively for a period of time
without a failure or breakdown.

Simulation. A technique whereby job environment phenomena are mimicked, in an often low-fidelity situation, in
which costs may be reduced, potential dangers eliminated, and time compressed. The simulation may focus on a
small subset of the features of the actual job environment.

Skill. The ability to perform a job-related activity that contributes to the effective performance of a task. Skills
involve physical or manipulative activities which often require knowledge for their execution. All skills are actions
having specific requirements for speed, accuracy, or coordination. Also seeAttitude and Knowledge.

Subject Matter Expert (SME). (a) An individual who has thorough knowledge of a job, duties/tasks, or a
particular topic, which qualifies him/her to assist in the training development process (for example, to consult,
108                                                                        AFMAN 36-2234 1 November 1993

review, analyze, advise, or critique). (b) A person who has high-level knowledge and skill in the performance of a
job.

Summative Evaluation. The overall assessment of a program at the completion of the developmental process. It is
designed and used after the instructional system has become operational. Also seeEvaluation.

Syllabus. See Plan of Instruction.

System Training Plan (STP). The specific document which includes program information and data concerning the
system or equipment program, event, or situation that originated the training requirement, and describes the training
required and the training programs to satisfy the requirement. The STP is designed to provide for planning and
implementation of training and ensure that all resources and supporting actions required for establishment and
support are considered.

System Approach to Training (SAT). Procedures used by instructional system developers to develop instruction.
Each phase requires input from the prior phase and provides input to the next phase. Evaluation provides feedback
which is used to revise instruction. Also see Instructional System Development.

Target Audience. The total collection of possible users of a given instructional system; the persons for whom the
instructional system is designed.
    AFMAN 36-2234 1 November 1993                                                                                   109
Task. A unit of work activity or operation which forms a significant part of a duty. A task usually has clear
beginning and ending points and directly observable or otherwise measurable processes, frequently but not always
resulting in a product that can be evaluated for quantity, quality, accuracy, or fitness in the work environment. A
task is performed for its own sake; that is, it is not dependent upon other tasks, although it may fall in a sequence
with other tasks in a duty or job array.

Task Analysis. The process of describing job tasks in terms of Job Performance Requirements (JPR) and the
process of analyzing these JPRs to determine training requirements. Also seeJob Performance Requirements.

TEMPEST. A term used to describe compromising emanations. They are unintentional, data-related, intelligence-
bearing signals which, if intercepted and analyzed, could disclose the classified information transmitted, received,
handled, or otherwise processed by electronic equipment.

Terminal Objective. An objective the learners are expected to accomplish upon completion of the instruction. It is
made up of enabling (support or subordinate) objectives.

Training. A set of events or activities presented in a structured or planned manner, through one or more media, for
the attainment and retention of skills, knowledge, and attitudes required to meet job performance requirements.

Training Needs Assessment (TNA). The study of performance and the environment that influences it in order to
make recommendations and decisions on how to close the gap between the desired performance and the actual
performance.

Training Planning Team (TPT). An action group composed of representatives from all pertinent functional areas,
disciplines, and interests involved in the life cycle design, development, acquisition, support, modification, funding,
and management of a specific defense training system.

Training Strategy. An overall plan of activities to achieve an instructional goal.

Training System. A systematically developed curriculum including, but not necessarily limited to, courseware,
classroom aids, training simulators and devices, operational equipment, embedded training capability, and personnel
to operate, maintain, or employ a system. The training system includes all necessary elements of logistic support.

Utilization and Training Workshop (U&TW). A forum to determine Specialty Training Standard requirements
and responsibilities for the specialty. Workshop attendees include, but are not limited to, representatives from the
training and using organizations.

Validation. The process of developmental testing, field testing, and revision of the instruction to be certain the
instructional intent is achieved. The instructional system is developed unit by unit and tested (or validated) on the
basis of the objective prepared for each unit.

Validity. The degree to which a criterion test actually measures what it is intended to measure.
