BY ORDER OF THE COMMANDER                       AIR FORCE OPERATIONAL TESTING AND
AIR FORCE OPERATIONAL TEST AND                    EVALUATION CENTER MANUAL 99-101
EVALUATION CENTER (AFOTEC)
                                                                             11 OCTOBER 2012

                                                                             Test and Evaluation

                                                    OPERATIONAL TEST PROCESSES AND
                                                                       PROCEDURES

              COMPLIANCE WITH THIS PUBLICATION IS MANDATORY

ACCESSIBILITY: Publications and forms are available for downloading or ordering on the e-
               Publishing website at www.e-Publishing.af.mil/.

RELEASABILITY: There are no releasability restrictions on this publication.
OPR: AFOTEC/A-3O                                                      Certified by: AFOTEC/A-3
                                                                            (Col Nevin K. Elden)
Supersedes:    AFOTECMAN 99-101,                                                       Pages: 62
               6 August 2010


The AFOTECMAN 99-101 provides organizationally specific guidance and procedures for
planning, executing, and reporting operational test and evaluation (OT&E) and related activities.
The AFOTECMAN 99-101 is to be used in conjunction with policies, directives, and instructions
contained in Department of Defense (DoD) Directive (DODD) 5000.01, The Defense Acquisition
System; DoD Instruction (DODI) 5000.02, Operation of the Defense Acquisition System;
Chairman of the Joint Chiefs of Staff Instruction (CJCSI) 3170.01H, Joint Capabilities
Integration and Development System; CJCSI 6212.01E, Interoperability and Supportability of
Information Technology and National Security Systems; Air Force Policy Directive (AFPD) 99-
1, Test and Evaluation Process; Air Force Instruction (AFI) 99-103, Capabilities Based Test and
Evaluation; Air Force Mission Directive (AFMD) 14, Air Force Operational Test and
Evaluation Center; and the AFOTEC OT&E Guide. This manual assumes a fundamental
understanding of the DoD and Air Force weapon system acquisition processes. This manual
does not repeat higher headquarters policy and direction and the higher headquarters guidance
should be consulted first to understand the roles and missions of AFOTEC. The AFOTECMAN
99-101 outlines the AFOTEC Commander’s (AFOTEC/CC) processes, procedures, checklists,
and techniques of the various phases of OT&E. The manual applies to all AFOTEC directorates,
detachments (Dets), and operating locations (OLs). This publication does not apply to ANG or
AFRC. Refer recommended changes and questions about this publication to AFOTEC
Operations Directorate (AFOTEC/A-3) using the AF Form 847, Recommendation for Change of
Publication; route AF Form 847s from the field through the appropriate chain of command
including the publications/forms manager. Ensure that all records created as a result of processes
prescribed in this publication are maintained in accordance with AF Manual (AFMAN) 33-363,
Management of Records, and disposed of in accordance with the Air Force Records Disposition
 2                                                                         AFOTECMAN99-101 11 OCTOBER 2012


Schedule (RDS) located at https://www.my.af.mil/gcss-af61a/afrims/afrims. Additionally, if
the publication generates reports, all applicable Reports Control Numbers must be in accordance
with AFI 33-324, The Information Collections and Reports Management Program: Controlling
Internal, Public, and Interagency Air Force Information Collections. This publication may not
be supplemented. Submit requests for waiver to the AFOTECMAN 99-101 to the AFOTEC/A-3
Corporate Account, AFOTEC.A3.workflow@kirtland.af.mil.                     AFOTEC/A-3 will
administratively coordinate the waiver request with the process owner and the affected AFOTEC
staff.

SUMMARY OF CHANGES

This manual has been significantly reduced in size and content, covering only an overview of the
processes and procedures required for OT&E. It must be read in its entirety and it should be
used in conjunction with the AFOTEC OT&E Guide that defines the mandatory processes and
procedures in detail.

Chapter 1—INTRODUCTION                                                                                                                        7

Section 1A—Overview                                                                                                                           7
       1.1.    Purpose. ..................................................................................................................    7

Section 1B—AFOTEC Processes                                                                                                                   7
       1.2.    Early Influence. ......................................................................................................        7
       1.3.    Integrated Test and Evaluation. .............................................................................                  7
       1.4.    Office of the Secretary of Defense T&E Oversight List. .......................................                                 8
       1.5.    Program Support by AFOTEC Liaison Officers. ...................................................                                8
       1.6.    Staffing and Coordination. .....................................................................................               9
       1.7.    External Briefings. .................................................................................................          9
       1.8.    Meeting Attendance. ..............................................................................................             9
       1.9.    Security Management. ...........................................................................................               9
       1.10.   AFOTEC Intranet. .................................................................................................            11
       1.11.   AFOTEC Test Program Applications. ...................................................................                         12
       1.12.   Training. .................................................................................................................   12
       1.13.   AFOTEC HQ Standardization and Evaluation. .....................................................                               12
       1.14.   Technical and Scientific Support. ..........................................................................                  12
       1.15.   Lessons Learned. ...................................................................................................          13
       1.16.   Risk Management. .................................................................................................            13
       1.17.   Rapid Test Considerations. ....................................................................................               13

Chapter 2—AFOTEC ACTIVITIES SUPPORTING MILESTONE A                                                                                           14
AFOTECMAN99-101 11 OCTOBER 2012                                                                                                            3


Section 2A—Overview                                                                                                                        14
       2.1.    Introduction. ...........................................................................................................   14

Section 2B—External Support Documents                                                                                                      15
       2.2.    Ongoing Activities. ................................................................................................        15
       2.3.    Initial Capabilities Document. ...............................................................................              15
       2.4.    Acquisition Decision Memorandum. .....................................................................                      15
       2.5.    Preliminary Concept of Operations. ......................................................................                   15
       2.6.    Analysis of Alternatives. ........................................................................................          15
       2.7.    Course of Action. ...................................................................................................       16
       2.8.    Modeling & Simulation Support Plan. ...................................................................                     16
       2.9.    Life Cycle Management Plan. ................................................................................                16
       2.10.   Information Support Plans. ....................................................................................             16
       2.11.   Information Assurance Strategy. ...........................................................................                 17

Section 2C—Processes, Procedures, and Products.                                                                                            17
       2.12.   Program Identification. ..........................................................................................          17
       2.13.   Program Involvement. ...........................................................................................            17
       2.14.   Initial Test Resource Plan. .....................................................................................           18
       2.15.   High Performance Teams. .....................................................................................               18
       2.16.   Integrated Test Team & Charter. ...........................................................................                 18
       2.17.   Certification of Readiness for Operational Test & Evaluation. .............................                                 19
       2.18.   The Core Team. .....................................................................................................        19
       2.19.   Initial Test Design Process. ....................................................................................           19
       2.20.   Tasking Order Update. ...........................................................................................           20
       2.21.   Test Resource Plan Update. ...................................................................................              20
       2.22.   Test and Evaluation Strategy. ................................................................................              21

Chapter 3—AFOTEC ACTIVITIES SUPPORTING MILESTONE B                                                                                         22

Section 3A—Overview                                                                                                                        22
       3.1.    Introduction. ...........................................................................................................   22

Section 3B—External Support Documents                                                                                                      22
       3.2.    Acquisition Decision Memorandum Update. .........................................................                           22
       3.3.    Capability Development Document. ......................................................................                     22
       3.4.    Analysis of Alternatives Update. ...........................................................................                22
 4                                                                        AFOTECMAN99-101 11 OCTOBER 2012


       3.5.    Modeling & Simulation Support Plan Update. ......................................................                           22
       3.6.    Life Cycle Management Plan Update. ...................................................................                      22
       3.7.    Information Support Plans Update. ........................................................................                  23
       3.8.    Information Assurance Strategy. ...........................................................................                 23
       3.9.    Authority to Operate or Interim Authorization to Operate. ...................................                               23
       3.10.   Security Classification Guide. ...............................................................................              23
       3.11.   Threat Assessment Documents. .............................................................................                  23
       3.12.   Request for Proposal. .............................................................................................         24

Section 3C—Processes, Procedures and Products.                                                                                             24
       3.13.   High Performance Team. .......................................................................................              24
       3.14.   Integrated Test Team Charter Review, Update and Coordination. ........................                                      24
       3.15.   Test Design Validation. .........................................................................................           24
       3.16.   Test & Evaluation Master Plan for Milestone B. ...................................................                          24
       3.17.   Test Concept Process. ............................................................................................          25
       3.18.   Test Capability Roadmap. ......................................................................................             25
       3.19.   Operational Test Planning Considerations. ............................................................                      26
       3.20.   Operational Assessment Planning. .........................................................................                  27

Section 3D—Activities and Events.                                                                                                          27
       3.21.   Early Operational Assessment. ..............................................................................                27

Chapter 4—AFOTEC ACTIVITIES SUPPORTING MILESTONE C                                                                                         28

Section 4A—Overview                                                                                                                        28
       4.1.    Introduction. ...........................................................................................................   28

Section 4B—External Support Documents                                                                                                      28
       4.2.    Acquisition Decision Memorandum Update. .........................................................                           28
       4.3.    Program Management Directive. ...........................................................................                   28
       4.4.    Capability Production Document. ..........................................................................                  28
       4.5.    Enabling Concept. ..................................................................................................        28
       4.6.    Analysis of Alternatives Update. ...........................................................................                29
       4.7.    Modeling & Simulation Support Plan Update. ......................................................                           29
       4.8.    Life Cycle Management Plan Update. ...................................................................                      29
       4.9.    Information Support Plans Update. ........................................................................                  29
       4.10.   Information Assurance Strategy Update. ...............................................................                      29
AFOTECMAN99-101 11 OCTOBER 2012                                                                                                            5


       4.11.   Authority to Operate or Interim Authorization to Operate. ...................................                               29
       4.12.   Threat Assessment Documents. .............................................................................                  29

Section 4C—Processes, Procedures and Products.                                                                                             30
       4.13.   High Performance Team. .......................................................................................              30
       4.14.   Integrated Test Team Charter Review, Update and Coordination. ........................                                      30
       4.15.   Forming the Test Team. .........................................................................................            30
       4.16.   Support Agreements. .............................................................................................           30
       4.17.   Test Capabilities. ...................................................................................................      31
       4.18.   Data Management and Analysis Plan. ...................................................................                      31
       4.19.   Detailed Test Procedures. ......................................................................................            31
       4.20.   Determine Last Test Event. ....................................................................................             31
       4.21.   Visual Information Documentation. ......................................................................                    32
       4.22.   Test & Evaluation Master Plan Update. .................................................................                     32
       4.23.   Operational Assessment Planning. .........................................................................                  32
       4.24.   Operational Utility Evaluation Planning. ...............................................................                    32

Section 4D—Activities and Events.                                                                                                          32
       4.25.   Operational Assessment. ........................................................................................            33
       4.26.   Operational Utility Evaluation. ..............................................................................              33

Chapter 5—AFOTEC ACTIVITIES SUPPORTING FULL-RATE PRODUCTION
            (FRP)/INITIAL OPERATIONAL CAPABILITY (IOC)/FIELDING
            DECISION                                                                                                                       34

Section 5A—– Overview                                                                                                                      34
       5.1.    Introduction. ...........................................................................................................   34

5B—-External Support Documents                                                                                                             34
       5.2.    Acquisition Decision Memorandum Update. .........................................................                           34

5C—- Processes, Procedures and Products.                                                                                                   34
       5.3.    Test & Evaluation Master Plan Update. .................................................................                     34
       5.4.    Operational Test & Evaluation Plans (IOT&E/QOT&E/FOT&E). .......................                                            34
       5.5.    Test Readiness Review. .........................................................................................            35

5D—-Activities and Events.                                                                                                                 35
       5.6.    Operational Utility Evaluation. ..............................................................................              35
       5.7.    Initial Operational Test & Evaluation Execution. ..................................................                         35
 6                                                                        AFOTECMAN99-101 11 OCTOBER 2012


Chapter 6—AFOTEC ACTIVITIES FOLLOWING FRP/IOC/FIELDING DECISION                                                                             36

Section 6A—Overview                                                                                                                         36
       6.1.    Introduction. ...........................................................................................................    36

Section 6B—Processes, Procedures and Products.                                                                                              36
       6.2.    Follow-on Operational Test & Evaluation Criteria. ...............................................                            36
       6.3.    Closeout. ................................................................................................................   36
Table 6.1.     OT Closeout/Change Activities. ............................................................................                  36

Attachment 1—GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION                                                                              38
AFOTECMAN99-101 11 OCTOBER 2012                                                                7



                                           Chapter 1

                                      INTRODUCTION

Section 1A—Overview

1.1. Purpose. This manual provides mandatory procedures for AFOTEC personnel on
accomplishing OT&E in support of the Air Force acquisition process. Requests for deviations to
this manual should be sent to AFOTEC/A-3 for AFOTEC/CC approval.
   1.1.1. Interim changes will be used to publish changes to the manual. In addition to the
   procedures on the title page, proposed changes to the manual can be submitted via request to
   the AFOTEC/A-3 workflow e-mail account. Operational test information files are used to
   provide immediate notice of updated information to AFOTEC that is not captured in formal
   policy.
   1.1.2. Use this manual in conjunction with the AFOTEC OT&E Guide, as well as, checklists,
   guides, templates, etc., on the AFOTEC Intranet. Throughout the manual, you can find
   references to documents located on the AFOTEC Intranet (see paragraph 1.10 for additional
   info). A working knowledge of the AFOTEC organization is assumed.
   1.1.3. Terms of Reference. To effectively execute the AFOTEC/CC’s procedures for
   planning, executing, and reporting Integrated Test and Evaluation (IT&E) and related
   activities, a common understanding of terms is essential. For the purposes of the manual, the
   term operational test (OT) includes initial OT&E (IOT&E), qualification OT&E (QOT&E),
   follow-on OT&E (FOT&E), and multiservice OT&E (MOT&E), as well as early operational
   assessment (EOA), operational assessment (OA), and operational utility evaluation (OUE).
   Operational utility assessments (OUA) are used to provide information for innovation
   programs.

Section 1B—AFOTEC Processes

1.2. Early Influence. Early Influence is an approach adopted by AFOTEC for engaging and
teaming with the user and acquisition communities early in the acquisition process in order to
reduce program risk and support delivering mission capable systems to the warfighter. In
addition, early influence enables AFOTEC to identify programs for possible involvement.
AFOTEC/A-3 will execute programmatic activities (assess AF equity, monitor program status,
etc.) during pre-involvement. Once an involvement decision has been made, the assigned Det
takes the lead for managing the programmatics.
1.3. Integrated Test and Evaluation. The objective of IT&E is to 1) maximize opportunities
to collect operationally relevant data, 2) optimize use of limited test and evaluation (T&E) time
and resources, and 3) identify problems of an operational nature at the earliest opportunity.
IT&E involves collecting OT&E-relevant data from appropriate developmental test (DT) events
with a focus on achieving both DT and OT objectives. Every effort will be made to avoid
collection of duplicate data by combining test events and consolidating data requirements to
reduce redundant testing during follow-on IT&E and/or OT events. The responsible test
organization (RTO) will perform the tests while AFOTEC collects data points to supplement
 8                                                 AFOTECMAN99-101 11 OCTOBER 2012


OT&E data. If AFOTEC determines the data is operationally relevant and remains unaltered by
the developing contractor as the program matures, AFOTEC has the option to carry this data
forward to dedicated OT&E. The integrated test team (ITT) members will have the option to
review contractor test plans and procedures and provide comments to the system program office
(SPO)/program manager (PM). If possible, integrated test modifications that do not significantly
impact schedule or cost will be negotiated by the SPO/PM with the contractor, and the
appropriate changes for the development T&E (DT&E) test scenarios will be incorporated to
partially satisfy or to collect data against an operational requirement. IT&E requires diligence
and a cradle-to-grave focus from all AFOTEC personnel. Early and continuous collaboration
between the warfighter, acquisition, and T&E communities go a long way to increase
programmatic confidence (e.g., schedule, requirements stability, funding, and testability).
1.4. Office of the Secretary of Defense T&E Oversight List. AFOTEC is the operational test
agency (OTA) for all Air Force programs on the Office of the Secretary of Defense (OSD) T&E
Oversight List until OT&E is completed. Any program still on oversight after this fact belongs
to the owning major command (MAJCOM). Detachment Commanders (Det/CCs), test directors
(TDs), and technical advisors are responsible for knowing the oversight status of their programs
and ensuring the current status is updated on the AFOTEC Intranet (see paragraph 1.10 for
additional info).
1.5. Program Support by AFOTEC Liaison Officers. Liaison Officers (LNOs) can greatly
benefit AFOTEC by engaging with SPOs, Air Force Materiel Command (AFMC) and Air Force
Space Command (AFSPC) product centers, MAJCOMs, and other key agencies (e.g., Director,
OT&E (DOT&E), Air Force T&E (AF/TE), Joint Interoperability Test Command, test ranges,
etc.) early in the requirements, alternatives, and acquisition processes. The LNOs should support
early program activities by discovering emerging requirements and new acquisition programs,
and by obtaining key program documentation. By providing program support, LNOs ensure
AFOTEC’s planning considerations are addressed, external offices are educated about the
benefits of AFOTEC’s involvement, and communications are enhanced between other
organizations and AFOTEC. The AFOTEC Program Manager’s Operational Test Toolkit
provides a value-added product for AFOTEC personnel to leave behind with SPO and MAJCOM
personnel.
     1.5.1. AFOTEC LNO. The AFOTEC LNOs co-located with AFMC and AFSPC product
     centers or the Pentagon, act as on-scene representative of the AFOTEC/CC and fulfill a
     critical role in the AFOTEC early influence process. These liaison officers accomplish the
     following actions:
        1.5.1.1. Interface directly with their assigned product center counterpart and actively
        participate in the acquisition plan process and test strategy formulation as directed via
        AFOTEC tasking orders. The LNO should actively look for the following information:
        new program basics (such as program name, description and acquisition strategies), RTO,
        other points of contact (POCs), related program documentation, program reviews and
        forecasts, and other information that may be helpful to support tasking order (TO)
        preparation and establish collaborative IT&E planning efforts. Additional program
        information such as program priorities, requirements documents, Concept of Operations
        (CONOPS), operating plans, information support plans (ISP) and tactics, techniques, and
        procedures (TTP) should be obtained as available.
AFOTECMAN99-101 11 OCTOBER 2012                                                                    9


       1.5.1.2. Notify AFOTEC/CC, AFOTEC/A-3, and Dets of emerging projects/programs.
       1.5.1.3. Filter project/program information and recommend involvement initiation when
       appropriate.
       1.5.1.4. Notify AFOTEC/CC, AFOTEC/A-3 and Dets of issues of interest and key
       meetings requiring AFOTEC representation.
       1.5.1.5. Attend SPO/product center meetings addressing program development.
       1.5.1.6. Clarify AFOTEC policy and positions as required and refer questions to
       appropriate AFOTEC Det or headquarters (HQ) staff.
1.6. Staffing and Coordination. Many different documents originating both inside and outside
AFOTEC will require staff and executive review. AFOTEC/CC requires prompt information
update and exchange for OT&E activities. The HQ staff POC is responsible for the coordination
of a product within the HQ and with external agencies, as applicable; adjudicating HQ and
external comments to a product, as applicable; staffing in Task Management Tool (TMT) for
appropriate 2 Letter (2-Ltr) and Command Staff (AFOTEC/CS) coordination, and modifying the
product for final signature and subsequent publishing. Det/CCs will provide programmatic
updates at monthly stand-up or staff meetings when staff packages do not support time
constraints. These updates serve to quickly inform the AFOTEC/CS and key personnel; they do
not negate the requirement for officially staffed documents.
1.7. External Briefings. The AFOTEC/CC or AFOTEC/ED is the release authority for all
external briefings. DOT&E requires a test concept briefing for all oversight programs at least
180 days prior to test start, and delivery of the test plan at least 60 days prior to test start. The
associated final test plan briefing will be coordinated through Commanders Action Group
(AFOTEC/CCX) before submittal to DOT&E. Final report briefings are provided to HQ USAF
staff and the OSD as requested. Remember, when presenting an AFOTEC-approved briefing
externally any changes must be approved by the release authority. AFOTEC/CCX will
coordinate all external briefings (e.g. AF/TE and DOT&E).
1.8. Meeting Attendance. OT planners attend various acquisition meetings either in person, via
teleconference, or via video teleconference. Typical meetings include integrated product team
meetings, IT&E working group meetings, analysis of alternatives (AoA) meetings, ITT
meetings, etc. Depending on the program, the titles of these meetings may vary. The common
thread is that they are usually called by the SPO director or staff, or a developing contractor.
Test team members should actively monitor SPO activities for meetings that could be of benefit
to test planning activities. Taking an active role and seeking out information on SPO activities is
beneficial and can prevent surprises. Collateral visit requests are processed through AFOTEC
Information Protection (AFOTEC/CVI). Special Access Program (SAP) visit requests are
processed through Special Access Programs Division (AFOTEC/A-3Z) Security. Special
Compartmented Information (SCI) visit requests are processed through Intelligence Division
(AFOTEC/A-2N).
1.9. Security Management. AFOTEC/CVI and Det security mangers assist test team members
with security issues involving information protection, facilities, and equipment policy. Identify
appropriate security measures for the conduct of OT&E efforts for Information, Industrial,
Personnel, Physical and Operational Security, and Anti-terrorism/Force Protection. OT&E
 10                                                  AFOTECMAN99-101 11 OCTOBER 2012


planning and reporting must consider these security elements during the conduct of OT&E.
Security elements to consider during OT&E planning and reporting are:
   1.9.1. Information Protection. AFOTEC/CVI serves as the HQ point of contact for
   information protection (IP). The AFOTEC Vice Commander (AFOTEC/CV) and each
   Det/CC are ultimately responsible for the oversight and execution of security policy. IP
   involves safeguarding any data/information that potentially reveals US vulnerabilities,
   capabilities, capability gaps, or any data/information that has been determined, in the
   interests of National Security, to require a specific degree of protection against unauthorized
   disclosure, in which unauthorized disclosure could cause exceptionally grave or serious
   damage to the US Government.
   1.9.2. Documentation Markings. The proper marking of a classified document is the specific
   responsibility of the original or derivative classifier (DC) (i.e., the author or originator of the
   information). DCs shall refer to the source documents, security classification guides (SCG),
   or other guidance issued by the original classification authority (OCA) when determining the
   marking to apply. The criteria for classifying information is defined in AFI 31-401,
   Information Security Program Management, AFI 31-401 AFOTECSup, The AFOTEC
   Information Security Program, DoD Manual (DODM) 5200.1 V1, DoD Information Security
   Program: Overview, Classification, and Declassification; DODM 5200.1 V2, DoD
   Information Security Program: Marking of Classified Information; DODM 5200.1 V3, DoD
   Information Security Program: Protection of Classified Information; DODM 5200.1 V4,
   DoD Information Security Program:               Controlled Unclassified Information (CUI);
   Information Security Oversight Office (ISOO) Marking Classified National Security
   Information Manual; Intelligence Community Authorized Classification and Control
   Markings (CAPCO) Register and Manual; USAF Security Marking Guide for Special Access
   Programs; and applicable SCGs.
   1.9.3. Defense Technical Information Center. The Defense Technical Information Center
   (DTIC) assists DoD component officials in determining whether their existing security
   classification guidance may be relevant to their systems, programs, plans, or projects. This
   site provides information on current guides available and is restricted to registered users of
   DTIC Online Access Controlled. The AFOTEC/CVI staff are registered users and can obtain
   copies of a SCG, upon request. Det Security Managers can also obtain copies from the SPO.
   These guide(s) should be read and understood by all test team members, prior to the conduct
   of any OT&E efforts. Test team members should be aware that AFOTEC/CC does not have
   OCA. In the absence of a SCG, or if the SCG does not adequately cover capabilities,
   vulnerabilities, weaknesses and limitations, test team members should contact AFOTEC/CVI
   regarding the OCA process.
   1.9.4. Access to classified information. There are two basic prerequisites required for access
   to classified information: possession of a security clearance commensurate with the level of
   the classified information and a valid ―need to know‖ for the information. In some cases,
   personnel may require special access to North Atlantic Treaty Organization (NATO),
   Restricted Data (RD), Formerly RD (FRD), Critical Nuclear Weapons Design Information
   (CNWDI), and Nuclear Command and Control Extremely Sensitive Information (NC2-ESI).
   Access to special category programs must be approved in writing by AFOTEC/CV or
   AFOTEC, Chief, Information Protection. Access to store special category material must also
AFOTECMAN99-101 11 OCTOBER 2012                                                             11


   be approved in writing by AFOTEC, Chief, Information Protection. AFOTEC/CVI is
   responsible for the management of NATO, RD, FRD, CNWDI, and NC2-ESI programs.
   1.9.5. Derivative Classifier. AFOTEC personnel who have to develop classified material
   and/or have a Secure Internet Protocol Router Network (SIPRNet) account, must be
   appointed as a DC. Appointments must be made in writing by a Director or Det/CC and
   coordinated/approved by AFOTEC/CVI and/or Det Security Manager (SM). DCs are
   mandated to receive initial training and then maintain training every two-years, thereafter.
   AFOTEC/CVI and/or Det SM are responsible for administering the training.
   1.9.6. Operations Security. The AFOTEC Operations Security (OPSEC) Plan and Critical
   Information List, identifies OPSEC factors and critical elements of information test teams
   should consider in OT&E planning and reporting. AFOTEC/CVI is the primary AFOTEC
   OPSEC program manager. (Contact AFOTEC/A-3Z Security for SAP related OPSEC
   issues/concerns. Contact AFOTEC/A-2N for SCI related OPSEC issues/concerns.)
   1.9.7. Special Access Programs. Access to SAPs are managed by AFOTEC/A-3Z and
   impose controls beyond those normally required for Confidential, Secret, or Top Secret
   information. AFOTEC has one dedicated Program Security Officer that resides at Kirtland
   Air Force Base, New Mexico. The utilization of an Area Program Security Officer at each
   Det and/or operating location (OL) for paperwork approval (i.e., Standard Operating
   Procedures, OPSEC Plan, Security Incident Reports, Facility Accreditations Letters, Fixed
   Facility Checklists, Memorandum of Agreement (MOA), Memorandum of Understanding
   (MOU), Co-utilization Agreements, Self-inspection Reports, Waiver Letters, Equipment
   Approval Letters, SAP Form 6s, Notification of Foreign Travel, Master System Security
   Plans, Authority to Operate (ATO) Letters, System Security Plans SAP Form 16s, Word
   Processor and Personal Computer Data Sheet, SAP Form 26s, Equipment/Software
   Movement Request, and Software Approval Requests) is permitted; however, paperwork
   must be pre-coordinated with AFOTEC/A-3Z Security and/or information technology (IT)
   personnel. This type of structure will ensure the integrity of AFOTEC involvement in SAP
   programs and our facilities are maintained. (Contact AFOTEC/A-3Z for information
   pertaining to SAPs.)
   1.9.8. Special Compartmented Information. Access to SCI is managed by AFOTEC/A-2N
   and SCI imposes controls on intelligence information beyond those normally required for
   collateral Confidential, Secret, or Top Secret information. (Contact AFOTEC/A-2N for
   information pertaining to SCI.)
1.10. AFOTEC Intranet. The AFOTEC Intranet is a web-based internal network that
encompasses both Non-Secure Internet Protocol Router Network (NIPRNet) and SIPRNet. It
integrates a variety of data sources and applications into a centralized information portal,
providing a single source for DoD, Air Force, and AFOTEC policy and guidance. The NIPRNet
side of the AFOTEC Intranet is the primary repository for all test program documentation
(unclassified). Any classified documentation will be stored on the SIPRNet side of the AFOTEC
Intranet; documentation for SAP will be stored on a stand-alone system, not SIPRNet. These
sites contain general support information, specialized directorate information, and program
specific data, and allow AFOTEC PMs, test teams, and deployed test personnel to submit reports
and documents throughout the life of the program. These sites also allow AFOTEC's senior
leaders to have greater insight to upcoming events and prompt notification of significant
 12                                                AFOTECMAN99-101 11 OCTOBER 2012


occurrences, to include safety and mishap issues involving AFOTEC programs, personnel, or
resources.
1.11. AFOTEC Test Program Applications. The overall objectives of AFOTEC Test Program
Applications (ATPA) are to support effective and efficient management of AFOTEC test
programs. For each test program, the TD or PM who owns the program is responsible for
maintaining current, complete and accurate program information and documents (externally and
internally generated) in Test Program Management (TPM) application. TPM is used to record
and maintain vital test program information (scheduled activities, current status, program issues,
etc.) AFOTEC/A-3 is responsible for posting all AFOTEC/CS approved documents to the
program’s TPM page and the owning Det will post all other program documents. The Det TD
will accomplish a monthly certification of their programs’ TPM pages for currency and accuracy.
The TMT application is used to coordinate specific test program documents, including TOs,
T&E Strategies (TESs), T&E Master Plans (TEMPs), Test Plans, Test Reports, briefings, etc.
AFOTEC/A-3 is responsible for staffing of all external program documents for 2-Ltr
coordination and all program documents for AFOTEC/CS review and approval.
1.12. Training. All formal training for AFOTEC is accomplished and managed by AFOTEC’s
Training Division. Your unit training monitor helps manage training through the AFOTEC
Training Management. Supervisors are responsible for ensuring all personnel (officer, enlisted,
and civilian) in-process with their respective training manager. During in-processing, AFOTEC
members will receive their individual training plan (letter of Xs) and career development training
plan. Contact your training monitor for your training status including completed, required, and
projected training.
1.13. AFOTEC HQ Standardization and Evaluation. Standardization and Evaluation
(Stan/Eval) is vital to AFOTEC’s operational test mission and is continuously executed through
a variety of AFOTEC operational test processes, procedures, tools and reviews designed to
enable efficient development of products and effective feedback. AFOTEC/A-3 is responsible
for leading overall development, management, and execution of AFOTEC operational test
program Stan/Eval products, processes, procedures, tools and reviews with support from
AFOTEC/A-2/9, AFOTEC/A-5/8, and AFOTEC/SE. Additionally, successful execution of
Stan/Eval requires AFOTEC A-2/9, AFOTEC/A-5/8, and AFOTEC/SE lead development,
management and execution of specific areas of Stan/Eval.
1.13.1. Roles and Responsibilities. AFOTEC/A-2/9 ensures technical adequacy, test design, test
measures development, relevant threat environments, data collection methods, scoring, analysis,
modeling and simulation, human factors analysis, and test capability accreditation. AFOTEC/A-
3 ensures operational sufficiency, test design, end-product quality, credibility, effective
feedback, and timeliness of all internal and external operational test program plans, reports and
program related documentation. AFOTEC/A-5/8 ensures compliance with policy, accurate
development of test resource plans, sufficiency of test resources, requirements review, and test
infrastructure. AFOTEC/SE advises on systems safety requirements and analysis and ensures
compliance with Environmental, Safety, and Occupational Health (ESOH) standards during test
planning and execution.
1.14. Technical and Scientific Support. OT planners may identify technical needs required to
perform specific tasks and should become aware of any test support shortfalls that may exist as
the first test resource plan (TRP) is being developed. OT planners should explore the availability
AFOTECMAN99-101 11 OCTOBER 2012                                                                13


of technical support from AFOTEC/A-2/9, the Det technical advisor, and other external military
organizations or government agencies. AFOTEC/A-2/9 provides technical and scientific support
in the areas of test methods, analysis techniques, human factors, modeling and simulation
(M&S), man-made and natural threats, and reliability, maintainability, and availability.
AFOTEC/A-2/9 preserves technical adequacy and credibility through ensuring feasible test plans
and test reports, analytically-sound measures and methods, and supportable conclusions for
OT&E. AFOTEC/A-2/9 is responsible for providing test teams with M&S guidance. The Test
Infrastructure Division (AFOTEC/A-5R) and (Long Range Investments Division
(AFOTEC/A8R) for Nevada Test and Training Range (NTTR)) identifies and advocates the
development of solutions to test capability shortfalls (open air range, ground test facilities,
instrumentation, targets, and M&S) to support test teams. Note: All new AFOTEC-funded
contractor efforts must be approved in writing by the AFOTEC/CV.
1.15. Lessons Learned. Continuous improvement of AFOTEC’s products and business
practices is facilitated through shared learning experiences. Lessons Learned (L2) are uncovered
in all areas of planning, execution, reporting, and closeout and must be collected after each test
activity. There are three types of L2: Topical (specific area of interest); After-Action (hot wash
or post-activity event); and Event Driven (tied to a specific event). The AFOTEC L2 process has
four steps: Collection, Validation, Dissemination, and Resolution. For more specific detail,
direction or additional assistance, refer to the Lessons Learned community on the AFOTEC
SharePoint or contact AFOTEC/A-2/9 (L2 Manager).
1.16. Risk Management. AFOTEC uses Risk Management (RM) throughout a program. As
defined in AFI 90-802, Risk Management, RM is a continuous process designed to detect, assess,
and control risk while enhancing performance and maximizing combat capabilities. RM enables
all personnel to maximize operational capabilities while limiting all dimensions of risk by
applying a simple, systematic process. Appropriate use of RM increases both our organizational
and individual ability to accomplish the mission, whether planning a test, collecting data,
executing test activities, or reviewing test data. AFOTEC/SE and Det safety personnel will assist
the TD in applying the RM process to their programs and will facilitate the evaluation of system
hazards that may affect the test.
1.17. Rapid Test Considerations. The need for rapid response stems from a rapidly evolving
warfighting environment and the acquisition community’s quick response to today’s threats
through various approaches. These approaches could include Joint Concept Technology
Demonstration (JCTD) and formal Urgent Operational Need (UON) acquisitions. From
AFOTEC’s perspective, rapid acquisition means short-notice, rapid response and right-sizing
planning timelines without sacrificing OT&E rigor. The ―Rapid Test‖ process formally
recognizes the need, intent, and capability to respond quickly. The Rapid Test capability
emphasizes speed and flexibility. However, a standardized process will be applied.
 14                                                AFOTECMAN99-101 11 OCTOBER 2012


                                           Chapter 2

                  AFOTEC ACTIVITIES SUPPORTING MILESTONE A

Section 2A—Overview

2.1. Introduction. The Det/CC, assisted by the Det technical advisor, is responsible for test
team activities and products leading up to Milestone (MS) A. Pre-MS A early influence
activities afford AFOTEC the greatest opportunity to influence emerging capabilities; it
formalizes AFOTEC program involvement and provides standardized methodologies for
influencing capability requirements development, program acquisition strategies, and T&E
strategies and plans. Early influence leads to identification and correction of issues that might
proliferate or become more difficult to solve later in the acquisition process. The Det, an LNO,
or AFOTEC/A-3 gathers program status, programmatic, and operational information relevant to
each program. During information gathering there may be additional considerations to address
such as multi-service involvement, non-traditional innovation efforts, or urgent warfighter needs.
   2.1.1. Depending on program maturity a formal involvement determination may be initiated.
   The involvement determination process culminates with a signed involvement letter (IL) and
   TO which defines the scope of involvement, the resource allocation bounds, and team
   responsibilities during early influence, planning, execution, and reporting including the need
   for an OL and required deliverables to be produced. The signed IL is transmitted to AF/TE
   and other program stakeholders to document AFOTEC’s formal involvement or non-
   involvement. The IL and TO may be executed concurrently or separately based on program
   schedule requirements.
   2.1.2. During pre-MS A early influence, the Det, an LNO, and/or AFOTEC/A-3 investigates
   current and future concepts of operations; gathers and assesses capabilities requirements and
   risk assessment information (capability gaps and programming) for application to IT&E;
   coordinates with other elements of the Air Force requirements and acquisition community to
   include MAJCOMs, Air Staff, Air Force Requirements Oversight Council (AFROC), HQ
   AFMC, HQ AFSPC, product centers, or laboratories; monitors understanding of scenarios
   used for defense planning; coordinates with the joint community; and obtains the results of
   technology demonstrations. The early work is accomplished to maintain cognizance of the
   acquisition and operational environments to support IT&E planning and to anticipate the
   nature and extent of OT&E involvement in future programs (specifically, to support early
   acquisition involvement in high performance teams (HPT), requirement strategy review
   (RSR), initial capabilities document (ICD), course of action (COA), technology development
   strategy (TDS), TES, functional solution analysis/analysis of materiel approaches, and AoA).
   2.1.3. AFOTEC/A-3 and the Det TD make first contact with the SPO in order to establish
   communication between the acquisition PM and developmental test personnel. The TD and
   AFOTEC/A-3 should review the acquisition process for the program using the AFOTEC-
   developed PM’s Operational Test Toolkit. The TD should be sure to discuss the readiness to
   test approach that will be applied for the program. Following initial contact, the TD is kept
   apprised of program developments by AFOTEC/A-3. The TD provides overall credibility to
   the early influence process while the AFOTEC/A-3 personnel provide continuity on the
AFOTECMAN99-101 11 OCTOBER 2012                                                                   15


   program. Activities for innovation programs and UONs should follow a similar path, but are
   expedited to accommodate the project schedule.

Section 2B—External Support Documents

2.2. Ongoing Activities. During the life of an OT&E program, several activities are done
repeatedly. AFOTEC’s participation may vary depending on the situation and level of
involvement. Some of these activities include reviewing and commenting on various documents,
developing and updating TEMP and Life Cycle Management Plans (LCMP), attending meetings,
maintaining the AFOTEC Intranets, tracking system certification and readiness status, inputting
lessons learned, obtaining contractor technical services, and presenting briefings. AFOTEC
helps prepare key requirements and acquisition documents so that IT&E concerns are
incorporated into the acquisition process. AFOTEC/A-3 manages the review process for all
program documents. Some of the key requirements and acquisition documents are discussed in
the following paragraphs.
2.3. Initial Capabilities Document. The ICD identifies the need for a materiel solution. The
ICD supports the AoA, the TDS, the MS A acquisition decision, and subsequent technology
development activities. The ICD defines the capability gap in terms of the functional area, the
relevant range of military operations, desired effects, and time. The ICD is normally developed
while the program is still in early influence and forms the foundation for initial test design (ITD).
2.4. Acquisition Decision Memorandum. The Acquisition Decision Memorandum (ADM)
documents the decisions made and exit criteria established for the materiel development decision
(MDD). The ADM specifies what is to be done prior to the MS A decision. Operational testers
need to be cognizant of and implement the decisions documented in the ADM. Det/CCs ensure
ADMs are sent to AFOTEC/A-3 for 2-Ltr coordination and AFOTEC/CS review. The
AFOTEC/CC or Executive Director (AFOTEC/ED) may approve the ADMs based on the
program’s acquisition category (ACAT) level.
2.5. Preliminary Concept of Operations. To support the ICD, the user produces a preliminary
CONOPS that defines notional system employment and support procedures. Standards are
specified for deployment, organization, command and control, basing, and support. This gives
an understanding of how the user plans to employ the system which is used to help develop the
ITD. The CONOPS will continue to develop throughout the acquisition cycle as the system
technologies mature and the enabling concept is defined.
2.6. Analysis of Alternatives. An AoA is conducted following an MDD and validation of the
ICD. The focus of the AoA is to refine the selected concept documented in the validated ICD.
The AoA assesses the critical technologies associated with these concepts, including technology
maturity, technology risk, and, if necessary, technology maturation and demonstration needs.
This analysis aids decision-makers in judging whether or not any of the alternatives offer
sufficient benefit that is worth the cost. AFOTEC’s participation in the AoA process can afford
insight into the CONOPS, mission tasks, and model scenarios, as well as leveraging information
for early influence and initial test design activities. The responsible Det and/or AFOTEC/A-3
may periodically provide input to the AoA Study Plan (AoA linkage to the requirements
document and test plan) that is provided to the AFROC. See AFI 10-601, Capabilities-Based
Requirements Development, and the AFMC Office of Aerospace Studies website located at
 16                                                 AFOTECMAN99-101 11 OCTOBER 2012


http://www.oas.kirtland.af.mil for more information on AoAs. AFOTEC/A-3 has developed a
checklist to assist in reviewing AoA documents.
2.7. Course of Action. The COA is a planning and decision process that culminates in a
MAJCOM commander decision. The COA includes a series of alternative program choices
developed by the Milestone Decision Authority (MDA) or a designate, in conjunction with the
user, and presented to a MAJCOM commander. Once a specific COA is selected, it becomes a
formal agreement between the MDA and the MAJCOM commander that clearly articulates the
performance, schedule, and cost expectations of the program. The COA provides the basis for
the TDS during the Technology Development Phase and the basis for the LCMP. The COA is
designed to address differences in expectations up front and to develop a common understanding
and agreement on program expectations. Approval at the MAJCOM commander/MDA level of
the selected COA ensures agreement among leadership on program expectations – performance
(or incremental performance) at the specified cost and schedule. For each alternative program
choice, the testers (developmental and operational) provide a preliminary TES for the alternative.
The preliminary TES for the selected alternative serves as the basis for the final TES, the TEMP,
or the LCMP as applicable in support of the MS decision.
2.8. Modeling & Simulation Support Plan. The Modeling & Simulation Support Plan
(MSSP), developed by the SPO, captures all the M&S requirements over the life cycle of an
acquisition program including those for DT and OT. TDs need to be aware of the MSSP and
ensure OT M&S requirements identified are included as early as possible in order to be a part of
the SPO's M&S funding strategy (the PM is responsible for funding required M&S resources).
Contact AFOTEC/A-2/9 if any questions arise concerning M&S. Reference DODI 5000.02 and
AFI 16-1002, Modeling and Simulation (M&S) Support to Acquisition.
2.9. Life Cycle Management Plan. The LCMP integrates the acquisition and sustainment
strategy(ies) and provides all support requirements of a system, subsystem, or major end item. It
references the systems engineering plan, which is designed to ensure supportability
considerations are implemented during the design, development, production and sustainment of a
weapon system. An effective product support strategy establishes the initial foundation for the
collaboration of acquisition and sustainment planning concepts and allows for the eventual
transfer of program management responsibility from the Program Executive Office (PEO)
portfolio to the Air Force Sustainment Center portfolio. If there is not a TES for the program,
the LCMP should contain all of the information that would have been contained in the TES to
provide integrated test planning to minimize test event duplication and streamline the process. If
there is both an LCMP and a TES for the program, the LCMP can contain a summary of the test
program as documented in the TES.
2.10. Information Support Plans. The ISP is developed by the SPO for all ACAT and non-
ACAT acquisitions and procurements to document IT and National Security Systems (NSS)
needs, dependencies, interface requirements, and the net-ready key performance parameters
(NR-KPP). The plan describes system dependencies and interface requirements in sufficient
detail to enable testing and verification of IT and NSS interoperability and supportability
requirements. The ISP also includes IT and NSS systems interface descriptions, infrastructure
and support requirements, standards profiles, measures of performance, and interoperability
shortfalls. The scope of the ISP is scaled to the relative size and funding profile for the program.
The sponsoring or cognizant authority reviews, assesses, and approves the ISP for non-ACAT
acquisitions and procurements, and forwards any critical interoperability or supportability issues
AFOTECMAN99-101 11 OCTOBER 2012                                                               17


to the Assistant Secretary of Defense (Networks and Information Integration/DoD Chief
Information Officer) and the applicable Functional Capabilities Board for review. The TD and
AFOTEC/A-3 staff should pay particular attention to the ISP development because of the
system-of-systems approach required to be described by the plan. Also of interest are the
DOT&E special interest items of information assurance and interoperability. They should ensure
the mission assurance category (MAC) code and confidentiality level are identified for
unclassified and collateral secret systems (see DODD 8500.01E, Information Assurance (IA)).
For Special Access Required, SAP, and SCI programs, they should ensure Protection Level,
Level-of-Concern and Security Features and Assurances are identified based on Intelligence
Community Directive 503, Intelligence Community Information, Technology Systems Security
Risk Management, Certification and Creditation, Committee on National Security Systems
Instruction (CNSSI) Number 1253, Security Categorization and Control Selection for National
Security Systems, Director of Central Intelligence Directive (DCID) 6/3, Protecting Sensitive
Compartmented Information within Information Systems, and/or Joint Air Force – Army – Navy
(JAFAN) 6/3, Special Access Program, Security Manual, Revision 1.
2.11. Information Assurance Strategy. The IA Strategy provides documentation that ―Ensure
that the program has an information assurance strategy that is consistent with DoD policies,
standards and architectures, to include relevant standards.‖ Prior to MS A the IA Strategy should
identify the Certification and Accreditation (C&A) process required by the system: DoD
Information Assurance Certification and Accreditation Process (DIACAP), National Institute of
Standards and Technology (NIST) 800-37, Certification and Accreditation Process, platform
information technology determination process or Intelligence Community Directive 503
certification process for sensitive compartment programs. The IA Strategy also ensures
compliance with the statutory requirements of USC, Title 40, Public Buildings, Property, and
Works, and related legislation, as implemented by DODI 5000.02.

Section 2C—Processes, Procedures, and Products.

2.12. Program Identification. Program identification is the initial step in beginning an OT&E
program within the early influence phase. In the program identification step, initial contact is
established with program sponsors and developers (e.g. MAJCOMs, AFMC or AFSPC product
centers, joint commands). Program information is gathered and AFOTEC/A-3 will track and
provide regular updates to the AFOTEC/CC and Dets on programs in a pre-involvement status.
The AFOTEC/CC approves all significant program related effort and travel prior to formal
AFOTEC involvement.
2.13. Program Involvement. When early OT&E efforts are not yet defined and AFOTEC
involvement is warranted, AFOTEC/A-3 recommends an executing Det and staffs an
involvement package. The involvement recommendation is based on AFI 99-103 guidance,
specifying which programs AFOTEC is responsible for. AFOTEC/A-3 prepares an involvement
package when AFOTEC is the default operational test organization or when AFOTEC accepts a
MAJCOM request to be the OT organization. AFOTEC/A-3 will develop, coordinate, and staff
all involvement/non-involvement packages for AFOTEC/CC approval. The involvement
package includes the IL, TO, bullet background paper (BBP) on the program, and any supporting
program documents. The format for the BBP can be found in the AFOTEC Library on the
AFOTEC Intranet.
 18                                                 AFOTECMAN99-101 11 OCTOBER 2012


2.14. Initial Test Resource Plan. The AFOTEC/A-3 test resource manager (TRM), in
conjunction with the Det TRM and test team members as required, prepares an initial TRP no
later than (NLT) 60 days after the TO is approved. The initial TRP is then updated during
program updates. The TRP is accessed through the AFOTEC Intranet. TRPs are not
initiated/required for: programs in pre-involvement; programs for which the Det (or
AFOTEC/A-3) plans to recommend ―non-involvement‖ to AFOTEC/CC; programs in which the
first OT&E activity (EOA/OA, OUE, or OT&E) is scheduled outside of eight years from the
requirements review board (RRB) (contact Programming Division for RRB information). Note:
For SAP, the AFOTEC/A-3Z TRM, in conjunction with the Det TRM (as appropriate) and test
team members as required, prepares an initial TRP NLT 60 days after the TO is approved. The
SAP TRP will be handled via special procedures and not through the AFOTEC Intranet. All
funding will be coordinated with AFOTEC/A-3Z TRM through proper communications
channels. No RRB inputs should be made for SAP without AFOTEC/A-3Z prior approval.
   2.14.1. External Funding for AFOTEC Programs. All new requests for external funding
   (including to SPOs and MAJCOMs) must go through AFOTEC/A-5/8 and Installations and
   Mission Support Directorate (AFOTEC/A-4/7). AFOTEC pays for all IOT&Es, FOT&Es,
   and QOT&Es out of our 3600 and 3400 program elements (PEs). In addition, our PEs are
   designed to accommodate start-up costs associated with new test programs, as well as most
   schedule slips. Exceptions arise when 1) awareness of a new program and an involvement
   determination occur within 18 months of planned test start (so-called ―pop-up‖ programs), 2)
   test costs increase due to acquisition program slippage or deferments, or 3) the total cost of a
   test program exceeds $8 million. If you believe external funding is warranted on a program,
   do not directly request funds from an external organization. Submit your rationale to
   AFOTEC/A-4/7 for current year issues and AFOTEC/A-5/8 for future year issues.
   AFOTEC/A-4/7 and AFOTEC/A-5/8 will confer, make a determination, and then make the
   request (if needed) to the appropriate external funding source.
2.15. High Performance Teams. HPTs are convened to support AF Requirements Office
(AF/A-5R) in the development of program requirements documents. The owning Det and
AFOTEC/A-3 will send representatives to attend and support all HPTs. Primary considerations
during the HPT are soundness of operational capability requirements, the testability of those
requirements, and a listing of potential operational capabilities needed to fill the identified
capability gap. AFOTEC/A-3 tracks HPT schedules and ensures Det awareness.
2.16. Integrated Test Team & Charter. The ITT, co-chaired by AFOTEC and the SPO, is
established to involve all T&E stakeholders in a program as early as possible and to facilitate and
coordinate IT&E planning. The ITT is the body that develops the required T&E documentation
for the program and continues through IT&E execution and reporting. AFOTEC will request
initiation of ITT charters within 60 days of the MDD, but not later than MS A or a TES
development, whichever comes first. For MOT&Es where AFOTEC is not the lead OTA, the
lead OTA’s procedures for test planning and management is followed.
   2.16.1. Charter. A formal, signed ITT charter is required for all ITTs and describes team
   membership, responsibilities, resources, and the products for which the ITT is responsible.
   While the ITT charter is owned by the SPO, the test team needs to ensure the SPO is aware
   of AFOTEC-unique requirements for an event-driven deliverable table and a conflict
   resolution chart in the charter. The charter is staffed by AFOTEC/A-3 for 2-Ltr coordination
   (AFOTEC/A-3 and AFOTEC/A-5/8 only) and AFOTEC/CS review for approval/signature
AFOTECMAN99-101 11 OCTOBER 2012                                                                  19


   by the AFOTEC/CV. The owning Det is responsible for supporting adjudication of
   comments and interaction with the SPO.
2.17. Certification of Readiness for Operational Test & Evaluation. A structured
mechanism or ―process‖ to identify problems and risks associated with transitioning from DT&E
to dedicated OT&E. It establishes a disciplined review and ―certification process‖ beginning in
the early stages of acquisition programs and culminating in certifications leading to more
successful OT&E outcomes. The certification process is a tool to help acquisition managers at
all levels identify risks, reach negotiated agreements on issues, and render more accurate
assessments of a system’s readiness to begin dedicated OT&E. The process includes a review of
DT&E results; an assessment of the system’s progress against critical technical parameters
documented in the TEMP; an analysis of identified technical risks to verify that those risks have
been retired during DT; and a review of the IOT&E entrance criteria specified in the TEMP.
(Reference AFMAN 63-119, Certification of System Readiness for Dedicated Operational Test
and Evaluation, for additional info.)
2.18. The Core Team. The core team is composed of AFOTEC Det and HQ personnel, user
representatives, and SPO representatives. The Det TD is the program lead for the team. The
headquarters staff is responsible for the coordination of a product within the HQ and external
agencies, as applicable; adjudicating HQ and external comments to a product; and modifying the
product for final signature and subsequent publishing. An AFOTEC HQ core team member’s
general responsibilities include ensuring the AFOTEC/CC’s intent is incorporated into all
products as early as possible to facilitate the staffing process.
2.19. Initial Test Design Process. The core team is responsible for executing the ITD process.
During the ITD process the Det TD has operational control and AFOTEC/A-3, with
AFOTEC/A-2/9 support, has process control to ensure overall technical and procedural integrity
is maintained. The ITD provides the foundation for an operation’s based test design and applies
scientific principles, such as Design of Experiment (DOE), to ensure technical adequacy. DOE
principles encompass a suite of techniques to design and analyze tests in an efficient, effective,
and comprehensive manner. DOE supports the intent of test design by helping identify and
manage factors in the operational test environment. The ITD fleshes out and documents the
details that are known in order to build a solid basis for a test approach and to communicate that
approach with others. The test approach is developed by identifying the operational conditions
and testing constraints, thereby leading to a set of high-return test events. Further discussion
leads to a basis of estimate and identification of resources (test articles, personnel, etc.),
determination of execution methodologies (field test, distributed test, M&S, etc.), identifying test
capability requirements and shortfalls, and refinement of the OT activities and schedule (IT&E,
EOA/OA, OUE, OT&E, or combinations). ITD culminates in a viable test design. It ensures the
level of involvement is appropriate, the cost is as accurate as possible, and that the core team has
laid the foundation of an operationally and technically adequate, credible and sufficient OT
where limitations and mitigation plans are clearly identified. The test design should be
operationally representative and adequate, but still affordable.
   2.19.1. Program Documentation. The ITD process relies heavily on the system employment
   and support concepts, capability requirements documents, and program acquisition strategy
   (additional documents may be used as required). AFOTEC/A-3 tracks the availability and
   completeness of program documentation and provides feedback to the community. In cases
   where program documentation is non-existent or only in draft form, the core team can expect
 20                                                  AFOTECMAN99-101 11 OCTOBER 2012


   final documents to change portions of the ITD. The core team should plan for ITD updates
   and validation prior to subsequent milestones and detailed test planning (see paragraph 3.15).
   In instances where AFOTEC can positively impact the requirements process, feedback or
   issues should be elevated through the Det/CC and AFOTEC/A-3 to the AFOTEC/CC for
   action.
   2.19.2. Initial Resource Estimates. The core team uses the ITD basis of estimate to further
   refine initial resource estimates documented in the initial TRP. The Det TRM updates the
   TRP to support the ITD. The TD and Det TRM review each resource category of the TRP to
   determine which line items need costing and what items AFOTEC typically pays for.
   2.19.3. Initial Test Design Briefing. The TD develops the ITD briefing with core team
   support for presentation to AFOTEC/CC or AFOTEC/ED, depending on the program’s
   ACAT level. The purpose of the ITD briefing is to convey to the AFOTEC/CC, with a high
   degree of confidence, the complete, beginning to end scope of OT activities, resources, and
   costs with rationale. The ITD briefing indicates the specific acquisition events that the
   planned OT activities support. The Det TD presents the acquisition information in a briefing
   to the AFOTEC/CC with the objective of receiving approval for an updated TO. The
   detailed briefing guide for the ITD is found on the AFOTEC Intranet.
   2.19.4. Early Multiservice Operational Test & Evaluation Considerations. As the lead OTA
   for early MOT&E activities, AFOTEC will execute all of the ITD process requirements
   including a briefing to gain approval. As a supporting OTA, AFOTEC will follow the
   processes and requirements of the lead Service OTA.
2.20. Tasking Order Update. AFOTEC/A-3 will prepare the TO update and load the
document into TMT for 2-Ltr and AFOTEC/CS coordination for approval/signature by the
AFOTEC/CC. The updated TO provides the AFOTEC/CC broad direction on the scope of the
evaluation and team responsibilities during planning, execution, and reporting including the
required deliverables to be produced during the execution of the TO. The TO package includes
an updated TRP as well as the program’s RRB slides. If programmatics dictate AFOTEC non-
involvement in a program after a TO has been issued (e.g., a program is cancelled), the
responsible Det will initiate the closeout process. (See paragraph 6.3 for additional info.)
2.21. Test Resource Plan Update. As explained in the earlier paragraphs regarding developing
the initial TRP, the resource requirements are identified in sufficient detail to support preparation
of a TRP (AFOTEC/A-3Z leads TRP activities for SAPs). An update of the resource
information should be accomplished after the basis of estimate is completed. The TRP is the
planning and management document that provides the means for programming all resources to
support OT&E, and is the source for OT&E inputs to the Air Force planning, programming,
budgeting, and execution system throughout the test. If a resource is not specified in the TRP, it
will not be planned or programmed for the upcoming test. (See paragraph 2.14 for additional
info.)
2.21.1. Test Capability Overview. Test capabilities are assets that are used in conjunction with
the system under test or a representation of the system under test to generate data for test
measures. AFOTEC does not own or operate any test range, facility, or asset. AFOTEC
leverages external funding to develop the required test capabilities. Test capabilities include test
ranges, instrumentation and data collection systems, ground test facilities, distributed test
capabilities, test drivers and digital modeling capabilities. Establishing and maintaining
AFOTECMAN99-101 11 OCTOBER 2012                                                                 21


adequate test capability is essential to the AFOTEC core mission of determining operational
capabilities and limitations of AF and joint systems. Test capabilities enable test teams to expose
systems under test to operationally realistic environments.
2.21.2. Test Capability Shortfalls. Test capabilities are developed and maintained to support
testing of advanced weapons systems that exploit the latest technologies. These important test
resources could take 5 to 10 years to design and build, so the TD should analyze the shortfalls
and include the shortfalls in an updated TRP as appropriate. The TRP needs to be in sufficient
detail to ensure it provides test resources in a timely manner. (The Det, AFOTEC/A-2/9, and
AFOTEC/A-5/8 work collaboratively to ensure test capabilities are properly accredited for use in
OT&E. AFOTEC/A-2/9 is the AFOTEC POC for M&S test capabilities and test capability
accreditation.)
2.22. Test and Evaluation Strategy. Programs that undergo a MS A decision have a TES. The
ITD process defines the OT requirements for the TES. The TES describes how T&E and M&S
are applied to confirm that each increment provides its required operational effectiveness,
suitability and mission capability. The Defense Acquisition Guidebook (DAG) outlines content
expectations for the TES including items such as critical operational issues, scope and structure
of the operational evaluations, T&E schedule, etc. Additionally, it is desired that the TES
describe, in as much detail as possible, the risk reduction efforts across the range of activities
(M&S, DT&E, OT&E, etc). The AFOTEC/CC coordinates on the TES; Under Secretary of
Defense for Acquisition, Technology and Logistics (USD(AT&L)) and DOT&E approve the
TES.
 22                                               AFOTECMAN99-101 11 OCTOBER 2012


                                          Chapter 3

                 AFOTEC ACTIVITIES SUPPORTING MILESTONE B

Section 3A—Overview

3.1. Introduction. The Det/CC, assisted by the Det technical advisor, is responsible for test
team activities and products between MS A and MS B. The activities include reviewing any
updates to existing or new external documentation, reviewing and updating the test design and
TO, participating in the HPT for production of the capability development document (CDD),
developing inputs to the MS B TEMP, and conducting a MS B EOA.

Section 3B—External Support Documents

3.2. Acquisition Decision Memorandum Update. The ADM documents the decisions made
and exit criteria established at the MS A decision review. The ADM specifies the pre-requisites
to the MS B decision. Operational testers need to be cognizant of and implement the decisions
documented in the ADM. Det/CCs ensure ADMs are sent to AFOTEC/A-3 for 2-Ltr
coordination and AFOTEC/CS review. The AFOTEC/CC or AFOTEC/ED may approve the
ADMs based on the program’s ACAT level. (See paragraph 2.4 for additional info.)
3.3. Capability Development Document. For programs where AFOTEC is the lead OTA,
AFOTEC/CC certifies requirements in the CDD are testable and measurable in conjunction with
the AFROC. The CDD captures the information necessary to develop a proposed program,
normally using an evolutionary acquisition strategy. The CDD outlines an affordable increment
of a technically mature capability with military utility. The CDD supports the MS B acquisition
decision. The CDD provides the operational performance attributes necessary for the acquisition
community to design the proposed system, including key performance parameters (KPPs) that
guide the development and demonstration of the current increment. The performance attributes,
including the KPPs, are expressed as thresholds and objectives. Performance attributes have
previously been referred to as performance parameters or performance requirements.
3.4. Analysis of Alternatives Update. The AoA is updated following a MS A decision and
validation of the ICD. The focus of the AoA is to refine the selected concept documented in the
validated ICD. AFOTEC/A-3 has developed a checklist to assist in reviewing AoA documents.
(See paragraph 2.6 for additional info.)
3.5. Modeling & Simulation Support Plan Update. The MSSP, updated by the SPO, captures
all updated M&S requirements over the life cycle of an acquisition program including those for
IT&E. TDs need to be aware of the MSSP and ensure OT M&S requirements identified are
included as early as possible in order to be a part of the SPO's M&S funding strategy (the
SPO/PM is responsible for funding required M&S resources). Reference DODI 5000.02 and
AFI 16-1002. TDs need to work with the SPO early in the program to develop models that will
satisfy both DT and OT requirements. Contact AFOTEC/A-2/9 if any questions arise concerning
M&S. (See paragraph 2.8 for additional info.)
3.6. Life Cycle Management Plan Update. The LCMP is updated for MS B and integrates the
acquisition and sustainment strategy(ies) and provides all support requirements of a system,
subsystem, or major end item. If there is both an LCMP and a TEMP for the program, then the
AFOTECMAN99-101 11 OCTOBER 2012                                                               23


LCMP can contain a summary of the test program as documented in the TEMP. If there is not a
TEMP for the program, then the LCMP contains all of the information that would have been
contained in the TEMP to provide an integrated test plan and minimize test event duplication and
streamline the process. If there is only an LCMP required for the program, the TD should ensure
the required KPP/key system attributes are addressed in the LCMP (e.g., sustainment KPP and
materiel availability KPP). (See paragraph 2.9 for additional info.)
3.7. Information Support Plans Update. The ISP is updated by the SPO for all ACAT and
non-ACAT acquisitions and procurements to document IT and NSS needs, dependencies,
interface requirements, and the NR-KPP. (See paragraph 2.10 for additional info.)
3.8. Information Assurance Strategy. The IA Strategy is reviewed at all Acquisition MS
Decisions, including early MSs when C&A documentation may not yet be available. It is written
at a higher level than the DIACAP or other C&A process documentation, and it provides
necessary details such as MAC, confidentiality level, applicable baseline IA controls, and
identifies the appropriate C&A process. (See paragraph 2.11 for additional info.)
3.9. Authority to Operate or Interim Authorization to Operate. The ATO/Interim
Authorization to Operate (IATO) and the request package (including the Information
Technology Security Plan of Action and MS, or plan of action and MSs (POA&M)) will provide
insight into the system’s IA readiness for operational test. It will also provide background for
developing test scenarios that consider realistic threats in the operational environment.
3.10. Security Classification Guide. The SCG provides security instructions for all military
and civilian personnel working on a system. It is available from the SPO and should be read and
understood by all core/test team members to avoid security violations. Working papers, test
reports and briefings, computer operations, telephone conversations, mailing, courier deliveries,
and meetings are governed by the SCG. Core/test team members should also be aware that
AFOTEC/CC does not have OCA. In the absence of a SCG, or if the SCG does not adequately
cover capabilities, vulnerabilities, weaknesses and limitations, core/test team members should
contact AFOTEC/CVI regarding the OCA process. (See paragraph 1.9 for additional info.)
3.11. Threat Assessment Documents. Validated intelligence products should be used to
establish operational realism for man-made threats during OT&E. The most authoritative threat
data reference for an acquisition program is the system threat assessment report (STAR),
generated by a designated intelligence production agency such as the National Air and Space
Intelligence Center (NASIC). The STAR describes the lethal and non-lethal threats against the
proposed system and the future threat environment in which the system operates. However,
STARs are usually only produced for ACAT I programs; ACAT II and III programs use either a
system threat assessment (STA), or one or more capstone threat assessment documents as a
primary threat reference. Capstone threat assessments describe threats to broad classes of
systems; published capstone threat assessments include those for air, missile defense,
information operations, chem/bio, and the interim space capstone threat assessment.
Additionally, OSD-validated defense planning scenarios should be used when building the test
threat list and the battlespace environment for the system under test. The OT planners should
use only the most current versions of these documents to develop the TEMP and to determine if
a new program meets user requirements. Det intelligence analysts are the point of contact for
obtaining any of these documents (most are available online on SIPRNet), and for providing
intelligence updates that may impact ongoing test planning. Det intelligence analysts and
 24                                                  AFOTECMAN99-101 11 OCTOBER 2012


AFOTEC/A-2/9 work closely with the TD to ensure that operationally realistic threats (including
natural environment threats) are used as a basis for test.
3.12. Request for Proposal. Request for Proposals (RFPs) are used in negotiated acquisitions
to communicate Government requirements to prospective contractors and to solicit proposals.
The RFPs for competitive acquisitions, at a minimum, describe the Government's requirement;
anticipated terms and conditions that apply to the contract; information required to be in the
offeror's proposal; and factors and significant subfactors that are used to evaluate the proposal
and their relative importance. To support IT objectives it is imperative that the RFP address
AFOTEC’s requirement to have the same data and data access required by the SPO or the RTO
conducting DT&E. Successful IT requires meaningful access to review contractor and
developmental test plans and procedures, test events, and DT data.

Section 3C—Processes, Procedures and Products.

3.13. High Performance Team. HPTs are convened to support AF/A-5R and the Joint
Capabilities Integration and Development System (JCIDS) process to produce the CDD. The
owning Det and AFOTEC/A-3 will send representatives to attend and support all HPTs. (See
paragraph 2.15 for additional info.)
3.14. Integrated Test Team Charter Review, Update and Coordination. The core/test team
reviews and provides inputs/updates to the program ITT charter. The charter is then staffed by
AFOTEC/A-3 for 2-Ltr coordination (AFOTEC/A-3 and AFOTEC/A-5/8 only) and
AFOTEC/CS review for approval/signature by the AFOTEC/CV. The Det is responsible for
supporting adjudication of comments and interaction with the SPO. (See paragraph 2.16 for
additional info.)
3.15. Test Design Validation. After the ITD has been accomplished, any changes/additions to
the program’s system design or performance capabilities/requirements may require a test design
validation. This process is initiated either by a request from the Det TD or a recommendation
from AFOTEC/A-3. The core team reviews those changes/additions to understand their impact
to the ITD and, if necessary, updates the test design using the ITD methodology. (See paragraph
2.19 for additional info.)
3.16. Test & Evaluation Master Plan for Milestone B. Major Defense Acquisition Programs
(MDAP), Major Automated Information Systems (MAIS), and oversight programs require a
TEMP to support MS B. The TEMP documents the overall structure and objectives of the T&E
program. It provides the framework within which to generate detailed T&E plans. It documents
schedule and resource implications associated with the T&E program, including comparison
testing or a suitable alternative. It contains many of the agreements among participants and
specifies the levels of funding for the test. The ―contract‖ between DT and OT for what test
activities are done in DT, and thereby reduce OT should be documented in the TEMP. As well
as, the ITT schedule and criteria for pre-certification reviews that will help to identify and reduce
program risks. The TEMP is widely viewed by members of the T&E community as a ―contract‖
among the various parties.
   3.16.1. The DAG outlines content expectations for the TES/TEMP including items such as
   critical operational issues, scope and structure of the operational evaluations, T&E schedule,
   etc. While DOT&E expects certain content included in the TEMP, the format is flexible.
AFOTECMAN99-101 11 OCTOBER 2012                                                               25


   During the initial development of the TEMP all inputs will be staffed by the Det via 2-Ltr
   TMT coordination for AFOTEC/A-3 approval prior to initial release to the SPO. When
   changes occur, it is critical to update the TEMP to reflect the requirements of the newly
   designed OT. The TEMP is staffed by AFOTEC/A-3 for 2-Ltr coordination and
   AFOTEC/CS review. The AFOTEC/CC or AFOTEC/ED may approve/sign the TEMP
   based on the program’s ACAT level, UON status, or as determined by the AFOTEC/A-3.
3.17. Test Concept Process. The Test Concept Process involves a technical review (TR) and
the test concept development which are accomplished for every OT activity (EOA/OA, OUE, or
OT&E). The TR is a quality check to verify the technical adequacy, credibility, and
methodology of the scheduled test, analysis and reporting. AFOTEC/A-2/9 is responsible for
conducting the TR to certify that the test team is collecting the appropriate level of data to
answer important OT questions. The test concept continues the development of the OT approach
created during the ITD, allowing the test team to leverage any increase in program maturity. The
test team can further develop the OT&E construct, test scenarios, M&S, and verification,
validation, and accreditation plans. The efforts spent developing the test concept also gives the
test team the information needed to integrate activities with the DT community. The TR should
be completed 270 days before the OT activity starts and the test concept should be completed
180 days before the OT activity starts. Once completed, the test concept goes through a 2-Ltr
review for operational and technical adequacy, credibility, and sufficiency. After adjudication,
the test concept is briefed to the AFOTEC/CC or AFOTEC/ED (dependent on ACAT level) for
approval regardless of the program’s oversight status. Approval is based on the value of the OT
information, operational and technical relevance, and resource requirements/availability.
Following approval, the test concept is briefed to the SPO, AF/TE, and DOT&E, as required.
   3.17.1. Updated Tasking Order. If necessary following test concept development,
   AFOTEC/A-3, with Det support, prepares the updated TO using the TO template on the
   AFOTEC Intranet (an updated TO must include an updated TRP.) The updated TO updates
   the AFOTEC/CC’s broad guidance on the scope of the evaluation (including critical
   operational issue (COIs)), the resource allocation bounds, and team responsibilities during
   the planning, execution, and reporting phases, including the required deliverables to be
   produced during the execution of the TO. AFOTEC/A-3 is the headquarters’ staff POC for
   coordinating the TO. AFOTEC/CC approves changes to the TO. Future updates to an
   existing TO should be handled by AFOTEC/A-3 with Det support, although scope or cost
   changes may require test team collaboration and participation. (See paragraph 2.13 for
   additional info.).
   3.17.2. Updated Test Resource Plan. An update of the resource information should be
   accomplished after the test concept is completed. The TRP must be updated in sufficient
   detail to ensure it provides test resources in a timely manner. The TRP will document the
   resources needed for dedicated OT. In addition, the TRP will assume IT&E will be
   successful in producing OT usable data. AFOTEC/A-3Z leads the TRP update activities for
   SAPs.
3.18. Test Capability Roadmap. AFOTEC/A-5R combines information from the test concept
along with AFOTEC long-range goals documented in the Strategic Plan and future weapons
system characteristics from a variety of sources to develop and publish the AFOTEC test
capability roadmap. The roadmap serves as the cornerstone of AFOTEC’s test capability
investment strategy and includes a detailed description of each test capability requirement,
 26                                                 AFOTECMAN99-101 11 OCTOBER 2012


information on the baseline test capability, existing shortfalls, potential solutions, impact if not
funded, and the preferred solution/investment strategy. The roadmap looks at 3-10 years in the
future and is updated every two years. (See paragraphs 2.21.1. and 2.21.2. for additional info.)
3.19. Operational Test Planning Considerations. The test concept is used as a basis for
detailed test planning. To support AFOTEC’s integrated test culture, the test plan should include
integrated test events and activities. Integrated test planning promotes the combined execution,
where appropriate, of developmental and operational test events to satisfy both DT and OT data
requirements. This provides an opportunity to establish a ―contract‖ with the DT community to
leverage testing, share data and reduce the number of test events. Instead of looking back at DT
and determining if an event was operationally relevant enough to apply to OT&E, AFOTEC can
influence OT relevance while DT is planned. Prior to using data collected during IT&E, the TD
should ensure the data is operationally relevant. Additional requirements for test planning
include: Environment, Safety, and Occupational Health (ESOH); Deficiency Reporting,
Investigation, and Resolution (DRI&R) Process; Joint Reliability and Maintainability Evaluation
Team (JRMET); and the Test Data Scoring Board (TDSB).
   3.19.1. Environmental, Safety, and Occupational Health. The three basic principles of
   ESOH are to sustain readiness, leverage resources, and be a good neighbor. The Det/CC is
   responsible for providing a safe and healthy workplace, enhancing mission accomplishment,
   preserving resources, protecting the environment and minimizing risks—on and off the
   installation or public lands. Every test activity (EOA/OA, OUE, or OT&E) requires an
   ESOH Certification Board (ESOHCB) with AFOTEC/SE. The ESOHCB will be scheduled
   with enough time (prior to the test readiness review for OT&E) to implement risk mitigation
   measures and publish a Health and Safety Plan. AFOTEC/SE supports these responsibilities
   with subject matter experts assigned to the core/test teams. (The ESOH documents
   supporting operationally relevant questions that need to be worked for the test activity are
   embedded support documents for the Test Concept.)
   3.19.2. Deficiency Reporting, Investigation, and Resolution. The DRI&R processes
   promote the ability to identify and correct deficiencies in Air Force and Joint systems or
   equipment for which AFOTEC is the OTA or supporting the OTA before they impact
   mission capability (Ref. Technical Order (T.O.) 00-35D-54, USAF Deficiency Reporting and
   Investigating System). Successful implementation drives resolution decisions, tempered by
   total ownership cost, to correct, mitigate, and/or accept risk of conditions impacting
   operational safety, suitability and effectiveness. Success is based upon two premises: the
   user, operator or maintainer will report deficiencies on their assigned systems; and the PM
   will establish a proactive process to analyze data and act accordingly to implement solutions
   after coordination with the user/sponsor.
   3.19.3. Joint Reliability and Maintainability Evaluation Team. Establishment of a JRMET is
   a key activity for T&E. The JRMET assists in analyzing and categorizing reliability,
   availability, and maintainability data during IT&E. The SPO establishes and chairs the
   JRMET during IT&E. If for any reason the SPO chooses not to chair or participate,
   AFOTEC may chair the JRMET. During dedicated OT&E, the AFOTEC TD (or designated
   representative) chairs the JRMET.
   3.19.4. Test Data Scoring Board. The TDSB is a government-only forum held in
   conjunction with those tests having a JRMET that compiles, reviews, and scores all available
AFOTECMAN99-101 11 OCTOBER 2012                                                                 27


   data that may be used in OT&E computations. The purpose of the TDSB is to remove
   perception of contractor bias in the data scoring process. The SPO establishes and chairs the
   TDSB during IT&E. If for any reason the SPO chooses not to chair or participate, AFOTEC
   may chair the TDSB. During dedicated OT&E, the AFOTEC TD (or designated
   representative) chairs the TDSB.
3.20. Operational Assessment Planning. EOA/OAs are not conducted in lieu of OT&E.
However, they are planned, executed, and reported from an operational perspective. EOA/OAs
are conducted by AFOTEC on acquisition programs when required to inform a MS/acquisition
decision. EOA/OAs are required for all OSD T&E oversight programs or as directed, and are
approved by DOT&E. EOA/OAs promote interaction with the operating command and
developer and (from an operational perspective) ensure the establishment of clearly defined
operational requirements and meaningful OT&E criteria. EOA/OAs outline the rationale
(decision point being informed), the overall program decision points (program, production, and
assessment/test events known or projected), and the general activities that are to be performed.
An EOA/OA may consist of a specially requested assessment, performed to address specific
operational questions. EOA/OAs are documented in the TEMP and the TRP. Multiservice
ACAT I and II programs with the Air Force designated as the lead service normally require an
EOA/OA. For non-Air Force led multiservice programs, the AFOTEC PM/TD coordinate with
the lead service to determine if an EOA/OA is required. (See paragraph 3.19 for additional info.)

Section 3D—Activities and Events.

3.21. Early Operational Assessment. Note: The Test Concept Process is accomplished for
every OT activity (see paragraph 3.17 for additional info). An EOA is conducted to provide
insight into progress being made toward operational effectiveness, suitability, mission capability,
and readiness for dedicated OT&E. The OT&E construct is built during the ITD development
process and will form the basis for the EOA. The OT&E construct used for the EOA will give
insight into the elements that make up effectiveness and suitability for the system under test.
The objective of the EOA is to assess the most promising design approach sufficiently early in
the acquisition process to ensure it has the potential to fulfill user requirements. It focuses on
significant trends noted in development efforts, programmatic voids, areas of risk, and adequacy
of requirements. The content of EOAs may vary depending on the program’s ACAT and
acquisition strategy. Det/CCs are required to develop an EOA plan prior to conducting the EOA.
For all OT plans/reports the owning Det will staff the products for 2-Ltr coordination and
AFOTEC/A-3 will coordinate the AFOTEC/CS review. The AFOTEC/CC or AFOTEC/ED may
approve/sign the plan/report based on the program’s ACAT level, UON status, or as determined
by the AFOTEC/A-3. An EOA report will be produced and signed within 42 days after the last
test event or 45 days prior to the MS decision. (See paragraph 3.20 for additional info.)
 28                                                 AFOTECMAN99-101 11 OCTOBER 2012


                                            Chapter 4

                  AFOTEC ACTIVITIES SUPPORTING MILESTONE C

Section 4A—Overview

4.1. Introduction. The Det/CC, assisted by the Det technical advisor, is responsible for the
activities and products between MS B and MS C. The activities include reviewing any document
updates or new external documentation, developing a test concept, participating in the high
performance team for development of the capability production document (CPD), developing
inputs to the MS C TEMP, and conducting a MS C OA. The Det/CC and TD need to review the
activities discussed in Chapter 2 and 3 if assigned to an acquisition program following MS B.

Section 4B—External Support Documents

4.2. Acquisition Decision Memorandum Update. The ADM documents the decisions made
and exit criteria established at the MS B decision review. It specifies what is to be done prior to
the MS C decision. The ADM update may also include development and processing of the
Acquisition Program Baseline. Operational testers need to be cognizant of and implement the
decisions documented in the ADM. Det/CCs ensure ADMs are sent to AFOTEC/A-3 for 2-Ltr
coordination and AFOTEC/CS review. The AFOTEC/CC or AFOTEC/ED may approve the
ADM based on the program’s ACAT level. (See paragraph 2.4 for additional info.)
4.3. Program Management Directive. The Program Management Directive (PMD) provides
HQ USAF program direction and guidance to the appropriate commands following formal
establishment of the program at MS B. It also designates the implementing, participating,
supporting commands, and OTAs and their program responsibilities/relationships. It is
important to know what the mandatory support obligations are for all listed agencies.
AFOTEC/A-3 has developed a checklist to assist in reviewing PMDs. When reviewing the
PMD, the AFOTEC reviewer should: understand the AFOTEC/CC position on the program;
involvement in the OT&E related activities; understand AFOTEC support requirements from/to
the SPO and other commands or agencies; and understand if the direction it proposes for
AFOTEC (and/or the MAJCOM) is correct and reflects AFOTEC’s intentions (if not, then
submit proposed changes to correct these deficiencies.) AFOTEC/A-3 will staff all PMDs for 2-
Ltr coordination and AFOTEC/CS review for signature by the AFOTEC/ED. Note: See AF HQ
Operating Instruction (HOI) 63-1, Headquarters Air Force Guidance for Preparing Program
management Directives, for information on PMDs.
4.4. Capability Production Document. For programs where AFOTEC is the lead OTA,
AFOTEC/CC validates requirements in the CPD are testable and measurable in conjunction with
the AFROC. The CPD addresses the production elements specific to a single increment of an
acquisition program. A CPD is developed after the critical design review and is required prior to
the MS C decision review. The CPD is approved prior to Low Rate Initial Production (LRIP)
and IOT&E. The threshold attribute is defined as the minimum acceptable operational value
below which the utility of the system becomes questionable.
4.5. Enabling Concept. The user develops an enabling concept which details their perceptions
for system operations, maintenance and associated training. It describes how a particular task or
AFOTECMAN99-101 11 OCTOBER 2012                                                               29


procedure is performed, within the context of a broader functional area, using a particular
capability, such as a specific technology, training or education program, organization, facility,
etc. AFOTEC ensures the enabling concept is reflected in the OT&E and integrated test
strategies and planning, to include OT&E documents, so that the OT&E of the system is
executed as the user/operator plans to employ it.
4.6. Analysis of Alternatives Update. Although rare, the AoA may be updated following a MS
B decision and validation of the CDD. The focus of the AoA update will be to refine the
selected concept documented in the validated CDD. AFOTEC/A-3 has developed a checklist to
assist in reviewing AoA documents. (See paragraph 2.6 for additional info.)
4.7. Modeling & Simulation Support Plan Update. The MSSP, updated by the SPO, captures
all the M&S requirements over the life cycle of an acquisition program including those for DT
and OT. TDs need to be aware of the MSSP and ensure OT M&S requirements identified are
included as early as possible in order to be a part of the SPO's M&S funding strategy (the PM is
responsible for funding required M&S resources). Reference DODI 5000.02 and AFI 16-1002.
Contact AFOTEC/A-2/9 if any questions arise concerning M&S. (See paragraph 2.8 for
additional info.)
4.8. Life Cycle Management Plan Update. The LCMP is updated for MS C and integrates the
acquisition and sustainment strategy(ies) and provides all support requirements of a system,
subsystem, or major end item. If there is not a TEMP for the program, then the LCMP contains
all of the information that would have been contained in the TEMP to provide an integrated test
plan and minimize test event duplication and streamline the process. If there is both a LCMP
and a TEMP for the program, then the LCMP can contain a summary of the test program as
documented in the TEMP. (See paragraph 2.9 for additional info.)
4.9. Information Support Plans Update. The ISP is updated by the SPO for all ACAT and
non-ACAT acquisitions and procurements to document IT and NSS needs, dependencies,
interface requirements, and the NR-KPP. (See paragraph 2.10 for additional info.)
4.10. Information Assurance Strategy Update. The IA Strategy is updated by the SPO to
ensure it captures all the IA requirements over the life cycle of the program. The TD will call
upon the test team IA subject matter expert should any questions arise concerning the planned IA
activities and the executed IA activities. (See paragraph 2.11 for additional info.)
4.11. Authority to Operate or Interim Authorization to Operate. The ATO/IATO or status
of the ATO/IATO request package (including the Information Technology Security Plan of
Action and Milestones, or POA&M) will provide insight into the system’s IA readiness for
operational test. (See paragraph 3.9 for additional info.)
4.12. Threat Assessment Documents. Validated intelligence products should be used to
develop the AFOTEC test concept and test plan. The most authoritative reference for man-made
threat data for an acquisition program is the STAR, STA or capstone threat assessment generated
by a designated intelligence production agency such as the NASIC. OT planners should use only
the most current versions of these documents to develop the test concept, test plan and TEMP. A
virtual STAR (VSTAR) may precede or supplement a Defense Intelligence Agency-validated
STAR. The TD should call upon the Det intelligence analyst or the Intelligence Division should
any questions arise. (See paragraph 3.11 for additional info.)
 30                                               AFOTECMAN99-101 11 OCTOBER 2012


Section 4C—Processes, Procedures and Products.

4.13. High Performance Team. HPTs are convened to support AF/A-5R and the JCIDS
process to produce the CPD. The owning Det and AFOTEC/A-3 will send representatives to
attend and support all HPTs. (See paragraph 2.15 for additional info.)
4.14. Integrated Test Team Charter Review, Update and Coordination. The core/test team
reviews and provides inputs/updates to the program ITT charter. The charter is then staffed by
AFOTEC/A-3 for 2-Ltr coordination (AFOTEC/A-3 and AFOTEC/A-5/8 only) and
AFOTEC/CS review for the AFOTEC/CV’s approval/signature. The Det is responsible for
supporting adjudication of comments and interaction with the SPO. (See paragraph 2.16 for
additional info.)
4.15. Forming the Test Team. Test team composition depends on the scope of the test. The
OT&E plan shows the formal organization of the test team. Test teams may consist entirely of
AFOTEC personnel or may be augmented by MAJCOM personnel. The Det/CC selects a TD
from his available personnel – the TD is generally not assigned analyst or other support duties.
Once assigned and oriented, the TD may make adjustments in needed personnel and where they
are assigned. Consider obtaining expertise from the local area where the test is conducted to
support the team and expedite acclimation to the area. Note: Assignment to a test team does not
mean you are a dedicated resource to that team exclusively. Team members are agile and flow
between teams for specific tasks.
   4.15.1. Activating an Operating Location. The request to activate an OL can come from an
   AFOTEC Director/Det/CC or it can be directed through an AFOTEC/CC approved TO. The
   Director/Det/CC will contact AFOTEC/A-3 and the AFOTEC/CV when considering
   activating an OL. One of the factors to consider when determining the need for an OL is
   whether it is more cost-effective to the government to have an OL versus test team members
   performing temporary duty (TDY) to plan, execute, and report the test. AFOTEC/CC
   approves all unit activation/inactivation requests. OLs are ―owned‖ by supporting AFOTEC
   Det or Directorate. The activation/inactivation process is managed by Strategic Plans and
   Policy Division (AFOTEC/A-8X).
   4.15.2. Test Team Members and the Test Resource Plan. The TD identifies which
   specialties and skill levels are needed for the test team. The results are included in the TRP
   and are updated biannually or on an as-needed basis. The TD and Det leadership decide
   which test team positions are permanently assigned and which positions are better filled
   using individuals in a TDY status. AFOTEC permanent party positions should be
   coordinated with Manpower and Personnel (Operations) Division (AFOTEC/A-1W) through
   the TRP process, and are normally taken from current directorate/Det resources. In
   determining how early to position the test team, consideration should be given to ensuring
   adequate time for training and familiarization of the test environment. The scope of the test,
   the location (for example, not with a Det), or special activities associated with an OA may
   warrant earlier assignment and placement of key test team members. The timing of test team
   stand-up needs to be carefully considered as part of OT Planning. Any late changes to test
   team personnel are coordinated with AFOTEC/A-1W and approved by AFOTEC/CV.
4.16. Support Agreements. Whenever a support agreement is required, the initial step should
be to contact the support agreements manager (SAM) in AFOTEC/A-8X. The SAM can provide
AFOTECMAN99-101 11 OCTOBER 2012                                                                    31


examples, establish reasonable timelines, and determine the appropriate coordination process
within the headquarters when it is time to staff the agreement. There are two major support
agreement directives: DODI 4000.19, Interservice and Intragovernmental Support, and AFI 25-
201, Support Agreement Procedures.
   4.16.1. Types of Support Agreements. There are several types of support agreements: host
   base support agreement (documented on a DD Form 1144, Support Agreement); MOA;
   MOU; and service level agreements. The support agreement identifies items such as test
   responsibilities, financial responsibility for various test activities, general guidelines for test
   support, guidelines for allowing non-AFOTEC assigned personnel permanent access to an
   AFOTEC facility, and host-base provisions.
4.17. Test Capabilities. Test teams define test capability shortfalls and AFOTEC/A-5/8 seeks
funding to develop solutions. AFOTEC/A-5R and AFOTEC/A-8R are the AFOTEC POCs for
test capabilities, including test investment planning. As such, AFOTEC/A-5R and AFOTEC/A-
8R support core teams, Det, and headquarters staff in the identification of test range/facility
capabilities, determining test capability shortfalls, submitting requirements; and advocating for
OT&E needs within the AF and DoD test investment process. AFOTEC/A-5R and AFOTEC/A-
8R work closely with the Dets and AFOTEC/A-3 to refine test infrastructure requirements.
Once the shortfalls are approved by AFOTEC/A-3, AFOTEC/A-5R and AFOTEC/A-8R seek
funds to develop solutions to shortfalls. AFOTEC/A-5R publishes the AFOTEC test capability
roadmap. AFOTEC/A-8R has the charter to develop and maintain OT capability at the NTTR.
(See paragraphs 2.21.1. and 2.21.2. for additional info.)
4.18. Data Management and Analysis Plan. The purpose of the Data Management and
Analysis Plan (DMAP) is to provide detailed procedures for the collection, reduction, quality
assurance, collation, analysis, storage, and disposition of data gathered to support determination
of a system’s operational effectiveness, suitability and mission capability. The Det/CC is the
approval authority for all DMAPs. The DMAP aligns with the test plan and detailed test
procedures (DTP) in terms of contribution to a successful test. The DMAP is both a planning
tool to ensure procedures are in place for data collection and a data management tool for tracking
and assessing data collection during test execution. A DMAP is published as a separate
document for all ACAT I and OSD T&E oversight programs. For all other programs, the
essential elements of the DMAP should be included in the OT&E plan or published as a separate
document. The test team should develop the DMAP in parallel with the OT&E plan. Any
external requests for a copy of the DMAP will be coordinated through AFOTEC/A-3.
4.19. Detailed Test Procedures. DTPs are written and maintained by the test team. DTPs are
living documents. The DTPs describe how the test team executes the test. DTPs are working-
level reference documents that provide an audit trail of planning decisions, rationale, and
records. The DTPs are intended for test team use only and are not required to be coordinated
externally. However, there may be situations when the test site/range requires the DTPs to be
reviewed for safety, security, and operational integrity issues. The Det/CC is the approval
authority for all DTPs.
4.20. Determine Last Test Event. In order to properly plan for the development and
coordination of the final report, the TD defines the activity that constitutes the last test event
(LTE) while producing the report at the earliest possible date. The LTE is either the last specific
event of a test (e.g., the last sortie) or the conclusion of the JRMET (see paragraph 3.19.3. for
 32                                                  AFOTECMAN99-101 11 OCTOBER 2012


additional info) or data analysis, whichever will meet the decision maker's report suspense of a
decision date minus 45 days. The LTE is documented in the tasking order, test plan, added to the
program’s ATPA page and briefed at the test readiness review (TRR). If the LTE needs to be
changed, the Det/CC requests approval from the AFOTEC/A-3 for the new LTE. Upon
completion of the last test event, the TD submits a daily report to highlight coordination
timelines for the final report.
4.21. Visual Information Documentation. Once the test plan has been approved, the TD and
test team should determine where to incorporate visual information documentation (VIDOC)
(photos, video, etc.) during test execution. Advance coordination with AFOTEC’s Public Affairs
and Multimedia is required. When VIDOC is deemed appropriate, test teams will consider
VIDOC resources using the following priority: VIDOC of the system performing in the real
world employed environment will be used first; VIDOC obtained from dedicated OT events will
be used second; and third choice will be to use VIDOC obtained from IT&E and dedicated DT
events.
4.22. Test & Evaluation Master Plan Update. MDAP, MAIS, and oversight programs
require a TEMP or TEMP update to support MS C. The TEMP documents the overall structure
and objectives of the T&E program. It provides the framework within which to generate detailed
T&E plans. The TEMP is staffed by AFOTEC/A-3 for 2-Ltr coordination and AFOTEC/CS
review. The AFOTEC/CC or AFOTEC/ED may approve/sign the TEMP based on the program’s
ACAT level, UON status, or as determined by the AFOTEC/A-3. (See paragraph 3.16 for
additional info.)
4.23. Operational Assessment Planning. OAs are not conducted in lieu of OT&E. However,
they are planned, executed, and reported from an operational perspective. OAs are conducted by
AFOTEC on acquisition programs when required to inform a MS/acquisition decision. (See
paragraphs 3.19 and 3.20 for additional info.)
4.24. Operational Utility Evaluation Planning. The OUE plan should define the purpose,
scope, resources, timing of events, and allocation of test responsibilities as required for the OUE.
OUEs can be used to identify capabilities and limitations of fielded systems; determine the
effectiveness/suitability or operational military utility of non-fielded systems; validate a system's
concept; evaluate the expanded role of fielded systems; assess competing concepts, alternatives,
or systems; evaluate a new application of an existing technology; determine utility of a system to
perform operational mission requirements; support AoA development, source selection, fielding
of interim or partial capability ACAT I or II programs, or full rate production and fielding for
ACAT III, non-oversight programs. Examples of such programs are one-of-a-kind or an
expanded or modified role of an existing system (e.g., putting a fighter electronic
countermeasures pod on a transport aircraft). When OUEs are used, they should be conducted
without excessive expenditures of time, money, and resources, streamlined tests that are specific
in nature, flexible in planning and reporting formats, and adjustable to customer expectations.
The organization requesting the OUE and AFOTEC jointly develop a test-readiness certification
process that may be tailored as appropriate. If not directed by a PMD and supported with a
verified capability requirements document, the OUE can be negotiated through an MOA which
specifies the OUE requirements in a manner that clearly defines the questions to be answered by
the OUE. (See paragraphs 3.19 and 3.20 for additional info.)

Section 4D—Activities and Events.
AFOTECMAN99-101 11 OCTOBER 2012                                                                  33


4.25. Operational Assessment. Note: The Test Concept Process is accomplished for every OT
activity (see paragraph 3.17 for additional info). An OA is conducted to provide insight into
progress being made toward operational effectiveness, suitability, mission capability, and
readiness for dedicated OT&E. The OT&E construct will form the basis for the OA and will
give insight into the elements that make up effectiveness and suitability for the system under test.
An OA can be conducted at any time using technology demonstrators, prototypes, mockups,
engineering development models, or simulations. The focus of an OA is on significant trends
noted in development efforts, programmatic voids, areas of risk, adequacy of requirements, and
the ability of the program to support adequate operational testing. The content of OAs may vary
depending on the program’s ACAT and acquisition strategy. Det/CCs are required to develop an
OA plan prior to conducting the OA. For all OT plans/reports the owning Det will staff the
products for 2-Ltr coordination and AFOTEC/A-3 will coordinate the AFOTEC/CS review. The
AFOTEC/CC or AFOTEC/ED may approve/sign the plan/report based on the program’s ACAT
level, UON status, or as determined by the AFOTEC/A-3. An OA report will be produced and
signed within 42 days after the last test event or 45 days prior to the MS decision. (See
paragraph 3.20 for additional info.)
4.26. Operational Utility Evaluation. Note: The Test Concept Process is accomplished for
every OT activity (see paragraph 3.17 for additional info). The OUE was designed to allow
AFOTEC a convenient and proper tool to assist both users and decision makers in determining
the utility and value of a system or partial capability. OUEs can be tailored to the needs of the
specific decision being supported. Det/CCs are required to develop an OUE Plan prior to
conducting the OUE. For all OT plans/reports the owning Det will staff the products for 2-Ltr
coordination and AFOTEC/A-3 will coordinate the AFOTEC/CS review. The AFOTEC/CC or
AFOTEC/ED may approve/sign the plan/report based on the program’s ACAT level, UON
status, or as determined by the AFOTEC/A-3. An OUE report will be produced and signed
within 42 days after last test event or 45 days prior to the MS decision. (See paragraph 4.24 for
additional info.)
 34                                                 AFOTECMAN99-101 11 OCTOBER 2012


                                            Chapter 5

  AFOTEC ACTIVITIES SUPPORTING FULL-RATE PRODUCTION (FRP)/INITIAL
          OPERATIONAL CAPABILITY (IOC)/FIELDING DECISION

Section 5A— – Overview

5.1. Introduction. The Det/CC, assisted by the Det technical advisor, is responsible for the
activities and products from MS C through the FRP, IOC, or fielding decision. The activities
include reviewing any updates to or new external documentation, finalizing the OT&E test plan,
conducting the test readiness review, and executing and reporting the OT&E. The TD needs to
review the activities discussed in Chapters 2, 3, and 4 if assigned to an acquisition program
following MS C.

Section 5B—-External Support Documents

5.2. Acquisition Decision Memorandum Update. The ADM documents the decisions made
and exit criteria established at the MS C decision review. It specifies what is to be done prior to
the FRP/IOC/Fielding decision. Operational testers need to be cognizant of and implement the
decisions documented in the ADM. Det/CCs ensure ADMs are coordinated with the
AFOTEC/CC. (See paragraph 2.4 for additional info.)

Section 5C—- Processes, Procedures and Products.

5.3. Test & Evaluation Master Plan Update. The TEMP update documents the overall
structure and objectives of the T&E program. It provides the framework within which to
generate detailed T&E plans. MDAP, MAIS, and Oversight programs require a TEMP or TEMP
update to support the FRP decision. The TEMP update is staffed by AFOTEC/A-3 for 2-Ltr
coordination and AFOTEC/CS review. The AFOTEC/CC or AFOTEC/ED may approve/sign
the TEMP update based on the program’s ACAT level, UON status, or as determined by the
AFOTEC/A-3. (See paragraph 3.16 for additional info.)
5.4. Operational Test & Evaluation Plans (IOT&E/QOT&E/FOT&E). The test plan
describes what is necessary and how to execute the special topic aspects of the OT&E. Since
each plan is developed for a specific program, copying a previously approved plan may not lead
to the optimum program test solution and is discouraged. The Det/CCs and TDs are responsible
for developing the test plans with support from the assigned test team and HQ staff. Template
use is mandatory. Currently IA, electromagnetic environmental effects, interoperability, and
global positioning system signal loss are addressed as Special Interest Items in the test plan
template. For all OT&E plans the owning Det will staff the products for 2-Ltr coordination and
AFOTEC/A-3 will coordinate the AFOTEC/CS review. The AFOTEC/CC or AFOTEC/ED may
approve/sign the plan based on the program’s ACAT level, UON status, or as determined by the
AFOTEC/A-3. Per DoD and AF requirements, the AFOTEC approved OT&E plans are
provided to AF/TE and DOT&E not later than 60 days prior to test start. DOT&E determines, in
writing, the test adequacy of the OT&E plan in accordance with United States Code (USC), Title
10, Armed Forces, and DODI 5000.02. If the DOT&E approval of test adequacy has not been
received within a reasonable period of time after submittal of the test plan, the AFOTEC/A-3
AFOTECMAN99-101 11 OCTOBER 2012                                                               35


should be advised and a letter of inquiry prepared for AFOTEC/CC’s signature. (See paragraph
3.19 for additional info.)
5.5. Test Readiness Review. Prior to executing the IOT&E, the Det/CC is responsible for
conducting a TRR. The purpose of the TRR is to advise the AFOTEC/CC on the readiness of
the program and the test team, to receive acknowledgment of the PEO’s certification memo from
the AFOTEC/CC, and to obtain the AFOTEC/CC’s formal approval to start operational test.
Because the PEO’s certification memo contains key information on the system’s performance,
stability, and limitations, the TRR will occur after the PEO’s Operational TRR and certification.
The TRR will occur no earlier than the date AFOTEC receives the PEO’s certification memo,
and no later than 15 days prior to the planned test start date. All TRR briefings are staffed by
AFOTEC/A-3 for AFOTEC/CS coordination prior to review and approval by the AFOTEC/CC.

Section 5D—-Activities and Events.

5.6. Operational Utility Evaluation. Note: The Test Concept Process is accomplished for
every OT activity (see paragraph 3.17 for additional info). An OUE is the evaluation of military
capability conducted to demonstrate or validate new operational concepts or capabilities, upgrade
components, or expand the mission or capabilities of existing or modified systems. (See
paragraphs 4.23 and 4.24 for additional info.)
5.7. Initial Operational Test & Evaluation Execution. Note: The Test Concept Process is
accomplished for every OT activity (see paragraph 3.17 for additional info). The Det/CC is
responsible for all aspects of IOT&E execution. Following approval of the TRR and
AFOTEC/CC acknowledgement of the PEO’s certification of system readiness, the TD can
begin IOT&E execution activities. The TD will ensure test execution in accordance with the
approved test plan. (See paragraph 5.4 for additional info.)
   5.7.1. Data Collection, Management, and Evaluation. The TD and the test team will execute
   the DMAP. During dedicated OT&E, the AFOTEC TD (or designated representative) chairs
   the JRMET and the TDSB. Participants include representatives from the supporting and
   operating commands, the DT&E and OT&E test teams, and when appropriate, system
   contractor personnel. Note: system development contractor personnel are prohibit from
   TDSB participation per Public Law (USC, Title 10). (See paragraphs 3.19.3. and 3.19.4. for
   additional info.)
   5.7.2. Deficiency Reporting, Investigation and Resolution. The Det/CC is responsible for
   documenting system deficiencies found during execution of the IOT&E.
   5.7.3. Last Test Event. Upon completion of the LTE, the TD submits a daily report as
   notification of the completed event to the A-3, Deputy A-3, and the A-3 workflow account.
   A-3 will forward the report to CS for situational awareness. The daily report triggers the
   coordination timeline for the final report. This highlights the coordination timeline for the
   Final Report which is the culmination of the OT&E process and is the single-most important
   product produced by AFOTEC. All Final Reports are approved and signed by the
   AFOTEC/CC either 42 days after LTE or 45 days prior to the MS decision. (See paragraph
   4.20 for additional info.)
 36                                                AFOTECMAN99-101 11 OCTOBER 2012


                                           Chapter 6

         AFOTEC ACTIVITIES FOLLOWING FRP/IOC/FIELDING DECISION

Section 6A—Overview

6.1. Introduction. The Det/CC, assisted by the Det technical advisor, is responsible for the
activities and products following the FRP/IOC/Fielding decision. The activities include
determining the need for any required follow-on OT&E and closing out the program. The
Det/CC and TD need to review the activities discussed in Chapters 2, 3, 4, and 5 if assigned to an
acquisition program following the FRP/IOC/Fielding decision.

Section 6B—Processes, Procedures and Products.

6.2. Follow-on Operational Test & Evaluation Criteria. FOT&E is the continuation of
OT&E after IOT&E, QOT&E or MOT&E, and is conducted by AFOTEC. FOT&E answers
specific questions about unresolved test issues. FOT&E verifies the resolution of I/Q/MOT&E
deficiencies or shortfalls determined to have substantial or severe impact(s) on mission
operations. FOT&E completes T&E of areas not finished or deferred during I/Q/MOT&E if
these areas are determined to have substantial or severe impact(s) on mission operations.
Additionally, FOT&E may be conducted on block upgrades, modifications, or pre-planned
product improvements following completion of I/Q/MOT&E at the request of the MAJCOM and
acceptance by the AFOTEC/CC. A follow-on OT activity not meeting the definition of FOT&E
is designated as an force development evaluation (FDE) and conducted by the MAJCOM.
6.3. Closeout. The OT Closeout phase is required to complete AFOTEC involvement in a
program and could also result in the need to inactivate an OL. See Table 6.1. for a list of
products that may be required to complete the OT Closeout phase. AFOTEC/A-3 monitors the
OT Closeout phase to ensure all actions are completed in a timely manner.

Table 6.1. OT Closeout/Change Activities.
              Decision                            Actions Needed

                                                  Det prepares an updated tasking
              Program returned to Early
                                                  order (see paragraph 2.20. for
              Influence
                                                  additional info).

                                                  Det prepares Closeout Checklist,
              Program complete, cancelled, or
                                                  memorandum for record (MFR), and
              AFOTEC involvement ended
                                                  update letter to AF/TE, if required.

              Program transfers from one Det      Losing Det prepares transfer
              to another                          checklist and MFR.

   6.3.1. Test Program Closeout. OT closeout activities are directed in the program’s TO and
   should be completed within 30 days after the decision to close the program or final report
   approval. The Det starts the process by reviewing the closeout checklist and identifying
AFOTECMAN99-101 11 OCTOBER 2012                                                              37


  those applicable to the program being closed. Both the closeout checklist and the MFR are
  available on the templates page on the AFOTEC Intranet. The TD is responsible for
  contacting all POCs and working the applicable closeout actions. The Det prepares the MFR
  and staffs it in TMT for 2-Ltr coordination (AFOTEC/A-1, AFOTEC/A-3, AFOTEC/A-5/8,
  Communication and Information Directorate and AFOTEC/A-4/7). The Det sends the
  coordinated memo to AFOTEC/A-3; AFOTEC/A-3 then uses it to close out the program on
  the AFOTEC Intranets. Once a program is closed out, future upgrades to the system (or
  program increments) go through the involvement and test design processes to determine
  AFOTEC’s level of involvement. (Contact AFOTEC/A-3 for additional information.)
  6.3.2. Inactivation of Operating Location. As part of a test program’s closeout activities, an
  OL may need to be inactivated. The owning AFOTEC Det or Directorate will ensure the TD
  or OL Chief contacts AFOTEC/A-8X to begin the inactivation process. AFOTEC/A-8X will
  work with the TD or OL Chief to develop an inactivation report and is responsible for
  staffing and AFOTEC/CS approval.
  6.3.3. Test Data Disposition. The Air Force Records Information Management System RDS
  states that raw data can be destroyed when no longer needed. Test teams should consult their
  tech advisor when contemplating what to do with raw data or whether it will be needed for
  follow-on tests or other reasons. Because of space limitations, test teams should convert
  large amounts of raw data onto CDs for easier storage. The Det functional area records
  manager assists the TD with the closeout of the program case file on the official records
  management network drive and the transfer of all other program records to the AFOTEC
  records manager. A copy of the closed program case file will be sent to the AFOTEC
  History Office to be archived.
  6.3.4. Funds Closeout Procedures. The resource manager is the POC for assistance with
  funds closeout procedures. A funds closeout procedures checklist is located on the AFOTEC
  Intranet.




                                           DAVID J. EICHHORN
                                           Major General, USAF
                                           Commander
 38                                              AFOTECMAN99-101 11 OCTOBER 2012


                                       Attachment 1
         GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION

References
AF Doctrine Document (AFDD) 1-1 – Leadership and Force Development
AFI 10-601 – Capabilities-Based Requirements Development
AFI 16-1002 – Modeling and Simulation (M&S) Support to Acquisition
AFI 21-102 – Depot Maintenance Management
AFI 25-201 – Support Agreements Procedures
AFI 31-401 – Information Security Program Management
AFI 33-324 – The Information Collections and Reports Management Program: Controlling
Internal, Public, and Interagency Air Force Information Collections
AFI 63-101 – Acquisition and Sustainment Life Cycle Management
AFI 90-802 – Risk Management
AFI 99-103 – Capabilities-Based Test and Evaluation
AFMAN 33-363 – Management of Records
AFMAN 63-119 – Certification of System Readiness for Dedicated Operational Test and
Evaluation
AFMD 14 – Air Force Operational Test and Evaluation Center (AFOTEC)
AFOTECI 36-2201 – Management of the AFOTEC Training Program
AFOTEC Pamphlet (AFOTECPAM) 99-104 – AFOTEC Operational Suitability Test and
Evaluation Guide
AFI 11-401 AFOTECSup – Aviation Management
AFI 31-401 AFOTECSup – The AFOTEC Information Security Program
AFOTEC OT&E Guide
AFOTEC Program Manager’s Operational Test Toolkit
AFPD 10-23 – Air Force Innovation Program
AFPD 63-1 – Acquisition and Sustainment Life Cycle Management
AFPD 99-1 – Test and Evaluation Process
CJCSI 3170.01 H – Joint Capabilities Integration and Development System
CJCSI 6212.01 E – Interoperability and Supportability of Information Technology and National
Security Systems
CNSSI 1253 – Security Categorization and Control Selection for National Security Systems
DAG – Defense Acquisition Guidebook
AFOTECMAN99-101 11 OCTOBER 2012                                                          39


DCID 6/3 – Protecting Sensitive Compartmented Information within Information Systems
DODD 5000.01 - The Defense Acquisition System
DODD 5000.59 – DoD Modeling and Simulation (M&S) Management
DODD 5134.01 - Under Secretary of Defense for Acquisition, Technology, and Logistics
(USD(AT&L))
DODD 8500.01E – Information Assurance (IA)
DODI 4000.19 – Interservice and Intragovernmental Support
DODI 5000.02 – Operation of the Defense Acquisition System
DODI 8500.2 - Information Assurance (IA) Implementation
DODM 5200.1 V1 - DoD Information Security Program: Overview, Classification, and
Declassification
DODM 5200.1 V2 - DoD Information Security Program: Marking of Classified Information
DODM 5200.1 V3 - DoD Information Security Program: Protection of Classified Information
DODM 5200.1 V4 - DoD Information Security Program: Controlled Unclassified Information
(CUI)
Intelligence Community Directive 503 – Intelligence Community Information, Technology
Systems Security Risk Management, Certification and Accreditation
JAFAN Manual 6/3 – Special Access Program, Security Manual, Revision 1
ISOO Marking Classified National Security Information Manual
Intelligence Community Authorized Classification and Control Markings (CAPCO) Register and
Manual
HOI 63-1 – Headquarters Air Force Guidance for Preparing Program Management Directives
Joint Pub 1-02 – DoD Dictionary of Military and Associated Terms
NIST 800-37 – Certification and Accreditation Process
T.O. 00-35D-54 – USAF Deficiency Reporting and Investigating System
USAF Security Marking Guide for Special Access Programs
USC, Title 10 – Armed Forces
USC, Title 10, Chapter 4 §139 – Director of Operational Test and Evaluation
USC, Title 10, Chapter 137 §2302(5) – Major System: Definitional Threshold Amounts
USC, Title 10, Chapter 139 §2366 – Major Systems and Munitions Programs: Survivability
Testing and Lethality Testing Required Before Full-Scale Production
USC, Title 40 – Public Buildings, Property, and Works
Adopted Forms
AF Form 847, Recommendation for Change of Publication
 40                                           AFOTECMAN99-101 11 OCTOBER 2012


DD Form 1144, Support Agreement
SAP Form 6, Notification of Foreign Travel
SAP Form 16, Word Processor and Personal Computer Data Sheet
SAP Form 26, Equipment/Software Movement Request

Abbreviations and Acronyms
2-Ltr—2 Letter
ACAT—acquisition category
ACTD—Advanced Concept Technology Demonstration
ADM—acquisition decision memorandum
AF/A—5R - AF Requirements Office
AF/TE—Air Force Test and Evaluation
AFDD—AF Doctrine Document
AFI—Air Force Instruction
AFMAN—Air Force Manual
AFMC—Air Force Material Command
AFMD—Air Force Mission Directive
AFOTEC—Air Force Operational Test and Evaluation Center
AFOTEC/A—1 - Manpower and Personnel Directorate
AFOTEC/A—1W - Manpower and Personnel (Operations) Division
AFOTEC/A—2/9 - Analyses, Assessments and Lessons Learned Directorate
AFOTEC/A—2N – Intelligence Division
AFOTEC/A—9E - Mission Support Division
AFOTEC/A—3 - Operations Directorate
AFOTEC/A—3Z - Special Access Programs Division
AFOTEC/A—4/7 - Installations and Mission Support Directorate
AFOTEC/A—5/8 - Plans and Programs Directorate
AFOTEC/A—5R -Test Infrastructure Division
AFOTEC/A—8R - Long Range Investments Division
AFOTEC/A—8X - Strategic Plans and Policy Division
AFOTEC/CC—AFOTEC Commander
AFOTEC/CCX—Commander's Action Group
AFOTEC/CS—Command Staff
AFOTECMAN99-101 11 OCTOBER 2012                                              41


AFOTEC/CV—AFOTEC Vice Commander
AFOTEC/CVI—Information Protection
AFOTEC/ED—Executive Director
AFOTEC/SE—Safety
AFOTECI—AFOTEC Instruction
AFOTECPAM—AFOTEC Pamphlet
AFOTTP—Air Force Operational Tactics, Techniques, and Procedures
AFPAM—Air Force Pamphlet
AFPD—Air Force Policy Directive
AFRC—Air Force Reserve Command
AFROC—Air Force Requirements Oversight Council
AIS—automated information system
ANG—Air National Guard
AoA—analysis of alternatives
APB—Acquisition Program Baseline
ASD(C3I)—Assistant Secretary of Defense for Command, Control, Communication and
Information
ATD—advanced technology demonstration
ATO—Authority to Operate
ATPA—AFOTEC Test Program Applications
BBP—bullet background paper
C&A—certification and accreditation
C4I—Command, Control, Communications, Computers, and Intelligence
CAPCO—Controlled Access Program Coordinating Office
CDD—capability development document
CJCSI—Chairman, Joint Chiefs of Staff Instruction
CNSSI—Committee on National Security Systems Instruction
CNWDI—critical nuclear weapons design information
COA—course of action
COI—critical operational issue
CONOPS—concept of operations
CPD—capability production document
DAB—Defense Acquisition Board
 42                                               AFOTECMAN99-101 11 OCTOBER 2012


DAC—designated acquisition commander
DAE—Defense Acquisition Executive
DAG—Defense Acquisition Guidebook
DC—derivative classifier
DCID—Director of Central Intelligence Directive
Det—detachment
Det/CC—Det Commander
DIACAP—DoD Information Assurance Certification and Accreditation Process
DMAP—data management and analysis plan
DoD—Department of Defense
DODD—Department of Defense Directive
DODI—Department of Defense Instruction
DODM—Department of Defense Manual
DOE—Design of Experiments
DOT&E—Director, Operational Test and Evaluation
DRI&R—Deficiency Reporting, Investigation and Resolution
DT—developmental test
DT&E—developmental test and evaluation
DTIC—Defense Technical Information Center
DTP—detailed test procedure
EOA—early operational assessment
ESOH—environment, safety, and occupational health
ESOHCB—environment, safety, and occupational health certification board
FCT—foreign comparative test
FDE—force development evaluation
FOT&E—follow-on operational test and evaluation
FRD—formerly restricted data
FRP—full-rate production
FY—fiscal year
HOI—Headquarters Operating Instruction
HPT—high performance team
HQ—headquarters
AFOTECMAN99-101 11 OCTOBER 2012                               43


IA—information assurance
IATO—interim authorization to operate
ICD—initial capabilities document
IL—involvement letter
IOC—initial operational capability
IOT&E—initial operational test and evaluation
IP—information protection
ISOO—Information Security Oversight Office
ISP—information support plan
IT—information technology
IT&E—integrated test and evaluation
ITD—initial test design
ITT—integrated test team
JAFAN—Joint Air Force-Army-Navy
JCIDS—Joint Capabilities Integration and Development System
JCTD—Joint concept technology demonstration
JRMET—joint reliability and maintainability evaluation team
JT&E—Joint Test and Evaluation
KPP—key performance parameter
L2—lessons learned
LCMP—life cycle management plan
LFT&E—live fire test and evaluation
LNO—Liaison Officers
LRIP—low-rate initial production
LTE—last test event
M&S—modeling and simulation
MAC—mission assurance category
MAIS—major automated information system
MAJCOM—major command
MDA—milestone decision authority
MDAP—major defense acquisition program
MDD—Material Development Decision
 44                                            AFOTECMAN99-101 11 OCTOBER 2012


MFR—memorandum for record
MOA—memorandum of agreement
MOE—measure of effectiveness
MOS—measure of suitability
MOT&E—multiservice operational test and evaluation
MOU—memorandum of understanding
MS—Milestone
MSSP—modeling and simulation support plan
NASIC—National Air and Space Intelligence Center
NATO—North Atlantic Treaty Organization
NC2- ESI—Nuclear Command and Control-Extremely Sensitive Information
NIPRNet—non-secure internet protocol router network
NIST—National Institute of Standards and Technology
NLT—no later than
NR—KPP - Net-Ready Key Performance Parameter
NSS—National Security Space
NTTR—Nevada Test and Training Range
OA—operational assessment
OC—operational capability
OCA—original classification authority
OL—operating location
OPSEC—Operations Security
ORM—operational risk management
OSD—Office of the Secretary of Defense
OT—operational test
OT&E—operational test and evaluation
OTA—operational test agency
OUA—operational utility assessment
OUE—operational utility evaluation
PE—program element
PEO—program executive office
PM—program manager
AFOTECMAN99-101 11 OCTOBER 2012                       45


PMD—program management directive
POA&M—plan of action and milestones
POC—point of contact
QOT&E—qualification operational test and evaluation
R&M—reliability and maintainability
RD—restricted data
RDS—Records disposition schedule
RDT&E—Research, Development, Test and Evaluation
RFP—request for proposal
RM—Risk Management
RRB—requirements review board
RSR—requirement strategy review
RTO—responsible test organization
SAE—Service Acquisition Executive
SAM—Support Agreement Manager
SAP—Special Access Programs
SCG—security classification guide
SCI—sensitive compartmented information
SIPRNet—secure internet protocol router network
SM—security manager
SPO—System Program Office
STA—system threat assessment
Stan/Eval—Standardization and Evaluation
STAR—system threat assessment report
T&E—test and evaluation
T.O.—technical order
TD—test director
TDS—technology development strategy
TDSB—Test Data Scoring Board
TDY—temporary duty
TEMP—test and evaluation master plan
TES—test and evaluation strategy
 46                                                 AFOTECMAN99-101 11 OCTOBER 2012


TMT—Task Management Tool
TO—tasking order
TPM—test program management
TR—Technical Reviews
TRM—test resource manager
TRP—test resource plan
TRR—test readiness review
TTP—tactics, techniques, and procedures
UON—urgent operational need
USC—United States Code
USD(AT&L)—Under Secretary of Defense for Acquisition, Technology and Logistics
VIDOC—Visual Information Documentation
VSTAR—virtual system threat assessment report

Terms
Accreditation— The official determination that a model or simulation (or other test capability)
is acceptable for a specific purpose. (DODD 5000.59, DoD Modeling and Simulation (M&S)
Management)
Acquisition— The procurement of real property or services by any means exclusive of lease
agreements. The process consists of planning, designing, producing, and distributing a system or
equipment. Acquisition includes the concept definition or exploration, demonstration and
validation (including prototype development and test), full-scale development or LRIP, FRP or
initial deployment, and operations support.
Acquisition Category (ACAT)— Acquisition categories determine the level of review, decision
authority, and applicable procedures. They facilitate decentralized decision making and
execution, and compliance with statutory imposed requirements. There are three ACATs based
on research, development, T&E (RDT&E) and/or procurement costs stated in fiscal year (FY)
2000 dollars.
Table A1.1 ACAT.—Acquisition Community — All personnel involved in the
conceptualization, initiation, design, development, test, contracting, production, deployment,
sustainment, logistics, support, modification, and disposal of weapon and other systems,
supplies, or services to satisfy DoD needs, and intended for use in or in support of military
missions.
Acquisition Decision Memorandum (ADM)— A memorandum signed by the MS decision
authority that documents the decisions made and the exit criteria established as the result of a MS
decision review or in-process review.
Acquisition Process— The system of discrete, logical phases separated by major decision points
called MSs. The acquisition process begins when broad mission capability needs are identified
AFOTECMAN99-101 11 OCTOBER 2012                                                                47


which cannot be satisfied with non-materiel solutions.           (AFI 63-101, Acquisition and
Sustainment Life Cycle Management)
Acquisition Program— A directed, funded effort that is designed to provide a new or improved
materiel capability in response to a validated need.
Acquisition Program Baseline (APB)— A succinct document that details cost, schedule, and
performance (including support) parameters, and program breach information. It establishes the
commitment between the program manager and the MS Decision Authority. (AFI 63-101)
Acquisition System— A single uniform system whereby all equipment, facilities, and services
are planned, designed, developed, tested, acquired, maintained, and disposed of within the DoD.
The system encompasses establishing and enforcing policies and practices that govern
acquisitions, to include documenting mission needs and establishing performance goals and
baselines; determining and prioritizing resource requirements for acquisition programs; planning
and executing acquisition programs; directing and controlling the acquisition review process;
developing and assessing logistics implications; contracting; monitoring the execution status of
approved programs; and reporting to Congress. (DODD 5134.01, Under Secretary of Defense
for Acquisition, Technology and Logistics (USD(AT&L)))
Analysis— The detailed examination and application of disciplined techniques (for example,
mathematics or statistics) to anything complex to understand its nature or determine its essential
features.
Analysis of Alternatives (AoA)— An analysis of the estimated costs and operational
effectiveness of alternative materiel systems to meet the need and the associated program for
acquiring each alternative.
Attribute— A quantitative or qualitative characteristic of an element or its actions.
Automated Information System (AIS)— A combination of computer hardware and software,
data, or telecommunications that performs functions such as collecting, processing, transmitting,
and displaying information. Excluded are computer resources, both hardware and software that
are physically part of, dedicated to, or essential in real time to the mission performance of
weapons systems.
Availability— A measure of the degree to which an item is in the operable and committable
state at the start of a mission when the mission is called for at an unknown (random) time.
Battlespace— The environment, factors, and conditions that are understood to successfully
apply combat power, protect the force, or complete the mission. The battlespace includes the air,
land, sea, space, and the included enemy and friendly forces; facilities; terrestrial and space
environment; terrain; the electromagnetic spectrum; and the information environment within the
operational areas and areas of interest.
Beyond Low Rate Initial Production (LRIP) Report— An assessment of the adequacy of the
operational T&E and the effectiveness and suitability of a weapon system for combat, prepared
by the DOT&E, and submitted to the defense acquisition executive (DAE) and then to the
Congress.
Capability— The capacity to be used, treated, or developed for a specific purpose. Capability
descriptions contain the following elements: Key characteristics (attributes) with appropriate
parameters and metrics. (CJCSI 3170.01H)
 48                                                 AFOTECMAN99-101 11 OCTOBER 2012


Capability Development Document (CDD)— The warfighter’s primary means of providing
authoritative, measurable and testable requirements for the system development and
demonstration phase of an acquisition program. The CDD provides the operational performance
attributes necessary for the acquisition community to design a proposed system and establish a
program baseline. The CDD states performance attributes, including KPP that guides the
development and demonstration of the proposed increment. (CJCSI 3170.01H)
Capability Production Document (CPD)— The warfighter’s primary means of providing
authoritative, measurable and testable requirements for the production/fielding phase of an
acquisition program. A CPD is finalized after critical design review and is validated and
approved prior to the MS C acquisition decision. The CPD provides the operational performance
attributes necessary for the acquisition community to produce a specified quantity of a single
increment of a specific system. The CPD states performance attributes, including KPP, to guide
the production and deployment of the current increment. Since a CPD applies to only a single
increment of a program’s development, the performance attributes and KPPs shall apply only to
the increment described in the CPD (or, in a single step to full capability, to the entire system).
(CJCSI 3170.01H)
Characteristic— 1. Pertaining to, indicating, or constituting a distinctive quality or disposition.
2. A distinguishing feature or attribute.
Compatibility— The capability of two or more items or components of equipment or materiel to
exist or function in the same system or environment without mutual interference. (CJCSI
6212.01E)
Concept of Operations (CONOPS)— Verbal or graphic statement, in broad outline, of a
commander’s assumptions or intent in regard to an operation or series of operations. The
concept of operations frequently is embodied in campaign plans and operation plans. In the
latter case, particularly when the plans cover a series of connected operations to be carried out
simultaneously or in succession. The concept is designed to give an overall picture of the
operation. It is included primarily for additional clarity of purpose. Also called commander’s
concept (Joint Pub 1-02, DoD Dictionary of Military and Associated Terms).
Confidentiality Level— Applicable to DoD information systems, the confidentiality level is
primarily used to establish acceptable access factors, such as requirements for individual security
clearances or background investigations, access approvals and need-to-know determinations;
interconnection controls and approvals; and acceptable methods by which users may access the
system (e.g., intranet, Internet, wireless). The DoD has three defined confidentiality levels:
classified, sensitive and public. (DODI 8500.2, Information Assurance (IA) Implementation)
Core Team— Working team established and tasked to perform the activities of AFOTEC’s
Early Influence and Initial Test Design. The core team is usually comprised of representatives
from AFOTEC/A-2/9, AFOTEC/A-3, AFOTEC/A-5/8, Det, and others. The team is initially
designated by the initial tasking order.
Critical Operational Issue (COI)— AFOTEC defines a COI as a critical element or operational
objective of the mission that must be examined in OT&E in order to determine the system’s
overall capability to support mission accomplishment as determined by effectiveness, suitability,
and other applicable operational considerations.
AFOTECMAN99-101 11 OCTOBER 2012                                                               49


Defense Acquisition Board (DAB)— The senior DoD acquisition review board, chaired by the
Office of the USD(AT&L). The Vice Chairman Joint Chiefs of Staff is the Vice Chair. Assists
the DAE with MS and program reviews, policy formulation, and acquisition resource
recommendations. The DAB is the primary forum for DoD components to provide advice and
assistance concerning acquisition matters through the DAE to the Secretary of Defense.
Defense Acquisition Executive (DAE)— The principal advisor to the Secretary of Defense on
all matters pertaining to the DoD Acquisition System. USD(AT&L) is the DAE.
Deficiency— A condition that prevents successful mission accomplishment or degrades a
system's operational effectiveness or operational suitability. (T.O. 00-35D-54)
Deficiency Report— A report used to identify, document, and track system deficiency and
enhancement data while a system is in advanced development, T&E, or operational transition.
(T.O. 00-35D-54)
Design of experiments (DOE)— is a powerful applied statistics tool that allows for multiple
input factors to be selected for analyzing and determining their effect on a desired output or
response.
Designated Acquisition Commander (DAC)— The individual who functions as the MDA on
programs not assigned to a PEO. The commanders of AFMC or AFSPC product centers and air
logistics centers act in the capacity of a DAC. DACs, like PEOs, are accountable to the SAE.
(AFPD 63-1, Acquisition and Sustainment Life Cycle Management)
Developmental Test and Evaluation (DT&E)— T&E conducted to evaluate design
approaches, validate analytical models, quantify contract technical performance and
manufacturing quality measure progress in system engineering design and development,
minimize design risks, predict integrated system operational performance (effectiveness and
suitability) in the intended environment, and identify system problems (or deficiencies) to allow
for early and timely resolution or correction. Decision-makers use DT&E results to minimize
design risk, whereas OT&E evaluates military utility, and system effectiveness and suitability.
DT&E includes contractor testing (AFPD 99-1).
DoD Information Assurance Certification and Accreditation Process (DIACAP)— The
DoD processes for identifying, implementing, validating, certifying, and managing IA
capabilities and services, expressed as IA Controls, and authorizing the operation of DoD
information systems in accordance with statutory, Federal and DoD requirements.
Early Influence— Early Influence is AFOTEC’s formalized approach to refine capability
requirements and acquisition strategies, and then develop early IT&E strategies and plans. We
don’t define requirements, but we can help refine them. If we get involved early, even before
MS A, we can ensure requirements are testable, measurable, and operationally relevant.
Typically starting before MS A, involvement by AFOTEC intended to inject operational T&E
issues and concerns as soon as possible in the acquisition program. The intent is to achieve cost
and schedule savings by making recommendations benefiting operational effectiveness and
suitability. An element of early influence is AFOTEC’s participation in HPTs for capability
requirements documents.
 50                                                AFOTECMAN99-101 11 OCTOBER 2012


Early Operational Assessment (EOA)— An operational assessment conducted prior to, or in
support of, MS B. An EOA assesses the most promising design approach sufficiently early in
the acquisition process to ensure it has the potential to fulfill user requirements.
Effectiveness— See Operational Effectiveness.
Electromagnetic Environmental Effects— The impact of the electromagnetic environment
upon the operational capability of military forces, equipment, systems, and platforms. It
encompasses        all     electromagnetic       disciplines,    including        electromagnetic
compatibility/electromagnetic interference; electromagnetic vulnerability; electromagnetic pulse;
electronic protection; hazards of electromagnetic radiation to personnel, ordnance, and volatile
materials; and natural phenomena effects of lightning and p-static (precipitation static). (Joint
Pub 1-02)
Electronic Countermeasures— That division of electronic warfare involving actions taken to
prevent or reduce an enemy's effective use of the electromagnetic spectrum. It includes
electronic jamming and deception. (Joint Pub 1-02)
Evaluation— The review and analysis of qualitative or quantitative data obtained from design
review, hardware inspection, testing, or operational usage of equipment.
Evaluation Criteria— Standards by which accomplishments of required technical and
operational effectiveness and/or suitability characteristics or resolution of critical operational
issues may be assessed. Evaluation criteria are composed of a metric and a threshold. They can
be either user-established criteria or an identified standard.
Evolutionary Acquisition— Evolutionary acquisition is the preferred DoD strategy for rapid
acquisition of mature technology for the user. An evolutionary approach delivers capability in
increments, recognizing, up front, the need for future capability improvements. The objective is
to balance needs and available capability with resources, and to put capability into the hands of
the user quickly. The success of the strategy depends on phased definition of capability needs
and system requirements, and the maturation of technologies that lead to disciplined
development and production of systems that provide increasing capability over time.
Evolutionary acquisition requires collaboration among the user, tester, and developer. In the
evolutionary acquisition process, a needed operational capability is met over time by developing
several increments, each dependent on available mature technology. Technology development
preceding initiation of an increment shall continue until the required level of maturity is
achieved, and prototypes of the system or key system elements are produced. Successive
Technology Development Phases may be necessary to mature technology for multiple
development increments.
Each increment is a militarily useful and supportable operational capability that can be
developed, produced, deployed, and sustained. Each increment will have its own set of
threshold and objective values set by the user. Block upgrades, pre—planned product
improvement, and similar efforts that provide a significant increase in operational capability and
meet an acquisition category threshold specified in DODI 5000.02 shall be managed as separate
increments under the requirements of DODI 5000.02. (DODI 5000.02)
Exit Criteria— Program specific accomplishments that are satisfactorily demonstrated before an
effort or program can progress further in the current acquisition phase, or transition to the next
AFOTECMAN99-101 11 OCTOBER 2012                                                                  51


acquisition phase. Exit criteria may include such factors as critical test issues, the attainment of
projected growth curves and baseline parameters, and the results of risk reduction efforts deemed
critical to the decision to precede further. Exit criteria supplement minimum required
accomplishments (e.g., beyond LRIP report, cost as an independent variable objective, APB
parameters) are specific to each acquisition phase.
Factor— A factor is a variable of the environment or situation that affects task performance.
(AFDD 1-1).
Follow—on Operational Test & Evaluation (FOT&E) — Continuation of IOT&E or
QOT&E. FOT&E answers specific questions about unresolved COIs and test issues, verifies the
resolution of deficiencies determined to have substantial or severe impact on mission operations,
or completes areas not finished during the I/QOT&E. Requirements for FOT&E are documented
in an approved AFOTEC OT&E report prior to the planning of the FOT&E.
Force Development Evaluation (FDE)— FDE is performed by MAJCOM operational test
organizations during fielding and sustainment or in support of MAJCOM-managed system
acquisition. If AFOTEC conducted OT&E, an FDE is used to evaluate and verify the resolution
of previously identified deficiencies or shortfalls that were not rated in the OT&E final report as
having a substantial or severe impact on mission operations. If AFOTEC did not conduct
OT&E, FDE can be done in lieu of OT&E as needed to support acquisition program decisions
and MSs.
Foreign Comparative Test (FCT)— An OSD-funded program that allows each Service to test
foreign-developed systems, components, equipment items, or technologies. The goal is to
determine if foreign items meet validated needs and requirements, and if they are viable
candidates for a competitive acquisition.
Full—Rate Production (FRP) — The period encompassing the process of uniting facilities,
hardware and software, personnel, and procedural publications necessary for manufacturing and
delivering an acceptable integrated system to the using and supporting commands.
High Performance Team (HPT)— The HPT is the preferred method to develop an ICD Stage
I/ICD Stage II, CDD, or CPD, and is used unless waived by AF/A-5R at the RSR. An HPT
consists of a lead (normally the sponsor), core and support team members. The HPT accelerates
the documentation process and increases the potential for a quality document. Its overarching
objective is to capture, articulate, and document the operator’s operational requirements in
minimum time, while achieving stakeholder buy-in. AFOTEC is a core member of HPTs.
Human Engineering— The application of knowledge of human beings' capabilities and
limitations to the planning, design, development, and testing of aerospace systems, equipment,
and facilities to achieve optimum personnel safety, comfort, and effectiveness compatible with
systems requirements.
Human Factors— The systematic application of relevant information about human abilities,
characteristics, behavior, motivation, and performance. It includes principles and applications in
the areas of human engineering, anthropometrics, personnel selection, training, life support, job
performance aids, and human performance evaluation.
Implementing Command— The lead command or agency designated by the SAE to manage an
acquisition program.
 52                                                 AFOTECMAN99-101 11 OCTOBER 2012


Increment or Block— (See Evolutionary Acquisition).
Information Assurance (IA)— Measures that protect and defend information and information
systems by ensuring their availability, integrity, authentication, confidentiality, and non-
repudiation. The measures include providing for restoration of information systems by
incorporating protection, detection and reaction capabilities. (DODD 8500.01E) Availability
relates to the timely, reliable access to data and information services for authorized users.
Integrity is the quality of an information system reflecting the logical correctness and reliability
of the operating system; the logical completeness of the software and software implementing the
protection mechanism, and the consistency of the data structures and occurrence of the stored
data. In a formal security mode, integrity is interpreted more narrowly to mean protection
against unauthorized modification or destruction of information. Authentication is a security
measure designed to establish the validity of a transmission, message, or originator, or a means
of verifying an individual’s authorization to receive specific categories of information.
Confidentiality is assurance that information is not disclosed to unauthorized entities or
processes. Non-repudiation is assurance the sender of data is provided with proof of delivery
and the recipient is provided with proof of the sender’s identity, so neither can later deny having
processed the data. (also DODD 8500.01E)‖
Information Protection (IP)— The safeguarding of any data/information that potentially
reveals US vulnerabilities, capabilities or capability gaps, or falls under any of the exemption
categories of the Freedom of Information Act. Information protection includes the correct
classification, marking, handling, and destruction of AFOTEC-generated products. AFOTEC
generally has three categories of information: unclassified, controlled unclassified (e.g., for
official use only, export controlled) and classified.
Initial Capabilities Document (ICD)— Describes capability gaps that exist in joint warfighting
functions as described in the applicable joint concepts and integrated architectures. The ICD
defines the capability gap in terms of the functional area, the relevant Range of Military
Operations, and time. The ICD captures the results of a well-framed functional analysis. The
ICD documents the evaluation of materiel approaches that are proposed to provide the required
capability. The ICD further proposes a recommended materiel approach based on analysis of the
different materiel approaches. The ICD describes how the recommended approach best satisfies
the desired joint capability. (CJCSI 3170.01H)
Initial Operational Capability (IOC)— The first attainment of the capability to employ
effectively a weapon, item of equipment, or system of approved specific characteristics, with the
appropriate number, type, and mix of trained and equipped personnel necessary to operate,
maintain, and support the system.
Initial Operational Test and Evaluation (IOT&E)— An independent and dedicated
operational T&E conducted in as realistic an operational environment as possible to estimate the
prospective system's overall operational capability determined by effectiveness, suitability, and
other operational considerations. In addition, OT&E provides information on organization,
personnel requirements, doctrine, and tactics. It may also provide data to support or verify
material in operating instructions, publications, and handbooks.
Initial Test Design (ITD)— Initial test design is another focus of Early Influence. It is a
systematic approach to take the test teams from capability requirements to credible OT&E
constructs which, when executed, will yield the final data required by decision-makers to make
AFOTECMAN99-101 11 OCTOBER 2012                                                                53


program decisions. ITD is a process to provide a standardized approach for the corporate
allocation of resources among all of the test programs managed by AFOTEC and to identify
major test capability requirements and shortfalls.
Innovation Program— Can include: pre-acquisition activities (Advanced Concept Technology
Demonstration (ACTD), advanced technology demonstration (ATD), FCT, non-developmental
item); warfighter assessments (battlelab and Combatant Commander initiatives, joint and service
experiments); doctrine/TTP development (joint T&E (JT&E)); exercise activities (Joint Chiefs of
Staff, Combatant Commander, service, federal). (AFPD 10-23, Air Force Innovation Program)
Integrated Test & Evaluation (IT&E)— An efficient approach to T&E, executed with the
deliberate intent and planning to use specific test events and activities for both developmental
test and operational test analysis and reporting, when there are clear cost and/or schedule
advantages. The high cost or lack of sufficient test articles may provide an overall benefit for
DT&E and OT&E teams to share test resources and data. IT&E usually ends with a phase of
dedicated OT&E. AFOTEC always considers doing IT&E for all programs. The restriction for
contractor involvement in USC, Title 10 applies only to dedicated OT&E.
Integrated Test Team (ITT)— The ITT is established to involve all T&E stakeholders in a
program as early as possible and to facilitate coordinated and IT&E planning. The ITT replaces
the test plan working group and may also be referred to as a T&E working-level integrated
product team. The ITT is co-chaired by the acquisition program manager and the OTA. The
ITT is the body that develops the required T&E documentation for the program (T&E Strategy,
TEMP, etc.) and continues through on IT&E execution and reporting. A charter outlining roles
and responsibilities of members is developed for the ITT. Typically, the AFOTEC TD is the
OT&E representative on the ITT.
Integration— The arrangement of systems in an architecture so that they function together in an
efficient and logical way. (CJCSI 6212.01E)
Interoperability— The ability of systems, units, or forces to provide and receive services from
other systems, units, or forces, and to use the services so interchanged to enable them to operate
effectively together. The conditions achieved among communications-electronics systems or
communications-electronics items when information or services can be exchanged directly
between them and/or their users.
Involvement Letter (IL)— Developed by AFOTEC/A-3 and approved by AFOTEC/CC, the IL
formally notifies associated outside agencies of AFOTEC’s decision to be involved or non-
involved in a particular program.
Joint Concept Technology Demonstration (JCTD)— 1) One of three technology transition
mechanisms; the other two are ATDs and experiments. JCTDs are used to determine the military
utility of proven technology and to develop the concept of operations that optimize effectiveness.
JCTDs are not themselves acquisition programs, but are designed to provide a residual, usable
capability upon completion, and/or transition into acquisition programs (AFI 10-601). 2) A
means of rapidly demonstrating the use of advanced technologies to address urgent military
needs. JCTDs are designed to rapidly transfer technology from developers to users.
Demonstrations are jointly developed and implemented with the operational user and
development communities as key participants. The fundamental goals are to provide a sound
 54                                                AFOTECMAN99-101 11 OCTOBER 2012


basis for investment decisions, and provide residual operational capabilities. JCTDs are partially
funded by OSD.
Joint Program— Any defense acquisition system, subsystem, component, or technology
program involving formal management or funding by more than one DoD component during any
phase of a system’s life cycle.
Joint Reliability and Maintainability Evaluation Team (JRMET)— The team responsible for
collecting, analyzing, and categorizing reliability and maintainability (R&M) data during DT&E
and OT&E. It is chaired by the single manager (or designated representative) and includes
representatives from the supporting and operating commands, the DT&E and OT&E test teams,
and, when appropriate, system contractor personnel as nonvoting members. (See AFOTECPAM
99-104, AFOTEC Operational Suitability Test and Evaluation Guide, for more information.)
Joint Test and Evaluation (JT&E)— JT&E candidate programs are nominated by the Services,
and directed and funded by OSD. JT&E programs evaluate technical or operational concepts
that are applicable to more than one Service. They usually do not result in the acquisition of
systems.
Key Performance Parameters (KPP)— KPPs are those system attributes considered essential
for successful mission accomplishment. The CDD should only contain a limited number of
KPPs (approximately 8 or fewer) that capture the parameters needed to reach the overall desired
capabilities for the system. Failure to meet a CDD KPP threshold can be cause for the system
selection to be reevaluated, the program to be reassessed or terminated, or the content of
production increments modified. Interoperability is a KPP in every increment of a program.
Last Test Event (LTE)— The LTE is the last specific event of a test (e.g., the last sortie, the
conclusion of the JRMET, the completion of data analysis, etc.) The LTE is documented in the
test plan (Section 3, Scope), added to the program’s AFOTEC-Intranet Test Management page,
and briefed at the TRR.
Lead Service— The Service designated by USD(AT&L) to be responsible for management of a
system acquisition involving two or more DoD components in a joint program.
Lethality— The ability of a munitions system (or laser, high power microwave) to cause
damage that results in the loss or degradation of the ability of a target system to complete its
designated mission(s).
Life Cycle Management Plan (LCMP)— The LCMP integrates both the acquisition and
sustainment strategies from concept development to disposal and provides all product support
requirements of a supported system, subsystem, or major end item. The LCMP lays out full life
cycle product support strategies; and maximizes system effectiveness from the perspective of the
warfighter.
Live Fire Test and Evaluation (LFT&E)— A test within the OSD approved LFT&E strategy
involving the firing of actual munitions at target components, subsystems, subassemblies, or
system-level targets (which may or may not be configured for combat) to examine personnel
casualty, vulnerability and/or lethality issues. (USC, Title 10, Chapter 139 §2366)
Logistics Supportability— The degree to which the planned logistics support allows the system
to meet its availability and wartime usage requirements. Planned logistics support includes the
AFOTECMAN99-101 11 OCTOBER 2012                                                                   55


following: test, measurement, and diagnostic equipment; spare and repair parts; technical data;
support facilities; transportation requirements; training; manpower; and software.
Low—Rate Initial Production (LRIP) — The minimum number of systems (other than ships
and satellites) to provide production representative articles for operational T&E, to establish an
initial production base, and to permit an orderly increase in the production rate sufficient to reach
full-rate production upon successful completion of operational testing.
Maintainability— The ability of an item to be retained in or restored to specified conditions
when maintenance is performed by personnel having specified skill levels, using prescribed
procedures and resources, at each prescribed level of maintenance and repair.
Major Automated Information System (MAIS)— An AIS acquisition program that is 1)
designated by ASD(C3I) as a MAIS, or 2) estimated to require program costs in any single year
in excess of $30 million in FY 1996 constant dollars, total program costs in excess of $120
million in FY 1996 constant dollars, or total life-cycle costs in excess of $360 million constant
dollars. MAISs do not include highly sensitive classified programs (as determined by the
Secretary of Defense).
Major System— A combination of elements that functions together to produce the capabilities
required to fulfill a mission need. The elements may include hardware, equipment, software, or
any combination thereof, but excludes construction or other improvements to real property. A
system shall be considered a major system if it is estimated by USD(AT&L) to require an
eventual total expenditure for RDT&E of more than $140 million in FY 2000 constant dollars or
for procurement of more than $660 million in FY 2000 constant dollars (USC, Title 10, Chapter
137 §2302(5), Major System: Definitional Threshold Amounts).
Measure— A measure is a device designed to convey information about an entity being
addressed. It is the dimensions, capacity, or amount of an attribute or characteristic an entity
possesses. A measure is used to provide the basis of comparison or for describing varying levels
of an attribute.
Measure of Effectiveness (MOE)— A measure of operational success that must be closely
related to the objective of the mission or operation being evaluated. For example, the number of
enemy submarines sunk or enemy tanks destroyed may be satisfactory MOEs if the objective is
to destroy such weapon systems. However, if the real objective is to protect shipping or an
infantry battalion, then the best course of action might be one that results in fewer friendly
submarines or tanks actually killed. A meaningful MOE must be quantifiable and measure to
what degree the real objective is achieved.
Measure of Suitability (MOS)— A measure of a system’s ability to support mission/task
accomplishment (identified by the COI) with respect to reliability, availability, maintainability,
transportability, supportability, and training.
Memorandum of Agreement (MOA)— An agreement that defines areas of responsibility and
agreement between two or more parties, normally at headquarters or MAJCOM level. MOAs
normally document the exchange of services and resources and establish parameters from which
support agreements may be authorized. (AFI 25-201)
 56                                                 AFOTECMAN99-101 11 OCTOBER 2012


Memorandum of Understanding (MOU)— An umbrella agreement that defines broad areas of
mutual understanding between two or more parties, normally at MAJCOM or higher level. (AFI
25-201)
Metric— A metric is a unit of measure that coincides with a specific method, procedure, or
analysis (e.g. function or algorithm). The function results in a distance (in an abstract sense such
as a relationship, not necessarily a physical sense) between two entities.
Milestone (MS)— Major management decision points in the system acquisition decision process
requiring OSD and (or) DoD component program review. MSs include both DAB and DoD
component equivalent program reviews.
Milestone Decision Authority (MDA)— The individual designated according to criteria
established by USD(AT&L), or by ASD(C3I) for AIS programs, to approve entry of an
acquisition program into the next phase.
Mission— A duty assigned to an individual or unit: a task (Joint Pub 1-02). A combat operation
assigned to an individual or unit.
Mission Assurance Category (MAC)— Reflects the importance of information relative to the
achievement of DoD goals and objectives, particularly the warfighter’s combat mission. The
MAC is primarily used to determine the requirements for availability and integrity (see definition
of information assurance). (DODD 8500.01E)
Modeling and Simulation (M&S)— The discipline that comprises the development and/or use
of models and simulations; M&S is highly dependent upon IT. (DODD 5000.59) A model is a
physical, mathematical, or otherwise logical representation of a system, entity, phenomenon, or
process. A simulation is a method for implementing a model over time. Also, it can be a
technique for testing, analysis, or training in which real-world systems are used, or where real-
world and conceptual systems are reproduced by a model.
Modification— A change to a system that is still in production. A ―major modification‖ is a
modification that in and of itself meets the criteria of an ACAT I or II, or is designated as such
by the MDA.
Multiservice Operational Test and Evaluation (MOT&E)— OT&E conducted by two or
more services on systems to be acquired by more than one service or to be interoperable between
services.
Objective— An operationally significant increment above the threshold. An objective value
may be the same as the threshold when an operationally significant increment above the
threshold is not identifiable (CJCSI 3170.01H and AFI 10-601).
Operating Command— The command primarily operating (using) a system, subsystem, or item
of equipment. Generally applies to those operational commands or organizations designated by
HQ USAF to conduct or participate in operations or operational testing. (AFI 10-601)
Operational Assessment (OA)— Analysis of progress toward operational effectiveness and
suitability made by an independent operational test activity, with user support as required, on
other than production systems. Additionally, AFOTEC assess progress toward overall mission
capability. The focus of an operational assessment is on significant trends noted in development
efforts, programmatic voids, areas of risk, adequacy of requirements, and the ability of the
program to support adequate operational testing. Operational assessments may be made at any
AFOTECMAN99-101 11 OCTOBER 2012                                                                57


time using technology demonstrators, prototypes, mockups, engineering development models, or
simulations, but are substitute for the independent OT&E necessary to support full production
decisions. An OA conducted before MS B is referred to as an EOA.
Operational Capability (OC)— An OC is a system attribute or grouping of attributes that users
and subject matter experts have identified as being crucial to the achievement of critical mission
elements and/or operational objectives and are, therefore, of significant value to the warfighter.
Operational Concept— A statement about intended employment of forces that provides
guidance for posturing and supporting combat forces. Standards are specified for deployment,
organization, command and control, basing, and support from which detailed resource
requirements and implementing programs can be derived.
Operational Effectiveness— The overall degree of mission accomplishment of a system when
used by representative personnel in the environment planned or expected (e.g., natural,
electronic, threat) for operational employment of the system considering organization, doctrine,
tactics, survivability, vulnerability, and threat (including countermeasures, initial nuclear
weapons effects, and nuclear, biological, and chemical contamination threats).
Operational Suitability— The degree to which a system can be placed satisfactorily in field use
with consideration given to availability, compatibility, transportability, interoperability,
reliability, wartime usage rates, maintainability, safety, human factors, manpower supportability,
logistics supportability, natural environmental effects and impacts, documentation, and training
requirements.
Operational Test (OT) Activity— Refers to all OT&E as well as OA, EOA, OUE, and test
support for ACTD, battlelab and other innovation programs.
Operational Test Agency (OTA)— Each Service has one designated operational test agency:
the Air Force has the AFOTEC; the Navy has the Operational T&E Force; the Army has the
Army T&E Command; and the Marine Corps has the Marine Corps Operational T&E Activity.
The command or agency designated in the PMD or other appropriate program directive as
responsible for managing the independent OT&E of a system.
Operational Test and Evaluation (OT&E)— The field test, under realistic combat conditions,
of any item of (or key component of) weapons, equipment, or munitions for the purpose of
determining the effectiveness and suitability of the weapons, equipment or munitions for use in
combat by typical military users, and the evaluation of the results of such test. (USC, Title 10,
Chapter 4 §139, Director of Operational Test and Evaluation)
Operational Test and Evaluation (OT&E) Construct— The OT&E Construct is a model that
identifies the elements of an operational test and the relationship of the individual elements to
each other. The elements of an OT&E Construct include: the mission statement, COI, OC, OC
requirements, conditions, measures (measures of effectiveness and measures of suitability, or
TES/TEMP measures), criteria (user established or identified standards), and data. The OT&E
Construct is typically summarized and depicted in the form of an Evaluation Summary Chart for
presentation although other views are developed to capture all aspects of the OT&E Construct.
Operational Utility Assessment (OUA)— OUAs are used to determine operational utility in
support of assessments conducted on innovation programs. An OUA is planned, conducted, and
reported by adapting the OT&E construct to the technology being assessed.
 58                                                 AFOTECMAN99-101 11 OCTOBER 2012


Operational Utility Evaluation (OUE)— OUEs are evaluations conducted to demonstrate or
validate new operational concepts or capabilities, upgrade components, or expand the mission or
capabilities of existing or modified systems. OUEs are not used when IOT&E, QOT&E, or
FDE are required or are more suitable.
Operations Security (OPSEC)— A process of identifying critical information and analyzing
friendly actions attendant to military operations and other activities to:
Identify those actions that hostile intelligence systems can observe.
Determine indicators hostile intelligence systems might obtain that could be interpreted or pieced
together to derive critical information in time to be useful to adversaries.

Select and execute measures to eliminate or reduce to an acceptable level the vulnerability
of friendly actions to exploitation by adversaries. (Joint Pub 1—02)
Oversight Program— An acquisition program on OSD’s T&E Oversight List that is published
by OSD. Generally, the list includes ACAT I (MDAP) programs, ACAT II (major system)
programs, and any other program designated for T&E oversight. The master list designates
oversight for three types of testing: DT&E, OT&E, and LFT&E. These programs require some
additional documentation, and have additional review and approval requirements. (DODI
5000.02)
Parameter— Any set of physical properties whose values determine the characteristics or
behavior of something (i.e., parameters for atmosphere are temperature, pressure, and density).
Performance— Those operational and support characteristics of the system that allow it to
effectively and efficiently perform its assigned mission over time. The support characteristics of
the system include both supportability aspects of the design and the support elements necessary
for system operation.
Program Executive Officer (PEO)— A military or civilian official who has primary
responsibility for directing several ACAT I programs and for assigned ACAT II and III
programs. PEOs review and assess changes reported in assigned programs, the significance of
the problems reported by the program manager, the program manager’s proposed action plans,
and the level of risk associated with such plans. PEOs also serve as decision authorities for
assigned programs. A PEO has no other command or staff responsibilities within the
component, and only reports to and receives guidance and direction from the DoD component
acquisition executive.
Program Management Directive (PMD)— The official Air Force document used to direct
acquisition or modification responsibilities to the appropriate MAJCOM, PEO, or DAC for a
specific system and subsystem's development, acquisition, concept direction study, or
modification. The PMD states the program's unique requirements, goals, and objectives,
especially those to be met at each acquisition MS or program review.
Program Manager (PM) (external to AFOTEC)— The individual designated by the
implementing command as having single-point management responsibility for an acquisition
program. The program director may delegate specific program authority to SPO staff members
as long as the authority is documented in management instructions or official correspondence.
AFOTECMAN99-101 11 OCTOBER 2012                                                                  59


Program Manager (PM) (AFOTEC/A—3/A-3Z) — The AFOTEC PMs are HQ staff POCs for
AFOTEC programs throughout the life of a program. They have a wide-range of responsibilities
depending where assigned in AFOTEC/A-3. Responsibilities range from tracking programs
prior to formal involvement determination and staff POC for requirements document reviews,
HPT participation, test design activities, test plans and test reports.
Prototype— A model suitable for evaluation of design, performance, and production potential.
(Joint Pub 1-02) The Air Force also uses prototypes during development of a technology or
acquisition program for verification or demonstration of technical feasibility. Prototypes may
not be representative of the final production item.
Qualification Operational Test and Evaluation (QOT&E)— The operational testing
performed on programs instead of IOT&E for which there is no RDT&E-funded development
effort.
Readiness— The ability of a system to deploy and employ without unacceptable delays and to
deliver the output for which they were designed. (Joint Pub 1-02)
Recoverability— Following combat damage, the ability to take emergency action to prevent
loss of the system, to reduce personnel casualties, or to regain weapon system combat mission
capabilities. Recoverability is considered a subset of survivability.
Reliability— The ability of a system and its parts to perform its mission without failure,
degradation, or demand on the support system.
Responsible Test Organization (RTO)— The lead government entity that is qualified and
responsible for DT&E.
Risk— A measure of the inability to achieve program objectives within defined cost and
schedule constraints and has two components: 1) the probability of failing to achieve a particular
outcome, and 2) the consequences of failing to achieve that outcome.
Risk Management (RM)—Risk management is a decision-making process to systematically
evaluate possible courses of action, identify risks and benefits, and determine the best course of
action for any given situation. RM enables commanders, functional managers, supervisors, and
individuals to maximize operational capabilities while limiting all dimensions of risk by applying
a simple, systematic process appropriate for all personnel and functions both on- and off-duty.
Appropriate use of RM increases both an organization’s and individual’s ability to accomplish
their mission, whether it is flying an airplane in combat, loading a truck with supplies, planning a
joint service exercise, establishing a computer network, or driving home at the end of the day.
Application of the RM process ensures more consistent results, while RM techniques and tools
add rigor to the traditional approach to mission accomplishment, thereby directly strengthening
the Air Force's warfighting posture.
Service Acquisition Executive (SAE)— A single official within a DoD component who is
responsible for all acquisition functions within that component.
Single Manager— A government official (military or civilian) responsible and accountable for
decisions and overall management (to include all cost, schedule, performance, and sustainment)
of a system, product group, or materiel group. Also known as system program director, program
manager, product group manager, or materiel group manager.
Suitability— See Operational Suitability.
 60                                                AFOTECMAN99-101 11 OCTOBER 2012


Staff POC— The staff POC is responsible for the coordination of a product within the HQ and
external agencies, as applicable; adjudicating HQ and external comments to a product, as
applicable; staffing in TMT for appropriate 2-Ltr and AFOTEC/CS coordination, and modifying
the product for final signature and subsequent publishing.
Supportability— The degree to which system design characteristics and planned logistics
resources, including manpower, meet system peacetime readiness and wartime utilization
requirements.
Supporting Command— The command (usually Air Force Materiel Command) responsible for
providing logistics support for a system. (AFI 21-102, Depot Maintenance Management)
Survivability— The capability of a system and its crew to avoid or withstand man-made hostile
environments without suffering an abortive impairment of its ability to accomplish its designated
mission. Survivability is comprised of susceptibility, vulnerability, and recoverability.
Susceptibility— The degree to which a weapon system is open to effective attack due to one or
more inherent weaknesses. (Susceptibility is a function of operational tactics, countermeasures,
and probability of the enemy fielding a threat.) Susceptibility is considered a subset of
survivability.
Sustainment— Activities that sustain systems during the operations and support phases of the
system life cycle. Sustainment activities include any investigative T&E that extends the useful
military life of systems, or expands the current performance envelope or capabilities of fielded
systems. Sustainment activities also include T&E for modifications and upgrade programs, and
may disclose system or product deficiencies and enhancements that make further acquisitions
necessary. The T&E conducted during sustainment follows the same guidance as for the T&E
conducted during the acquisition process.
System Threat Assessment (STA)— A document prepared by the intelligence community that
serves as the single authoritative reference for man-made threat data regarding an ACAT II or III
program. It describes the lethal and non-lethal threats against the proposed system and the threat
environment in which the system operates.
System Threat Assessment Report (STAR)— A document prepared by the intelligence
community that serves as the single authoritative reference for man-made threat data regarding
an ACAT I program. It describes the lethal and non-lethal threats against the proposed system
and the threat environment in which the system operates.
Tactics, Techniques, and Procedures (TTP)— The Air Force Operational TTPs (AFOTTP)
provides guidance for the planning and execution of aerospace operations across the spectrum of
conflict. AFOTTPs describe, in detail, how to formulate the theater’s aerospace strategy and
then translate it into an executable order. The series also discusses the integration and
employment of aerospace capabilities at the operational level of war. Tactical TTPs applies
basic and operational doctrine to military actions by describing the proper use of specific weapon
systems or detailed TTPs, to accomplish specific military operations.
Targets, Threats, and Ranges— Target. An aircraft, ship, or ground vehicle that emulates the
signature, performance, and vulnerability of a threat weapon system when engaged by US
sensors and weapons. Note: Targets may be many other things besides emulations of a weapon
system that are engaged by sensors and weapons. While the issues of accurate signature,
AFOTECMAN99-101 11 OCTOBER 2012                                                                  61


performance and vulnerability are necessary; the definition must be broad enough to include
anything planned for surveillance or attack with the system under test, e.g., bridges, bunkers,
runways, C4I nodes, SAM sites, or factories. Attacks do not have to use lethal force, but may
include jamming and other non-lethal means. Similarly, not all targets are ―attacked‖ in the
literal sense, i.e., surveillance. A reconnaissance asset (unmanned aerial vehicle, KH-xx
satellite, Joint Surveillance Target Attack Radar System) may photograph or image a target in
some other way without employing weapons.
Threat Representation. Simulator, target, or model used to represent opposing weapon systems.
Ranges.    Instrumented open—air ranges that permit tests in a real-world, dynamic
environment, e.g., Naval Air Weapons Center/China Lake, Nellis Open Air Range, or White
Sands Missile Range.
Tasking Order (TO)— Developed by AFOTEC/A-3 and approved by AFOTEC/CC, the TO
details those products and services provided by the Det/evaluation team/special test, as
determined by the initial test design. The TO has enough detail to supply the TRP and the draft
TEMP. The TO is coordinated as a package that includes an initial/updated TRP and the
program’s requirements review board slides.
Technical Order (T.O.)— An AF publication that gives specific technical direction and
information concerning inspection, installation, operation, safety modification, and maintenance
of Air Force items and equipment.
Technical Adequacy— Addresses the relevance of the technical information produced by the
test in relation to the purpose of the test (i.e., the operationally relevant questions being
addressed by the test activity). A test is technically adequate if the test data evaluation provides
the user/warfighter with sufficient information to make fielding and employment decisions. The
purpose of the test, the set of test events, and the type of test are important considerations, as
well as data collection during test events executed across a representative range of battlespace
conditions for the system under test.
Test and Evaluation (T&E)— The term "test" denotes any project or program designed to
obtain, verify, and provide data to evaluate, research, and develop; progress in accomplishing
development objectives; performance and operational capability of systems, subsystems, and
components; and equipment items. The term "evaluation" denotes the review and analysis of
data produced during current or previous testing and data obtained from test conducted by other
government agencies and contractors, from operation and commercial experience, or
combinations thereof.
Test and Evaluation Master Plan (TEMP)— The basic planning document for all T&E related
to a particular system acquisition and used in planning, reviewing, and approving T&E. The
TEMP is required for all major defense acquisition programs, all OSD T&E oversight programs,
all HQ USAF programs directed by a PMD, and may be required for an OSD-directed
information system program. The TEMP integrates critical issues, associated measures
(MOE/MOS), evaluation criteria, system characteristics, responsibilities, resources, and
schedules for T&E.
Test Data Scoring Board (TDSB)— Government-only forum that compiles, reviews, and
scores R&M data to be used in OT&E computations.
 62                                                  AFOTECMAN99-101 11 OCTOBER 2012


Test      Director     (TD)—        The       Det-designated      person    responsible     for
leading/coordinating/completing test activities in the OT Planning, OT Execution, OT Reporting
and OT Close Out phases.
Test Readiness Review (TRR)— A review by the program’s management structure, including
the TD, AFOTEC/CC or designated approval authority, and other concerned participants. The
purpose of the TRR is to determine that the test team is ready to execute the test plan.
Test Resource Plan (TRP)— The basic resource management document used throughout the
OT&E planning process. It identifies resources required to support testing and is the basis for
budget submissions, manpower plans, and procurement lead-time.
Test Team— The group assigned to the TD for the purposes of planning, executing, and
reporting the OT&E. The test team is part of the core team for the program.
Threshold— A minimum acceptable operational value for a system capability or characteristic
below which the utility of the system becomes questionable. The minimum acceptable value
that, in the user’s judgment, is necessary to satisfy the need. If threshold values are not achieved,
program performance is seriously degraded, the program may be too costly, or the program may
no longer be timely. The spread between objective and threshold values shall be individually set
for each program based on the characteristics of the program (e.g., maturity, risk).
Transportability— The capability of materiel to be moved by towing, self-propulsion, or carrier
via any means such as railways, highways, waterways, pipelines, oceans, and airways. (Joint
Pub 1-02)
User Requirement— Operational requirement.
Verification, Validation, and Accreditation— 1) Verification: The process of determining that
a model or simulation (or other test capability) implementation accurately represents the
developer’s conceptual description and specifications. For model and simulation, verification
also evaluates the extent to which the model and simulation has been developed using sound and
established software-engineering techniques. 2) Validation: The process of determining a) the
manner and degree to which a model and simulation (or other test capability) is an accurate
representation of the real-world from the perspective of the intended uses of the model and
simulation, and b) the confidence that should be placed on the assessment. 3) Accreditation: An
official determination that a model or simulation is acceptable for a specific purpose, and is
based on a five-step process: identify test issues; review validation documentation; compare test
capabilities and validation information with test issues; identify potential shortfalls; and develop
and execute strategy to address shortfalls (assess risk).
Virtual—STAR (VSTAR) — A VSTAR is an OSD methodology for developing or updating
Vulnerability— The characteristics of a system that cause it to suffer a definite degradation
(loss or reduction of capability to perform the designated mission) as a result of having been
subjected to a certain level of effects in an unnatural (man-made) hostile environment.
Vulnerability is considered a subset of survivability. (Joint Pub 1-02).
